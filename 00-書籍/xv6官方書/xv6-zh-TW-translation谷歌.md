### xv6：一個簡單的類別Unix教學作業系統

Russ Cox Frans Kaashoek Robert Morris

2024 年 8 月 31 日

內容
--

*   1 作業系統介面
*   1.1 進程和內存
*   1.2 I/O and File descriptors
*   1.3 管道
*   1.4 檔案系統
*   1.5 Real world
*   1.6 Exercises
*   2 Operating system organization
*   2.1 物理資源抽象
*   2.2 User mode, supervisor mode, and system calls
*   2.3 Kernel organization
*   2.4 Code: xv6 organization
*   2.5 流程概述
*   2.6 程式碼：啟動xv6，第一個進程和系統調用
*   2.7 安全模型
*   2.8 Real world
*   2.9 Exercises
*   3 頁表
*   3.1 Paging hardware
*   3.2 Kernel address space
*   3.3 程式碼：建立位址空間
*   3.4 實體記憶體分配
*   3.5 代碼：實體記憶體分配器
*   3.6 Process address space
*   3.7 Code: sbrk
*   3.8 Code: exec
*   3.9 Real world
*   3.10 Exercises
*   4 陷阱和系統調用
*   4.1 RISC-V trap machinery
*   4.2 使用者空間的陷阱
*   4.3 Code: Calling system calls
*   4.4 代碼：系統呼叫參數
*   4.5 來自內核空間的陷阱
*   4.6 頁面錯誤異常
*   4.7 Real world
*   4.8 Exercises
*   5 中斷和設備驅動程式
*   5.1 Code: Console input
*   5.2 代碼：控制台輸出
*   5.3 驅動程式中的並發性
*   5.4 Timer interrupts
*   5.5 Real world
*   5.6 Exercises
*   6 Locking
*   6.1 Races
*   6.2 Code: Locks
*   6.3 Code: Using locks
*   6.4 Deadlock and lock ordering
*   6.5 Re-entrant locks
*   6.6 Locks and interrupt handlers
*   6.7 指令和記憶體排序
*   6.8 Sleep locks
*   6.9 Real world
*   6.10 Exercises
*   7 Scheduling
*   7.1 Multiplexing
*   7.2 代碼：上下文切換
*   7.3 Code: Scheduling
*   7.4 Code: mycpu and myproc
*   7.5 Sleep and wakeup
*   7.6 Code: Sleep and wakeup
*   7.7 代碼：管道
*   7.8 代碼：等待、退出、終止
*   7.9 Process Locking
*   7.10 Real world
*   7.11 Exercises
*   8 檔案系統
*   8.1 概述
*   8.2 Buffer cache layer
*   8.3 Code: Buffer cache
*   8.4 Logging layer
*   8.5 Log design
*   8.6 Code: logging
*   8.7 Code: Block allocator
*   8.8 Inode layer
*   8.9 Code: Inodes
*   8.10 Code: Inode content
*   8.11 代碼：目錄層
*   8.12 Code: Path names
*   8.13 File descriptor layer
*   8.14 Code: System calls
*   8.15 Real world
*   8.16 Exercises
*   9 重新審視並發
*   9.1 Locking patterns
*   9.2 Lock-like patterns
*   9.3 No locks at all
*   9.4 並行性
*   9.5 Exercises
*   10 Summary

前言和致謝
=====

這是為作業系統課程準備的文字草稿。它透過研究名為 xv6 的範例核心來解釋作業系統的主要概念。 Xv6 是以 Dennis Ritchie 和 Ken Thompson 的 Unix Version 6 (v6) \[17\] 為藍本的。 Xv6 大致遵循 v6 的結構和風格，但以 ANSI C \[7\] 實現，用於多核心 RISC-V \[15\]。本文應與 xv6 的源代碼一起閱讀，這是一種受到 John Lions 的 UNIX 第六版評論 \[11\] 啟發的方法；該文字具有指向原始程式碼的超鏈接，網址為 https://github.com/mit-pdos/xv6-riscv。請參閱[https://pdos.csail.mit.edu/6](https://pdos.csail.mit.edu/6) 。有關 v6 和 xv6 線上資源的其他指示，包括使用 xv6 的多個實驗室作業。我們在 6.828 和 6.1810（麻省理工學院的操作系統課程）中使用了此文本。我們感謝那些直接或間接為 xv6 做出貢獻的教師、助教和學生。我們特別要感謝 Adam Belay、Austin Clements 和 Nickolai Zeldovich。最後，我們要感謝透過電子郵件向我們發送文字中的錯誤或改進建議的人們：Abutalib Aghayev、Sebastian Boehm、brandb97、Anton Burtsev、Raphael Carvalho、Tej Chajed、Brendan Davidson、Rasit Eskicioglu、Color Fuzzy、Wej Chajed、Brendan Davidson、Rasit Eskicioglu、Color Fuzzy、Woj Chajed、Bojciech Gac ,ojciech Gac ,ojciech Gac ,ojci Gac ,ojcijech Gac Giuseppe, 郭濤, 郝海波, Naoki Hayama, Chris Henderson, Robert Hilderman, Eden Hochbaum, Wolfgang Keller, Paweł Kraszewski, Henry Laih, Jin Li, Austin Liew, [lyazj@github.](mailto:lyazj@github.com)com , Pavan Maddamsetti, Jacek Masiulaniec, Michael McConville, m3hm00d, miguelgvieira, Mark Morrissey, Muhammed Mourad, Harry Pan, Harry Porter, 錢思源, 喬哲峰, Askar Safin, Salman Shah, Huang Sha, Vikram Shenoy, Aikram Shenoy. Pawel Szczurko、Warren Toomey、tyfkda、tzerbib、Vanush Vaswani、Xi Wang 和Zou Chang Wei、Sam Whitlock、Qiongsi Wu、LucyShawYang、 [ykf1114@gmail.com](mailto:ykf1114@gmail.com)和孟週 如果您發現錯誤或有至改進建議，請發送電子郵件Frans Kaashoek 與Robert Morris (kaashoek, [rtm@csail.mit.edu](mailto:rtm@csail.mit.edu) )。

第一章
===

作業系統介面
======

作業系統的工作是在多個程序之間共享計算機，並提供比硬體單獨支援的更有用的服務集。作業系統管理和抽象低階硬件，因此，例如，文字處理器不需要關心正在使用哪種類型的磁碟硬體。作業系統在多個程式之間共享硬件，以便它們同時運行（或看似運行）。最後，作業系統為程式互動提供受控方式，以便它們可以共享資料或協同工作。作業系統透過介面向用戶程式提供服務。設計一個好的介面是很困難的。一方面，我們希望介面簡單又狹窄，因為這樣比較容易正確實作。另一方面，我們可能會想為應用程式提供許多複雜的功能。解決這種矛盾的技巧是設計依賴於幾種機制的介面，這些機制可以組合起來以提供更多的通用性。本書以單一作業系統作為具體例子來說明作業系統概念。該作業系統 xv6 提供了 Ken Thompson 和 Dennis Ritchie 的 Unix 作業系統 \[17\] 引入的基本接口，並模仿了 Unix 的內部設計。 Unix 提供了一個狹窄的接口，其機制結合得很好，提供了令人驚訝的通用性。這種介面非常成功，以至於現代作業系統（BSD、Linux、macOS、Solaris，甚至在較小程度上還有 Microsoft Windows）都具有類似 Unix 的介面。了解 xv6 是了解這些系統和許多其他系統的良好開端。如圖1。如圖 1 所示，xv6 採用傳統形式的 kernel，為正在運行的程式提供服務的特殊程式。每個正在運行的程式（稱為進程）都有包含指令、資料和堆疊的記憶體。這些指令實現程式的計算。數據是計算所作用的變數。堆疊組織程序的過程呼叫。給定的電腦通常具有許多進程，但只有一個核心。當進程需要調用核心服務時，它會調用系統調用，這是作業系統介面中的呼叫之一。系統呼叫進入核心；內核執行服務並返回。因此，進程在用戶空間和核心空間之間交替執行。正如後續章節中詳細描述的，核心使用 CPU^1 提供的硬體保護機制來確保在用戶空間中執行的每個進程只能訪問

(^1) 本文通常指的是使用術語 CPU（縮寫詞）執行計算的硬體元件

Kernel


shell cat
user
space


kernel
space


system
call


Figure 1.1: A kernel and two user processes.


它自己的記憶。核心以實現這些保護所需的硬體權限執行；使用者程式在沒有這些權限的情況下執行。當使用者程式呼叫系統呼叫時，硬體會提升特權等級並開始執行核心中預先安排的函數。

核心提供的系統呼叫的集合是用戶程式看到的介面。 xv6 核心提供了 Unix 核心傳統上提供的服務和系統呼叫的子集。圖1.2列出了xv6的所有系統呼叫。本章的其餘部分概述了 xv6 的服務——進程、記憶體、檔案描述符、管道和檔案系統——並用程式碼片段和討論 Unix 的命令列使用者介面 theshell 如何使用它們來說明它們。 shell 對系統呼叫的使用說明了它們的設計是多麼仔細。 shell是一個普通的程序，它讀取使用者的命令並執行它們。 shell 是一個使用者程序，而不是核心的一部分，這一事實說明了系統呼叫介面的強大功能：shell 沒有什麼特別的。這也意味著外殼易於更換；因此，現代 Unix 系統有多種 shell 可供選擇，每種 shell 都有自己的使用者介面和腳本功能。 xv6 shell 是 Unix Bourne shell 本質的簡單實作。它的實作可以在(user/sh.c:1) 找到。

### 1.1 進程和內存

xv6 行程由使用者空間記憶體（指令、資料和堆疊）和核心私有的每個行程狀態所組成。 Xv6time-shares 進程：它在等待執行的進程集中透明地切換可用的 CPU。當進程未執行時，xv6 會保存進程的 CPU 暫存器，並在下次執行該進程時恢復它們。核心將進程標識符 (PID) 與每個進程相關聯。

進程可以使用 fork 系統呼叫建立一個新進程。在原進程中，fork傳回新進程的PID。在新進程中，fork 傳回零。原始進程和新進程通常稱為父進程和子進程。

對於中央處理單元。其他文件（例如 RISC-V 規範）也使用字詞「處理器」、「核心」和「hart」來取代「CPU」。

System call Description
int fork() Create a process, return child’s PID.
int exit(int status) Terminate the current process; status reported to wait(). No return.
int wait(int *status) Wait for a child to exit; exit status in *status; returns child PID.
int kill(int pid) Terminate process PID. Returns 0, or -1 for error.
int getpid() Return the current process’s PID.
int sleep(int n) Pause for n clock ticks.
int exec(char *file, char *argv[]) Load a file and execute it with arguments; only returns if error.
char *sbrk(int n) Grow process’s memory by n zero bytes. Returns start of new memory.
int open(char *file, int flags) Open a file; flags indicate read/write; returns an fd (file descriptor).
int write(int fd, char *buf, int n) Write n bytes from buf to file descriptor fd; returns n.
int read(int fd, char *buf, int n) Read n bytes into buf; returns number read; or 0 if end of file.
int close(int fd) Release open file fd.
int dup(int fd) Return a new file descriptor referring to the same file as fd.
int pipe(int p[]) Create a pipe, put read/write file descriptors in p[0] and p[1].
int chdir(char *dir) Change the current directory.
int mkdir(char *dir) Create a new directory.
int mknod(char *file, int, int) Create a device file.
int fstat(int fd, struct stat *st) Place info about an open file into *st.
int link(char *file1, char *file2) Create another name (file2) for the file file1.
int unlink(char *file) Remove a file.


圖 1.2：Xv6 系統呼叫。如果沒有另外說明，這些呼叫如果沒有錯誤則傳回 0，如果有錯誤則傳回 -1。

例如，考慮以下用 C 程式語言編寫的程式片段 \[7\]：

int pid = fork();
if(pid > 0){
printf("parent: child=%d\n", pid);
pid = wait((int *) 0);
printf("child %d is done\n", pid);
} else if(pid == 0){
printf("child: exiting\n");
exit(0);
} else {
printf("fork error\n");
}


exit 系統呼叫導致呼叫程序停止執行並釋放資源，例如記憶體和開啟的檔案。 Exit 採用整數狀態參數，通常 0 表示成功，1 表示失敗。 wait系統呼叫返回目前程序退出（或殺死）的子程序的PID，並將子程序的退出狀態複製到傳遞給wait的位址；如果沒有一個

呼叫者的孩子已退出，請等待其中一個退出。如果呼叫者沒有孩子，wait 立即返回-1。如果父進程不關心子進程的退出狀態，它可以傳遞一個 0 位址來等待。在範例中，輸出行parent:child=child:exiting

可能會以任一順序（甚至混合）出現，這取決於父級或子級是否首先呼叫其 printf 。子進程退出後，父進程的wait返回，導致父進程打印

parent: child 1234 is done


儘管子進程最初與父進程具有相同的記憶體內容，但父進程和子進程使用單獨的記憶體和單獨的暫存器執行：更改其中一個變數不會影響另一個變數。例如，當wait的回傳值儲存到父進程中的pid時，它不會改變子進程中的變數pid。子進程中的 pid 值仍為零。 exec 系統呼叫以從檔案系統儲存的檔案載入的新記憶體映像取代呼叫進程的記憶體。該文件必須具有特定的格式，該格式指定文件的哪一部分保存指令、哪一部分是資料、從哪條指令開始等。通常該檔案是編譯程式原始碼的結果。當exec成功時，不會回到呼叫程式；相反，從檔案載入的指令在 ELF 標頭中聲明的入口點開始執行。 exec 採用兩個參數：包含可執行檔的檔名和字串參數陣列。例如：

char *argv[3];


argv[0] = "echo";
argv[1] = "hello";
argv[2] = 0;
exec("/bin/echo", argv);
printf("exec error\n");


該片段將呼叫程式替換為帶有參數listecho hello的program/bin/echorunning實例。大多數程式都會忽略參數數組的第一個元素，它通常是程式的名稱。 xv6 shell 使用上述呼叫代表使用者執行程式。外殼主要結構簡單；參見main(user/sh.c:146)。主循環使用 getcmd 讀取使用者的一行輸入。然後它呼叫 fork，建立 shell 進程的副本。父進程呼叫 wait，而子進程運行該命令。例如，如果使用者在 shell 中輸入了“echo hello”，則 runcmd 將以“echo hello”作為參數呼叫。對於“echo hello”，它將呼叫exec(user/sh.c:79)。如果exec成功，那麼子程序將執行來自echo的指令，而不是runcmd。在某些時候，echo 將呼叫 exit，這將導致父級從 waitinmain(user/sh.c:146) 返回。您可能想知道為什麼 fork 和 execare 不合併在一個呼叫中；稍後我們將看到 shell 在 I/O 重定向的實作中利用了分離。為了避免浪費

建立一個重複的進程，然後立即取代它（用 exec），作業系統核心透過使用虛擬記憶體技術（例如寫入時複製）來優化 fork 的實作（請參閱第 4.6 節）。 Xv6 隱式分配大部分用戶空間內存：fork 分配父內存的子副本所需的內存，exec 分配足夠的內存來保存可執行檔。在運行時需要更多記憶體（可能是formalloc）的進程可以呼叫brk(n)將其資料記憶體增加n0個位元組；sbrk傳回新記憶體的位置。

### 1.2 I/O and File descriptors

檔案描述符是一個小整數，表示進程可以讀取或寫入的核心管理物件。進程可以透過開啟檔案、目錄或設備，或透過建立管道，或透過複製現有描述符來取得檔案描述符。為了簡單起見，我們通常將文件描述符所指的物件稱為「文件」；文件描述符介面抽象化了檔案、管道和設備之間的差異，使它們看起來都像位元組流。我們將輸入和輸出稱為 I/O。在內部，xv6 核心使用檔案描述符作為每個進程表的索引，以便每個進程都有一個從零開始的檔案描述符的私有空間。依照慣例，進程從檔案描述符 0（標準輸入）讀取，將輸出寫入檔案描述符 1（標準輸出），並將錯誤訊息寫入檔案描述符 2（標準錯誤）。正如我們將看到的，shell 利用該約定來實現 I/O 重定向和管道。 shell 確保它始終開啟三個檔案描述符 (user/sh.c:152)，預設情況下它們是控制台的檔案描述符。 read 和 write 系統呼叫讀取位元組和寫入位元組來開啟由檔案描述符命名的檔案。呼叫read(fd,buf,n)從檔案描述子fd中讀取最多n個字節，將它們複製到buf中，並傳回讀取的位元組數。引用文件的每個文件描述符都有一個與其關聯的偏移量。次讀取返回的位元組之後的位元組。當沒有更多位元組可供讀取時，read 會傳回零以指示檔案結束。 呼叫 write(fd,buf,n) 將 n 個位元組從 buf 寫入檔案描述符 fd 並傳回寫入的位元組數。僅當發生錯誤時才會寫入少於 n 個位元組的資料。與 read 類似，write 在當前檔案偏移處寫入數據，然後將該偏移量前進寫入的位元組數：每次寫入都會從前一個寫入結束的位置繼續。以下程式片段（構成programcat的本質）將資料從其標準輸入複製到其標準輸出。如果發生錯誤，它將向標準錯誤寫入一條訊息。

char buf[512];
int n;


for(;;){
n = read(0, buf, sizeof buf);
if(n == 0)


break;
if(n < 0){
fprintf(2, "read error\n");
exit(1);
}
if(write(1, buf, n) != n){
fprintf(2, "write error\n");
exit(1);
}
}


程式碼片段中需要注意的重要一點是 cat 不知道它是從檔案、控制台還是管道中讀取。同樣，cat 也不知道它是否正在列印到控制台、檔案或其他什麼。檔案描述符的使用以及檔案描述符 0 為輸入、檔案描述符 1 為輸出的約定允許簡單地實作 cat。 close 系統呼叫釋放檔案描述符，使其可供將來的 open、pipe 或 dup 系統呼叫重複使用（見下文）。新指派的檔案描述符始終是目前進程中編號最小的未使用描述符。檔案描述符和 fork 相互作用，使 I/O 重定向易於實現。系統調用 exec 替換調用進程的內存，但保留其檔案表。此行為允許 shell 透過分叉、重新開啟子進程中選定的檔案描述符，然後呼叫 exec 運行新程式來實現 I/O 重定向。以下是 shell 為命令cat < input.txt 運行的程式碼的簡化版本：

char *argv[2];


argv[0] = "cat";
argv[1] = 0;
if(fork() == 0) {
close(0);
open("input.txt", O_RDONLY);
exec("cat", argv);
}


子進程關閉檔案描述子0 後，open 保證為新開啟的input.txt 使用該檔案描述子：0 將是最小的可用檔案描述子。執行。此序列不會更改父進程的檔案描述符，因為它僅修改子進程的描述符。

xv6 shell 中 I/O 重定向的程式碼正是以此方式運作的（user/sh.c:83）。回想一下，此時在程式碼中，shell 已經分叉了子 shell，並且 runcmd 會呼叫 exec 來載入新程式。 open 的第二個參數由一組標誌組成，以位元表示，用於控制 open 執行的操作。可能的值在檔案控制(fcntl)頭(kernel/fcntl.h:1-5)中定義：O\_RDONLY、O\_WRONLY、O\_RDWR、O\_CREATE和O\_TRUNC，指示open開啟檔案

用於讀取、或用於寫入、或用於讀取和寫入，如果文件不存在則建立文件，並將文件截斷為零長度。

現在應該清楚為什麼 fork 和 exe 單獨呼叫是有幫助的：在兩者之間，shell 有機會重定向子程序的 I/O，而不會幹擾主 shell 的 I/O 設定。人們可以想像一個假設的組合 forkexec 系統調用，但使用此類調用進行 I/O 重定向的選項似乎很尷尬。 shell 可以在呼叫 forkexec 之前修改自己的 I/O 設定（然後撤銷這些修改）；或者forkexec可以將I/O重定向指令當作參數；或（最不吸引人的）每個程式（如 cat）都可以被教導進行自己的 I/O 重新導向。

儘管 fork 複製檔案描述符表，但每個底層檔案偏移量在父級和子級之間共用。考慮這個例子：

if(fork() == 0) {
write(1, "hello ", 6);
exit(0);
} else {
wait(0);
write(1, "world\n", 6);
}


在此片段的末尾，附加到檔案描述符 1 的檔案將包含 datahello world。父級中的寫入（由於等待，僅在子級完成後才運行）將從子級寫入停止的地方繼續進行。此行為有助於從 shell 命令序列產生順序輸出，例如(echo hello;echo world)>output.txt。

dup 系統呼叫複製現有的檔案描述符，傳回一個引用相同底層 I/O 物件的新檔案描述符。兩個檔案描述符共用一個偏移量，就像 forkdo 複製的檔案描述符一樣。這是將 hello world 寫入檔案的另一種方法：

fd = dup(1);
write(1, "hello ", 6);
write(fd, "world\n", 6);


如果兩個檔案描述子是透過一系列 fork 和 ddup 呼叫從相同原始檔案描述子派生的，則它們共用一個偏移量。否則，檔案描述子不共享偏移量，即使它們是由對相同檔案的 open 呼叫產生的。 2>&1 告訴 shell 給指令一個檔案描述符 2，它是描述符 1 的副本。 xv6 shell 不支援錯誤檔案描述符的 I/O 重新導向，但現在您知道如何實現它。

檔案描述符是一個強大的抽象，因為它們隱藏了它們所連接的細節：寫入檔案描述符 1 的進程可能正在寫入檔案、控制台等裝置或管道。

### 1.3 管道

Apipe 是一個小型核心緩衝區，作為一對檔案描述子向進程公開，一個用於讀取，一個用於寫入。將資料寫入管道的一端使得該資料可用於從管道的另一端讀取。管道為進程提供了一種通訊方式。以下範例程式碼執行程式 wc，並將標準輸入連接到管道的讀取端。

int p[2];
char *argv[2];


argv[0] = "wc";
argv[1] = 0;


pipe(p);
if(fork() == 0) {
close(0);
dup(p[0]);
close(p[0]);
close(p[1]);
exec("/bin/wc", argv);
} else {
close(p[0]);
write(p[1], "hello world\n", 12);
close(p[1]);
}


程式呼叫pipe，建立一個新的管道，並將讀寫檔案描述子記錄在arrayp中。 Afterfork 後，父級和子級都有引用管道的檔案描述符。子程序呼叫 close 和 dup 使檔案描述子為零，引用管道的讀取端，關閉檔案描述子 inp，並呼叫 exec 運行 wc。當wc從其標準輸入讀取時，它從管道讀取。父級關閉管道的讀取端，寫入管道，然後關閉寫入端。如果沒有可用數據，則管道上等待資料寫入或所有引用寫入端的檔案描述符關閉；在後一種情況下，read 將傳回 0，就像已到達資料檔案末尾一樣。 read 會一直阻塞直到新資料無法到達，這一事實是子進程在執行wcabove 之前關閉管道的寫入端非常重要的原因之一：如果wc 的檔案描述符之一引用了管道的寫入端，則wc 將永遠不會看到檔案結尾。 xv6 shell 實作了管道，例如 grep fork sh.c | wc -lin 的方式類似上面的程式碼(user/sh.c:101)。子進程會建立一個管道來連接管道的左端和右端。然後，它為管道的左端呼叫 forkandruncmd，為右端呼叫 forkandruncmd，並等待兩者完成。管道的右端可能是一個命令，它本身包括一個管道（例如，a | b | c），它本身分叉兩個新的子進程（一個forband一個forc）。因此，外殼可以創建進程樹。葉子

這棵樹的節點是命令，內部節點是等待左右子節點完成的程序。管道可能看起來並不比臨時檔案更強大：管道 echo hello world |廁所

可以在沒有管道的情況下實現

echo hello world >/tmp/xyz; wc </tmp/xyz


在這種情況下，管道比臨時檔案至少有三個優點。首先，管道會自動進行自我清理；透過檔案重定向，完成後 shell 必須小心刪除 /tmp/xyz。其次，管道可以傳遞任意長的資料流，而檔案重新導向需要磁碟上有足夠的可用空間來儲存所有資料。第三，管道允許並行執行管道階段，而檔案方法要求第一個程式在第二個程式開始之前完成。

### 1.4 檔案系統

xv6 檔案系統提供資料檔案（包含未解釋的位元組陣列）和目錄（包含對資料檔案和其他目錄的命名引用）。這些目錄形成一棵樹，從稱為 root 的特殊目錄開始。 /a/b/c 等路徑是​​指根目錄/ 中名為bin 的目錄中名為cin 的檔案或目錄。不以 / 開頭的路徑是相對於呼叫程序的當前目錄進行評估的，可以透過 chdir 系統呼叫來更改該目錄。這兩個程式碼片段都打開同一個檔案（假設所有涉及的目錄都存在）：

chdir("/a");
chdir("b");
open("c", O_RDONLY);


open("/a/b/c", O_RDONLY);


第一個片段將進程的目前目錄改為/a/b；第二個既不引用也不更改行程的目前目錄。有系統呼叫來建立新檔案和目錄：mkdir 建立一個新目錄，使用 O\_CREATE 標誌開啟建立一個新資料文件，mknod 建立一個新裝置檔案。此範例說明了所有三個：

mkdir("/dir");
fd = open("/dir/file", O_CREATE|O_WRONLY);
close(fd);
mknod("/console", 1, 1);


mknod 建立一個引用設備的特殊檔案。與設備檔案關聯的是主設備號碼和次設備號碼（兩個參數 tomknod），它們唯一地識別核心設備。當進程稍後打開設備檔案時，核心會將讀寫系統呼叫轉移到核心設備實現，而不是將它們傳遞到檔案系統。

文件名與文件本身不同；同一個底層檔案（稱為 annode）可以有多個名稱（稱為連結）。每個連結都包含目錄中的一個條目；該條目包含檔案名稱和對索引節點的引用。索引節點保存有關檔案的元數據，包括其類型（檔案或目錄或裝置）、長度、檔案內容在磁碟上的位置以及檔案的連結數。 fstat 系統呼叫從檔案描述符引用的索引節點檢索資訊。它填入一個struct stat，在stat.h(kernel/stat.h)中定義為：

#define T_DIR 1 // Directory
#define T_FILE 2 // File
#define T_DEVICE 3 // Device


結構體 stat { int dev; // 檔案系統的磁碟設備 uint ino; // 短類型索引節點號； // 檔案類型 Short nlink; // 檔案連結數 uint64 size; // 檔案大小（以位元組為單位） }; link 系統呼叫建立另一個檔案系統名稱，引用與現有檔案相同的 inode。該片段建立一個名為 Bothaandb 的新檔案。

open("a", O_CREATE|O_WRONLY);
link("a", "b");


讀取或寫入 toai 與讀取或寫入 tob 相同。每個索引節點都由唯一的索引節點號碼來識別。在上面的程式碼序列之後，透過檢查offstat結果可以確定a和b引用相同的底層內容：兩者將傳回相同的inode編號（ino），然後linkcount將被設定為2。刪除一個名稱檔案系統。只有當檔案的連結計數為零且沒有檔案描述符引用它時，才會釋放檔案的索引節點和保存其內容的磁碟空間。因此添加

unlink("a");


到最後一個程式碼序列使 inode 和檔案內容可存取 asb。此外，

fd = open("/tmp/xyz", O_CREATE|O_RDWR);
unlink("/tmp/xyz");


是建立一個沒有名稱的臨時索引節點的慣用方法，當進程 closesfdor 退出時，該臨時索引節點將被清除。 Unix 提供可從 shell 作為使用者級程式呼叫的檔案實用程序，例如 mkdir、ln 和 rm。這種設計允許任何人透過添加新的用戶級程式來擴展命令列介面。事後看來，這個計劃似乎是顯而易見的，但 Unix 時代設計的其他系統經常將此類命令內建到 shell 中（並將 shell 內建到核心中）。一個例外是 cd，它內建在 shell 中 (user/sh.c:161)。如果 cd 作為常規命令運行，那麼 shell 會

fork一個子進程，子進程將運行cd，並且cd將更改子進程的工作目錄。父級（即 shell 的）工作目錄不會改變。

### 1.5 Real world

Unix 將「標準」檔案描述子、管道和對其進行操作的便捷 shell 語法結合，這是編寫通用可重複使用程式的一大進步。這個想法引發了一種「軟體工具」文化，Unix 的強大和流行在很大程度上歸功於這種文化，而 shell 是第一個所謂的「腳本語言」。如今，Unix 系統呼叫介面仍存在於 BSD、Linux 和 macOS 等系統中。 Unix 系統呼叫介面已透過可移植作業系統介面 (POSIX) 標準進行了標準化。 Xv6 不符合 POSIX：它缺少許多系統調用（包括基本的系統調用，如 lseek），而且它提供的許多系統調用與標準不同。我們 xv6 的主要目標是簡單和清晰，同時提供簡單的類 UNIX 系統呼叫介面。有幾個人用更多的系統呼叫和簡單的 C 庫擴展了 xv6，以便運行基本的 Unix 程式。然而，與 xv6 相比，現代核心提供了更多的系統呼叫和更多種類的核心服務。例如，它們支援網路、視窗系統、使用者級執行緒、許多裝置的驅動程式等等。現代核心不斷快速發展，並提供了許多超越 POSIX 的功能。 Unix 透過一組檔案名稱和檔案描述符介面統一存取多種類型的資源（檔案、目錄和裝置）。這個想法可以擴展到更多種類的資源； Plan 9 \[16\]就是一個很好的例子，它將「資源就是文件」的概念應用於網路、圖形等。然而，大多數 Unix 衍生的作業系統並沒有遵循這條路線。檔案系統和檔案描述符是強大的抽象。即便如此，作業系統介面還有其他模型。 Multics 是 Unix 的前身，它以一種看起來像記憶體的方式抽象化了檔案存儲，從而產生了一種截然不同的介面風格。 Multics 設計的複雜性對 Unix 的設計者產生了直接影響，他們的目標是建造更簡單的東西。 Xv6 不提供使用者的概念或保護一個使用者免受另一使用者侵害的概念；在 Unix 術語中，所有 xv6 進程都以 root 身分執行。本書探討了 xv6 如何實現其類 Unix 接口，但其中的思想和概念不僅僅適用於 Unix。任何作業系統都必須將進程復用到底層硬體上，將進程彼此隔離，並提供受控進程間通訊的機制。研究完 xv6 後，您應該可以了解其他更複雜的作業系統，並了解這些系統中 xv6 的底層概念。

### 1.6 Exercises

1. 寫一個程序，使用 UNIX 系統呼叫透過一對管道（每個方向一個）在兩個進程之間「乒乓」一個位元組。衡量程式的效能，以每秒的交換次數為單位。

第2章
===

Operating system organization
=============================

作業系統的一個關鍵要求是同時支援多個活動。例如，使用第 1 章中所述的系統呼叫接口，進程可以透過 fork 啟動新進程。作業系統必須在這些進程之間共享電腦資源。例如，即使進程數量多於硬體 CPU 數量，作業系統也必須確保所有進程都有機會執行。作業系統也必須安排進程之間的隔離。也就是說，如果一個進程有錯誤並且發生故障，它不應該影響不依賴有錯誤的進程的進程。然而，完全隔離太強了，因為進程應該可以有意地互動；管道就是一個例子。因此，作業系統必須滿足三個要求：重複使用、隔離和互動。

本章概述如何組織作業系統來實現這三個要求。事實證明，有很多方法可以做到這一點，但本文重點關注以單晶片為中心的主流設計，該核心被許多 Unix 作業系統所使用。本章也概述了 xv6 進程（xv6 中的隔離單元）以及 xv6 啟動時第一個進程的建立。

Xv6 在多核心^1 RISC-V 微處理器上運行，其許多低階功能（例如，其流程實現）特定於 RISC-V。 RISC-V是64位元CPU，xv6是用「LP64」C編寫的，這意味著C程式語言中的長整型（L）和指標（P）是64位元，但anin是32位元。本書假設讀者已經在某些架構上完成了一些機器級編程，並將在出現時介紹 RISC-V 特定的想法。使用者層級ISA \[2\]和特權架構\[3\]文件是完整的規格。您也可以參考「RISC-V Reader：開放架構圖集」\[15\]。

完整電腦中的 CPU 周圍環繞著支援硬件，其中大部分以 I/O 介面的形式存在。 Xv6 是為支援 qemu 的「-machine virt」選項模擬的硬體而編寫的。這包括 RAM、包含啟動代碼的 ROM、與用戶鍵盤/螢幕的串行連接以及用於存儲的磁碟。

(^1) 本文中的「多核心」是指共享記憶體但並行執行的多個 CPU，每個 CPU 都有自己的一組暫存器。本文有時會使用術語多處理器作為多核心的同義詞，但多處理器也可以更具體地說是具有多個不同處理器晶片的電腦。

### 2.1 物理資源抽象

當遇到作業系統時，人們可能會問的第一個問題是為什麼要擁有它？也就是說，可以將圖 1.2 中的系統呼叫實作為一個函式庫，應用程式可以與該函式庫連結。在此計劃中，每個應用程式甚至可以擁有適合其需求的自己的庫。應用程式可以直接與硬體資源交互，並以最適合應用程式的方式使用這些資源（例如，實現較高的或可預測的效能）。一些嵌入式設備或即時系統的作業系統就是以這種方式組織的。這種庫方法的缺點是，如果有多個應用程式正在運行，則這些應用程式必須表現良好。例如，每個應用程式必須定期放棄CPU，以便其他應用程式可以運行。如果所有應用程式相互信任且沒有錯誤，那麼這種協作分時方案可能是可行的。更常見的情況是應用程式彼此不信任並且存在錯誤，因此人們通常需要比協作方案提供的更強的隔離性。為了實現強隔離，禁止應用程式直接存取敏感硬體資源，並將資源抽象化為服務，會很有幫助。例如，Unix應用程式僅透過檔案系統的open、read、write和close系統呼叫與儲存交互，而不是直接讀寫磁碟。這為應用程式提供了路徑名的便利，並且允許作業系統（作為介面的實現者）管理磁碟。即使隔離不是問題，有意互動（或只是希望不妨礙彼此）的程式也可能發現檔案系統是比直接使用磁碟更方便的抽象。 類似地，Unix 在進程之間透明地切換硬體 CPU，根據需要保存和恢復暫存器狀態，因此應用程式不必了解分時。即使某些應用程式處於無限循環中，這種透明度也允許作業系統共享 CPU。另一個例子，Unix進程使用exec來建立它們的記憶體映像，而不是直接與實體記憶體互動。這允許作業系統決定將進程放置在記憶體中的位置；如果記憶體緊張，作業系統甚至可能將一些進程的資料儲存在磁碟上。 Unix 進程之間的許多形式的交互作用都是透過檔案描述符發生的。文件描述符不僅抽象化了許多細節（例如，管道或文件中資料的儲存位置），而且還以簡化互動的方式定義。例如，如果管道中的一個應用程式失敗，核心會為管道中的下一個程序產生檔案結束訊號。圖 1.2 中的系統呼叫介面經過精心設計，既為程式設計師提供了便利，也提供了強隔離的可能性。 Unix 介面並不是抽象資源的唯一方法，但它已被證明是一種很好的方法。

### 2.2 User mode, supervisor mode, and system calls

強隔離需要應用程式和作業系統之間有硬邊界。如果應用程式出錯，我們不希望作業系統失敗或其他應用程式失敗

失敗。相反，作業系統應該能夠清理失敗的應用程式並繼續運行其他應用程式。為了實現強隔離，作業系統必須安排應用程式不能修改（甚至讀取）作業系統的資料結構和指令，並且應用程式不能存取其他進程的記憶體。 CPU為強隔離提供硬體支援。例如，RISC-V具有CPU執行指令的三種模式：機器模式、管理程式模式、使用者模式。在機器模式下執行的指令具有完全特權； CPU 以機器模式啟動。機器模式主要用於在啟動期間設定電腦。 Xv6 在機器模式下執行幾行，然後變更為管理模式。在管理模式下，CPU 被允許執行特權指令：例如，啟用和停用中斷、讀取和寫入保存頁表位址的暫存器等。指令，而是切換到管理模式，以便管理模式代碼可以終止應用程序，因為它做了一些不應該做的事情。第 1 章中的圖 1.1 說明了該組織。一個應用程式只能執行使用者模式指令（例如，加數字等），並且被稱為在用戶空間中運行，而處於管理模式的軟體也可以執行特權指令，並且被稱為在核心空間中運行。運行在核心空間（或管理模式）的軟體稱為核心。想要呼叫核心函數（例如xv6中的read系統呼叫）的應用程式必須轉換到核心；應用程式不能直接呼叫內核函數。 CPU 提供了一個特殊的指令，可以將 CPU 從使用者模式切換到管理模式，並在核心指定的入口點進入核心。 （RISC-V 為此目的提供了 ecall 指令。）一旦 CPU 切換到管理模式，核心就可以驗證系統呼叫的參數（例如，檢查傳遞給系統呼叫的位址是否是應用程式記憶體的一部分） ，決定是否允許應用程式執行請求的操作（例如，檢查是否允許應用程式寫入指定的檔案），然後拒絕或執行。核心控制轉換到管理模式的入口點非常重要；例如，如果應用程式可以決定核心入口點，則惡意應用程式可以在跳過參數驗證的點進入核心。

### 2.3 Kernel organization

一個關鍵的設計問題是作業系統的哪一部分應該在管理模式下運作。一種可能性是整個作業系統駐留在核心中，因此所有系統呼叫的實作都在管理程式模式下運行。這種組織稱為單晶片內核。在這個組織中，整個作業系統由一個以完全硬體權限運行的程式組成。這種組織很方便，因為作業系統設計者不必決定作業系統的哪些部分不需要完整的硬體權限。此外，作業系統的不同部分更容易協作。例如，作業系統可能具有可由檔案系統和虛擬記憶體系統共享的緩衝區快取。單一組織的缺點是作業系統不同部分之間的互動通常很複雜（正如我們將在本文的其餘部分中看到的），因此它

Microkernel


user shell File server
space


kernel
space


(^) 傳送訊息 圖 2.1：具有檔案系統伺服器的微內核很容易讓作業系統開發人員犯錯。在單晶片中，一個錯誤是致命的，因為管理模式下的錯誤往往會導致核心失敗。如果核心發生故障，電腦就會停止運作，因此所有應用程式也會失敗。電腦必須重新啟動才能重新啟動。為了降低核心出錯的風險，作業系統設計者可以最大限度地減少在管理模式下運行的作業系統程式碼量，並在使用者模式下執行作業系統的大部分內容。這種內核組織稱為微內核。圖 2.1 說明了這種微內核設計。圖中，檔案系統作為使用者級進程運作。作為一個行程運行的作業系統服務稱為伺服器。為了允許應用程式與檔案伺服器交互，核心提供了一種進程間通訊機制，將訊息從一個使用者模式進程發送到另一個使用者模式進程。例如，如果像 shell 這樣的應用程式想要讀取或寫入文件，它會向文件伺服器發送訊息並等待回應。在微核心中，核心介面由一些低階函數組成，用於啟動應用程式、傳送訊息、存取裝置硬體等。在現實世界中，單片內核和微內核都很流行。許多 Unix 核心都是單一的。例如，Linux 具有單片內核，儘管某些作業系統功能作為用戶級伺服器運行（例如，視窗系統）。 Linux 為作業系統密集型應用程式提供了高效能，部分原因是核心的子系統可以緊密整合。 Minix、L4 和 QNX 等作業系統被組織為具有伺服器的微內核，並且在嵌入式設定中得到了廣泛的部署。 L4 的一個變體 seL4 足夠小，已經過記憶體安全性和其他安全性屬性的驗證 \[8\]。關於哪種組織更好，作業系統開發人員之間存在著許多爭論，並且沒有任何確鑿的證據。此外，這在很大程度上取決於「更好」的含義：更快的效能、更小的程式碼大小、核心的可靠性、整個作業系統的可靠性（包括用戶級服務）等。更重要的實際考慮因素而不是哪個組織的問題。一些作業系統具有微內核，但出於性能原因在內核空間中運行一些用戶級服務。一些作業系統具有單片內核，因為它們就是這樣開始的，並且幾乎沒有動力轉向純粹的微內核組織，因為新功能可能比重寫現有作業系統以適應微內核設計更重要。從本書的角度來看，微核心和單晶片作業系統有許多共同的關鍵想法。他們實現系統調用，他們使用頁表，他們處理中斷，他們支持

File Description
bio.c Disk block cache for the file system.
console.c Connect to the user keyboard and screen.
entry.S Very first boot instructions.
exec.c exec() system call.
file.c File descriptor support.
fs.c File system.
kalloc.c Physical page allocator.
kernelvec.S Handle traps from kernel.
log.c File system logging and crash recovery.
main.c Control initialization of other modules during boot.
pipe.c Pipes.
plic.c RISC-V interrupt controller.
printf.c Formatted output to the console.
proc.c Processes and scheduling.
sleeplock.c Locks that yield the CPU.
spinlock.c Locks that don’t yield the CPU.
start.c Early machine-mode boot code.
string.c C string and byte-array library.
swtch.S Thread switching.
syscall.c Dispatch system calls to handling function.
sysfile.c File-related system calls.
sysproc.c Process-related system calls.
trampoline.S Assembly code to switch between user and kernel.
trap.c C code to handle and return from traps and interrupts.
uart.c Serial-port console device driver.
virtio_disk.c Disk device driver.
vm.c Manage page tables and address spaces.


Figure 2.2: Xv6 kernel source files.


進程，它們使用鎖進行並發控制，它們實現文件系統等等。與大多數 Unix 作業系統一樣，Xv6 是作為整體核心實現的。因此，xv6核心介面對應於作業系統接口，核心實現了完整的作業系統。由於 xv6 不提供很多服務，因此它的內核比一些微內核要小，但從概念上講 xv6 是整體的。

### 2.4 Code: xv6 organization

xv6 核心原始碼位於kernel/子目錄。原始碼被分成文件，遵循模組化的粗略概念；圖 2.2 列出了這些文件。模組間接口定義在

0


user text
and data


user stack


heap


MAXVA
trampoline
trapframe


Figure 2.3: Layout of a process’s virtual address space


defs.h(kernel/defs.h).

### 2.5 流程概述

xv6 中的隔離單位（與其他 Unix 作業系統中一樣）是進程。進程抽象可以防止一個進程破壞或監視另一個進程的記憶體、CPU、檔案描述符等。核心必須小心地實現進程抽象，因為有錯誤或惡意的應用程式可能會欺騙核心或硬體做一些壞事（例如，規避隔離）。核心用於實現進程的機制包括使用者/管理程式模式標誌、位址空間和執行緒的時間分片。為了幫助實施隔離，進程抽象化為程式提供了它擁有自己的私人機器的錯覺。進程為程式提供看似私有的記憶體系統或位址空間，其他進程無法讀取或寫入。進程也為程式提供看似自己的 CPU 來執行程式的指令。 Xv6 使用頁表（由硬體實現）為每個進程提供自己的位址空間。 RISC-V 頁表將虛擬位址（RISC-V 指令操作的位址）轉換（或「對映」）為實體位址（CPU 傳送至主記憶體的位址）。 Xv6 為每個行程維護一個單獨的頁表，用於定義該行程的位址空間。如圖 2.3 所示，位址空間包含從虛擬位址 0 開始的程序的使用者記憶體。首先是指令，然後是全域變量，然後是堆疊，最後是進程可以根據需要擴展的「堆」區域（用於 malloc）。 有許多因素限制了進程位址空間的最大大小：RISC-V 上的指標是 64 位元寬；硬體在頁表中尋找虛擬位址時僅使用低 39 位元； xv6 僅使用這 39 位元中的 38 位元。因此，最大位址為 238 − 1 = 0x3ffffffffff，其中

isMAXVA（內核/riscv.h：378）。 xv6 在位址空間的頂部放置 atrampolinepage（4096 位元組）和 atrapframepage。 Xv6 使用這兩個頁面來轉換核心並返回； Trampoline 頁包含了進出核心的程式碼，trapframe 是核心保存進程使用者暫存器的地方，如第 4 章所述。

xv6 核心為每個行程維護許多狀態，並將其收集到 struct proc (kernel/proc.h:85) 中。進程最重要的核心狀態部分是其頁表、核心堆疊和運行狀態。我們將使用符號 p->xxx 來引用 proc 結構的元素；例如，p->pagetable是指向進程頁表的指標。

每個行程都有一個控制執行緒（或簡稱執行緒），用來保存執行進程所需的狀態。在任何給定時間，執行緒可能正在 CPU 上執行，或暫停（不執行，但能夠在將來恢復執行）。為了在進程之間切換 CPU，核心會掛起目前在該 CPU 上執行的執行緒並保存其狀態，並恢復另一個進程先前掛起的執行緒的狀態。線程的大部分狀態（局部變數、函數呼叫返回地址）都儲存在線程的堆疊中。每個行程都有兩個堆疊：使用者堆疊和核心堆疊 (p->kstack)。當進程執行使用者指令時，只有其使用者堆疊在使用，其核心堆疊為空。當行程進入核心時（進行系統呼叫或中斷），核心程式碼會在行程的核心堆疊上執行；當進程位於核心中時，其使用者堆疊仍然包含已儲存的數據，但不會被主動使用。進程的執行緒在主動使用其使用者堆疊和核心堆疊之間交替。核心堆疊是獨立的（並受到使用者程式碼的保護），因此即使進程破壞了其用戶堆疊，核心也可以執行。

進程可以透過執行RISC-Vecall指令來進行系統呼叫。此指令提高硬體特權等級並將程式計數器變更為核心定義的入口點。入口點的程式碼切換到進程的核心堆疊並執行實現系統呼叫的核心指令。當系統呼叫完成後，核心切換回使用者堆疊，並透過呼叫retinstruction返回使用者空間，從而降低硬體特權等級並在系統呼叫指令之後恢復執行使用者指令。進程的執行緒可以在核心中「阻塞」以等待 I/O，並在 I/O 完成後從中斷處恢復。

p->state 指示進程是否已分配、準備運行、目前在 CPU 上運行、正在等待 I/O 或正在退出。

p->pagetable 以 RISC-V 硬體期望的格式儲存進程的頁表。當在使用者空間中執行該進程時，Xv6 導致分頁硬體使用該進程的 sp->pagetable。進程的頁表也充當分配用於儲存進程記憶體的實體頁位址的記錄。

總而言之，進程捆綁了兩種設計想法：位址空間為進程提供了自己記憶體的假象，線程為進程提供了自己 CPU 的假象。在xv6中，一個行程由一個位址空間和一個執行緒組成。在實際作業系統中，一個行程可能有多個執行緒來利用多個 CPU。

### 2.6 程式碼：啟動xv6，第一個進程和系統調用

為了使 xv6 更加具體，我們將概述核心如何啟動和運行第一個進程。後續章節將更詳細地描述本概述中所顯示的機制。

當 RISC-V 電腦開機時，它會進行自身初始化並運行儲存在唯讀記憶體中的引導程式。引導程式將 xv6 核心載入到記憶體中。然後，在機器模式下，CPU 從 at\_entry(kernel/entry.S:7) 開始執行 xv6。 RISC-V 在停用分頁硬體的情況下啟動：虛擬位址直接對應到實體位址。

載入器將 xv6 核心載入到實體位址 0x80000000 的記憶體中。它將核心放置在 0x80000000 而不是 0x0 的原因是因為位址範圍 0x0:0x80000000 包含 I/O 裝置。

at\_entry指令設定了一個堆疊，以便xv6可以運行C程式碼。 Xv6 在檔案start.c(kernel/start.c:11) 中宣告了初始堆疊stack0 的空間。程式碼 at\_entry 載入位址為 stack0+4096 的堆疊指標暫存器 sp，即堆疊頂部，因為 RISC-V 上的堆疊是向下增長的。現在核心有了一個堆疊，\_entry 在啟動時呼叫 C 程式碼 (kernel/start.c:15)。

函數start執行一些僅在機器模式下允許的配置，然後切換到管理模式。為了進入管理模式，RISC-V 提供了 mret 指令。該指令最常用於從先前的呼叫從管理模式返回到機器模式。的位址寫入暫存器mepc來設定回傳位址為main，透過將0寫入頁表暫存器satp來停用管理模式下的虛擬位址轉換，並將所有中斷和異常委託給管理模式。

在進入管理模式之前，start 也執行一項任務：對時脈晶片進行程式設計以產生定時器中斷。完成此內務處理後，透過呼叫 mret 開始「返回」到主管模式。這會導致程式計數器變更為 main(kernel/main.c:11)，即先前儲存在 mepc 中的位址。

main(kernel/main.c:11)初始化幾個裝置和子系統後，它透過呼叫userinit(kernel/proc.c:233)來建立第一個程序。第一個程序執行一個用RISC-V彙編語言編寫的小程序，這使得xv6.initcode.S(user/initcode.S:3)中的第一個系統呼叫載入了exec系統呼叫的編號，SYS\_EXEC( kernel/syscall.h: 8)、進入registera7，然後呼叫ecallto重新進入核心。

核心使用syscall(kernel/syscall.c:132)中的registera7中的編號來呼叫所需的系統呼叫。系統呼叫表(kernel/syscall.c:107)將SYS\_EXEC對應到核心呼叫的函式sys\_exec。正如我們在第 1 章中所看到的，exec 以一個新程式（在本例中為 /init）取代目前進程的記憶體和暫存器。

一旦核心完成exec，它就會返回到用戶空間中的/initprocess.init（user/init.c:15）如果需要的話創建一個新的控制台設備文件，然後將其作為文件描述符0 、1和2開啟。系統已啟動。

### 2.7 安全模型

您可能想知道作業系統如何處理有錯誤或惡意程式碼。由於應對惡意行為比處理意外錯誤要困難得多，因此主要關注提供針對惡意行為的安全性是合理的。以下是作業系統設計中典型安全假設和目標的高階視圖。作業系統必須假設進程的使用者級程式碼將盡最大努力破壞核心或其他進程。使用者程式碼可能會嘗試取消引用其允許的位址空間之外的指標；它可能會嘗試執行任何 RISC-V 指令，甚至是那些不用於使用者程式碼的指令；它可能會嘗試讀寫任何RISC-V控制暫存器；它可能會嘗試直接存取設備硬體；它可能會向系統呼叫傳遞聰明的值，試圖欺騙核心崩潰或做一些愚蠢的事情。核心的目標是限制每個用戶進程，使其只能讀/寫/執行自己的用戶內存，使用 32 個通用 RISC-V 寄存器，並透過系統調用的方式影響內核和其他進程旨在允許。內核必須阻止任何其他操作。這通常是核心設計中的絕對要求。對核心自身程式碼的期望有很大不同。內核程式碼被認為是由善意且細心的程式設計師編寫的。內核程式碼應該沒有錯誤，並且肯定不包含任何惡意內容。這個假設影響我們分析內核程式碼的方式。例如，有許多內部核心函數（例如，自旋鎖），如果核心程式碼不正確地使用它們，就會導致嚴重的問題。當檢查任何特定的核心程式碼片段時，我們希望說服自己它的行為正確。 然而，我們假設內核程式碼總體上是正確編寫的，並且遵循有關使用內核自身函數和資料結構的所有規則。在硬體層面，假設 RISC-V CPU、RAM、磁碟等依照文件中宣傳的方式運行，沒有硬體錯誤。當然，在現實生活中事情並不是那麼簡單。很難阻止聰明的使用者程式碼透過消耗核心保護的資源而導致系統無法使用（或導致系統崩潰）

*   磁碟空間、CPU 時間、行程表槽位等。如果惡意使用者程式碼的編寫者意識到核心或硬體錯誤，他們就會利用它們。即使在成熟、廣泛使用的核心中，例如 Linux，人們也會不斷發現新的漏洞 \[1\]。值得在核心中設計保護措施以防止其存在錯誤：斷言、類型檢查、堆疊保護頁等。地成為作業系統的一部分，並且在某些作業系統中特權使用者程式碼可以將新程式碼插入核心（就像Linux 的可載入核心模組一樣）。

### 2.8 Real world

大多數作業系統都採用了進程概念，大多數進程看起來與 xv6 類似。然而，現代作業系統支援進程內的多個線程，以允許單一進程利用多個 CPU。支援進程中的多執行緒涉及 xv6 所沒有的大量機制，通常包括介面變更（例如 Linux 的clone、a

fork 的變體），以控制進程執行緒共享的哪些方面。

### 2.9 Exercises

1. 在 xv6 中新增一個系統調用，返回可用的可用記憶體量。

第三章
===

頁表
==

頁表是最受歡迎的機制，作業系統透過它為每個行程提供自己的私有位址空間和記憶體。頁表決定記憶體位址的含義以及可以存取實體記憶體的哪些部分。它們允許 xv6 隔離不同進程的位址空間並將它們重複使用到單一實體記憶體上。頁表是一種流行的設計，因為它們提供了一定程度的間接性，允許作業系統執行許多技巧。 Xv6 執行一些技巧：在多個位址空間中映射相同的記憶體（彈翻床頁面），並使用未映射的頁面保護核心和使用者堆疊。本章的其餘部分解釋了 RISC-V 硬體提供的頁表以及 xv6 如何使用它們。

### 3.1 Paging hardware

提醒一下，RISC-V 指令（使用者和核心）操作虛擬位址。機器的 RAM（或實體記憶體）透過實體位址進行索引。 RISC-V 頁表硬體透過將每個虛擬位址對應到實體位址來連接這兩種位址。 xv6運行在Sv39 RISC-V上，這意味著只使用64位元虛擬位址的底部39位元；不使用前 25 位。在此 Sv39 配置中，RISC-V 頁表在邏輯上是 227 (134,217,728) 個頁表條目 (PTE) 的陣列。每個 PTE 包含一個 44 位元實體頁號 (PPN) 和一些標誌。分頁硬體透過使用39位元中的高27位元索引頁表來找到PTE，並產生一個56位元實體位址，其高44位元來自PTE中的PPN，其低位元實體位址轉換為虛擬位址。 12 位。圖 3.1 使用頁表的邏輯視圖顯示了此過程，將其作為簡單的 PTE 陣列（有關更完整的故事，請參見圖 3.2）。頁表使作業系統能夠以 4096 (212) 位元組對齊區塊的粒度控制虛擬到實體位址轉換。這樣的區塊稱為頁面。在 Sv39 RISC-V 中，虛擬位址的前 25 位元不用於轉換。實體位址也有成長的空間：PTE 格式中有空間讓實體頁號再成長 10 位元。 RISC-V 的設計者根據技術預測選擇了這些數字。 239 位元組是 512 GB，這應該足以運行應用程式的位址空間

Virtual address


Physical Address


12
Offset


12


PPN Flags


0


1


10


Page table


27
EXT


(^44) 2^27 44 Index 25 64 56 圖 3.1：RISC-V 虛擬和實體位址，有簡化的邏輯頁表。在 RISC-V 計算機上。 256 的實體記憶體空間足以在不久的將來容納許多 I/O 裝置和 RAM 晶片。如果需要更多，RISC-V 設計人員已經定義了具有 48 位元虛擬位址的 Sv48 \[3\]。如圖 3.2 所示，RISC-V CPU 透過三個步驟將虛擬位址轉換為實體位址。頁表作為三層樹儲存在實體記憶體中。樹的根是一個 4096 位元組的頁表頁面，包含 512 個 PTE，其中包含樹的下一層頁表頁面的實體位址。每個頁面都包含樹中最終層級的 512 個 PTE。分頁硬體使用 27 位元中的前 9 位元來選擇根頁表頁中的 PTE，中間 9 位元來選擇樹的下一層頁表頁中的 PTE，最後 9 位元來選擇最終的 PTE。 （在 Sv48 RISC-V 中，頁表有四級，虛擬位址索引的第 39 到 47 位元進入頂層。）如果轉換位址所需的三個 PTE 中的任何一個不存在，則分頁硬體會引發一個頁面-fault 異常，由核心來處理異常（請參閱第4 章）。與圖 3.1 的單層設計相比，圖 3.2 的三層結構允許以節省記憶體的方式記錄 PTE。在大範圍虛擬位址沒有對應的常見情況下，三級結構可以省略整個頁目錄。例如，如果應用程式僅使用從位址 0 開始的幾個頁，則頂級頁目錄的 1 到 511 項無效，且核心不必為 511 中間頁目錄指派這些頁。 此外，核心也不必為那些 511 個中間頁目錄的底層頁目錄分配頁。因此，在本例中，三級設計為中間頁目錄節省了 511 頁，為底層頁目錄節省了 511 × 512 頁。儘管 CPU 在執行載入或儲存指令時會遍歷硬體中的三級結構，但三級結構的潛在缺點是 CPU 必須從記憶體載入三個 PTE 才能執行載入/儲存中虛擬位址的轉換指向實體位址的指令。為了避免從實體記憶體載入 PTE 的成本，RISC-V CPU 將頁表條目快取在轉換後備緩衝區 (TLB) 中。

Physical Page Number


6
A


543
U


2
W


1
V


63 8910 07


V
R
W
X
U
AD


*   Valid
*   可讀
*   Writable
*   Executable
*   User
*   Accessed
*   髒（頁目錄為 0）

Virtual address Physical Address
9 12
L1 L0 Offset


12
PPN Offset


PPN Flags


0


1


10


Page Directory


satp


L2


PPN Flags


0


1


44 10


Page Directory


PPN Flags


0


1


511


10


Page Directory


9 9
EXT


9


511
511


44


44


44


D GU X R


A - Accessed
-G - Global


RSW


Reserved for supervisor software


53
Reserved


Figure 3.2: RISC-V address translation details.


每個 PTE 都包含標誌位，這些標誌位告訴分頁硬體如何允許使用關聯的虛擬位址。允許指令讀取頁面。 PTE\_U控制是否允許使用者態指令存取該頁面；如果未設定PTE\_U，則PTE只能在supervisor模式下使用。圖 3.2 顯示了它是如何運作的。標誌和所有其他頁面硬體相關的結構在（kernel/riscv.h）中定義

為了告訴CPU使用頁表，核心必須將根頁表頁的實體位址寫入satp暫存器。 CPU將使用其自己的satp指向的頁表來翻譯後續指令產生的所有位址。每個CPU都有自己的satps，因此不同的CPU可以運行不同的進程，每個進程都有一個由自己的頁表描述的私有位址空間。

從核心的角度來看，頁表是儲存在記憶體中的數據，核心使用程式碼建立和修改頁表，就像您在任何樹形資料結構中看到的那樣。

關於本書中使用的術語的一些註釋。實體記憶體的一個位元組有一個位址，稱為物理位址。解引用位址（例如載入、儲存、跳躍和函數呼叫）的指令僅使用虛擬位址，分頁硬體將其轉換為實體位址，然後傳送到 RAM 硬體以讀取或寫入儲存。位址空間是給定頁表中有效的虛擬位址集；

每個xv6行程都有一個單獨的使用者位址空間，xv6核心也有自己的位址空間。表並使用它們來實現隔離等目標相關的技術。

0


Trampoline


Unused


Unused


Kstack 0 Unused


Guard page


Kstack 1


Guard page


0x1000
0


R-X


Virtual Addresses


CLINT


Kernel text


boot ROM


2^56-1 Physical Addresses


Unused
and other I/O devices


0x02000000


0x0C000000 PLIC

UART0


VIRTIO disk 0x10000000

0x10001000

KERNBASE
(0x80000000)


PHYSTOP
(0x88000000)


MAXVA


Kernel data


R-X


RW-


Physical memory (RAM)


VIRTIO disk
UART0


PLIC


RW-
RW-


RW-


Free memory RW-


---


---
RW-
RW-


圖3.3：左邊是xv6的核心位址空間。右側是 xv6 期望看到的 RISC-V 實體位址空間。

### 3.2 Kernel address space

Xv6為每個行程維護一個頁表，描述每個行程的使用者位址空間，以及一個描述核心位址空間的頁表。核心配置其位址空間的佈局，使其能夠以可預測的方式存取實體記憶體和各種硬體資源。

虛擬地址。圖 3.3 顯示了該佈局如何將核心虛擬位址對應到實體位址。檔案(kernel/memlayout.h)宣告了xv6的核心記憶體佈局的常數。 QEMU 模擬一台包含 RAM（實體記憶體）的計算機，從實體位址 0x80000000 開始，一直持續到至少 0x88000000，xv6 稱之為 PHYSTOP。 QEMU 模擬還包括磁碟介面等 I/O 設備。 QEMU 將裝置介面公開為位於實體位址空間中 0x80000000 以下的記憶體對映控制暫存器。核心可以透過讀取/寫入這些特殊的實體位址來與設備互動；此類讀取和寫入與設備硬體而不是 RAM 進行通訊。第 4 章解釋了 xv6 如何與裝置互動。核心使用“直接映射”獲取 RAM 和內存映射設備寄存器；即，將資源對應到與實體位址相同的虛擬位址。例如，核心本身在虛擬位址空間和實體記憶體中都位於KERNBASE=0x80000000。直接映射簡化了讀取或寫入物理記憶體的核心程式碼。例如，當 fork 為子進程分配使用者記憶體時，分配器會傳回該記憶體的實體位址；當將父進程的使用者記憶體複製到子進程時，會直接將該位址作為虛擬位址。有幾個未直接映射的核心虛擬位址：

*   彈跳床頁面。它映射在虛擬位址空間的頂部；使用者頁表具有相同的對應。第 4 章討論了彈翻床頁的作用，但我們在這裡看到了頁表的一個有趣的用例；實體頁（保存彈翻床程式碼）在核心的虛擬位址空間中映射兩次：一次在虛擬位址空間的頂部，一次是直接映射。
*   內核堆疊頁。每個進程都有自己的核心堆疊，該堆疊被映射到高位，以便在其下方 xv6 可以留下未映射的保護頁面。保護頁的PTE無效（即PTE\_Vis未設定），因此如果核心溢位核心堆疊，則可能會導致異常且核心將出現恐慌。如果沒有保護頁，溢出的堆疊將覆蓋其他內核內存，從而導致不正確的操作。恐慌崩潰是更好的選擇。雖然核心透過高記憶體映射使用其堆疊，但核心也可以透過直接映射位址存取它們。替代設計可能只有直接映射，並在直接映射位址處使用堆疊。然而，在這種安排中，提供保護頁將涉及取消虛擬地址的映射，否則這些虛擬地址將引用物理內存，從而難以使用。核心使用權限 PTE\_R 和 PTE\_X 來映射彈跳床和核心文字的頁面。核心從這些頁面讀取並執行指令。核心將其他頁面映射到權限PTE\_RandPTE\_W，以便它可以讀寫這些頁面中的記憶體。保護頁的對應無效。

### 3.3 程式碼：建立位址空間

大多數用於操作位址空間和頁表的 xv6 程式碼都位於 invm.c(kernel/vm.c:1) 中。中心資料結構是pagetable\_t，它實際上是一個指向RISC-V的指針

根頁表頁； apagetable\_t 可以是核心頁表，也可以是每個行程頁表之一。核心功能是walk（它尋找虛擬位址的PTE）和mappages（它為新映射安裝PTE）。以kvm開頭的函數操作內核頁表；以uvm開頭的函數操作使用者頁表；其他函數用於將資料複製到作為系統呼叫參數提供的使用者虛擬地址；它們是invm.c，因為它們需要明確轉換這些位址才能找到對應的實體記憶體。

在啟動序列的早期，main 呼叫 skvminit(kernel/vm.c:54) 使用 kvmmake(kernel/vm.c:20) 建立核心頁表。該呼叫發生在 xv6 在 RISC-V 上啟用分頁之前，因此位址直接引用實體記憶體。然後它呼叫kvmmap來安裝核心所需的翻譯。翻譯包括內核的指令和資料、直到 PHYSTOP 的物理記憶體以及實際上是裝置的記憶體範圍。它呼叫 kvmmap 將每個堆疊映射到 KSTACK 產生的虛擬位址，這為無效的堆疊保護頁面留出了空間。

kvmmap(kernel/vm.c:132)呼叫mappages(kernel/vm.c:144)，它將一系列虛擬位址到對應實體位址範圍的對應安裝到頁表中。它以頁面間隔為範圍內的每個虛擬位址單獨執行此操作。對於要對應的每個虛擬位址，mappages 呼叫 walk 來尋找該位址的 PTE 位址。然後，它初始化 PTE 以保存相關的實體頁號、所需的權限（PTE\_W、PTE\_X 和/或 PTE\_R）以及 PTE\_V 以將 PTE 標記為有效 (kernel/vm.c:165)。

walk(kernel/vm.c:86) 模仿 RISC-V 分頁硬件，因為它在 PTE 中找到虛擬地址（參見圖 3.2）。到相關頁目錄頁的網址。在每個級別，它都會找到下一級頁面目錄頁面的 PTE，或最終頁面 (kernel/vm.c:92) 的 PTE。如果一級或二級頁目錄頁中的PTE無效，則表示所需的目錄頁尚未分配；如果設定了allocargument，則walk分配一個新的頁表頁並將其實體位址放入PTE中。它會傳回樹中最底層的 PTE 的位址 (kernel/vm.c:102)。

上面的程式碼依賴直接映射到核心虛擬位址空間的實體記憶體。例如，aswalkdescends頁表的級別，它從PTE（kernel/vm.c:94）中提取下一級頁表的（物理）地址，然後使用該地址作為虛擬地址來獲取PTE 處於下一個級別（kernel/vm.c:92）。

main呼叫skvminithart(kernel/vm.c:62)來安裝核心頁表。它將根頁表頁的實體位址寫入暫存器satp。此後，CPU 將使用核心頁表轉換位址。由於核心使用直接映射，因此下一指令的當前虛擬位址將映射到正確的實體記憶體位址。

每個 RISC-V CPU 將頁表條目快取在翻譯後備緩衝區 (TLB) 中，當 xv6 更改頁表時，它必須告訴 CPU 使對應快取的 TLB 條目失效。如果沒有，那麼在稍後的某個時刻，TLB 可能會使用舊的快取映射，指向同時已分配給另一個進程的物理頁，因此，進程可能能夠在其他進程的記憶體上亂塗亂畫。 RISC-V 有一個

instructionsfence.vmathat刷新當前CPU的TLB。 Xv6在重新載入satp暫存器後執行ssfence.vmain kvminithart，並在返回使用者空間之前切換到使用者頁表的trampoline程式碼中（kernel/trampoline.S:89）。還需要在更改 satp 之前發出fence.vma，以便等待所有未完成的載入和儲存完成。此等待可確保先前對頁表的更新已完成，並確保先前的載入和儲存使用舊頁表，而不是新頁表。為了避免刷新整個 TLB，RISC-V CPU 可能支援位址空間標識符 (ASID) \[3\]。然後，核心可以僅刷新特定位址空間的 TLB 條目。 Xv6 沒有使用此功能。

### 3.4 實體記憶體分配

核心必須在運行時為頁表、使用者記憶體、核心堆疊和管道緩衝區分配和釋放實體記憶體。 Xv6 使用核心末端和 PHYSTOP 之間的實體記憶體進行執行時間分配。它一次分配和釋放整個 4096 位元組頁面。它透過將連結清單穿入頁面本身來追蹤哪些頁面是空閒的。分配包括從鍊錶中刪除頁面；釋放包括將釋放的頁面新增到清單中。

### 3.5 代碼：實體記憶體分配器

分配器位於 inkalloc.c(kernel/kalloc.c:1)。分配器的資料結構是可用於分配的實體記憶體頁的空閒列表。每個空閒頁面的列表元素都是一個struct run(kernel/kalloc.c:17)。分配器從哪裡取得記憶體來保存該資料結構？它將每個空閒頁面的運行結構儲存在空閒頁面本身中，因為那裡沒有儲存任何其他內容。空閒清單受自旋鎖保護(kernel/kalloc.c:21-24)。列表和鎖定包裝在一個結構中，以明確鎖定保護結構中的字段。現在，忽略鎖以及對 acquire 和release 的呼叫；第 6 章將詳細研究鎖定。函數main呼叫skinit來初始化分配器(kernel/kalloc.c:27)。 Xv6 應該透過解析硬體提供的配置資訊來確定有多少實體記憶體可用。相反，xv6 假設機器有 128 MB 的 RAM。 PTE 只能引用在 4096 位元組邊界（是 4096 的倍數）上對齊的物理位址，因此 freerange 使用 PGROUNDUP 來確保它只釋放對齊的實體位址。分配器啟動時沒有記憶體；這些調用 tokfree 給它一些管理。分配器有時將位址視為整數以便對它們執行算術（例如，遍歷自由範圍中的所有頁面），有時使用位址作為讀寫記憶體的指標（例如，操縱儲存在每個頁面中的運行結構）；位址的雙重使用是分配器代碼充滿 C 類型轉換的主要原因。

函數kfree(kernel/kalloc.c:47) 首先將要釋放的記憶體中的每個位元組設為值1。舊的有效內容；希望這會導致這樣的程式碼更快崩潰。然後kfree將該頁面添加到空閒列表中：它將spato轉換為指向struct run的指針，在r->next中記錄空閒列表的舊開始，並將空閒列表設置為等於tor.kallocremoves並返回空閒列表中的第一個元素。

### 3.6 Process address space

每個進程都有自己的頁表，當xv6在進程之間切換時，它也會改變頁表。圖 3.4 比圖 2.3 更詳細地顯示了進程的位址空間。進程的使用者記憶體從虛擬位址 0 開始，可以成長到 MAXVA(kernel/riscv.h:375)，原則上允許進程尋址 256 GB 記憶體。進程的位址空間由包含程式文字的頁面（xv6 與權限 PTE\_R、PTE\_X 和 PTE\_U 映射）、包含程式預先初始化資料的頁面、堆疊頁面和堆疊頁面組成。 Xv6 使用權限 PTE\_R、PTE\_W 和 PTE\_U 來映射資料、堆疊和堆疊。在使用者位址空間內使用權限是強化使用者程序的常用技術。如果文字使用 PTE\_W 映射，則進程可能會意外修改自己的程式；例如，程式錯誤可能會導致程式寫入空指針，修改位址 0 處的指令，然後繼續運行，這可能會造成更大的破壞。為了立即偵測此類錯誤，xv6 會對應不帶 PTE\_W 的文字；如果程式意外地嘗試儲存到位址 0，硬體將拒絕執行儲存並引發頁面錯誤（請參閱第 4.6 節）。然後核心終止該進程並列印出一條資訊性訊息，以便開發人員可以追蹤問題。類似地，透過映射不帶 PTE\_X 的數據，使用者程式不會意外跳到程式資料中的某個位址並在該位址開始執行。在現實世界中，透過仔細設定權限來強化流程也有助於防禦安全攻擊。對手可能會向程式提供精心構建的輸入（例如，一個 Web 伺服器）觸發程式中的錯誤，希望將該錯誤轉化為漏洞利用 \[14\]。仔細設定權限和其他技術（例如隨機化使用者位址空間的佈局）會使此類攻擊變得更加困難。堆疊是一個單頁，並顯示由 exec 建立的初始內容。包含命令列參數的字串以及指向它們的指標數組位於堆疊的最頂部。就在該值的下面，如果函數 main(argc,argv) 剛剛被調用，則允許程式在 mainas 處啟動。為了偵測使用者堆疊溢位分配的堆疊內存，xv6 透過清除 PTE\_Uflag 在堆疊正下方放置一個不可存取的保護頁。如果使用者堆疊溢位且進程嘗試使用堆疊下方的位址，則硬體將產生頁面錯誤異常，因為在使用者模式下執行的程式無法存取保護頁。現實世界的作業系統可能會在使用者堆疊溢位時自動為其分配更多記憶體。當進程向 xv6 請求更多使用者記憶體時，xv6 會增加進程的堆。xv6首先使用

Figure 3.4: A process’s user address space, with its initial stack.


kallocto 分配物理頁。然後，它將 PTE 新增到指向新實體頁的進程頁表中。 Xv6 在這些 PTE 中設定 PTE\_W、PTE\_R、PTE\_U 和 PTE\_V 標誌。大多數進程並不使用整個使用者位址空間； xv6 在未使用的 PTE 中保留 PTE\_Vclear。

我們在這裡看到一些使用頁表的很好的例子。首先，不同進程的頁表將使用者位址轉換為不同的實體記憶體頁，因此每個行程都擁有私有的使用者記憶體。其次，每個進程將其記憶體視為具有從零開始的連續虛擬位址，而進程的實體記憶體可以是不連續的。第三，核心將帶有彈跳床程式碼的頁面對應到使用者位址空間的頂部（沒有PTE\_U），因此單一實體記憶體頁面出現在所有位址空間中，但只能由核心使用。

### 3.7 Code: sbrk

sbrki 是進程收縮或增加其記憶體的系統呼叫。系統呼叫由函數growproc(kernel/proc.c:260)實作。 mappages將PTE加入到使用者頁表中。 uvmdealloc呼叫suvmunmap(kernel/vm.c:178)，它使用walk來尋找PTE並使用kfree來釋放它們所引用的實體記憶體。 xv6使用進程的頁表不僅僅是為了告訴硬體如何映射使用者虛擬位址，

而且也是分配給該進程的實體記憶體頁的唯一記錄。這就是釋放使用者記憶體（inuvmunmap）需要檢查使用者頁表的原因。

### 3.8 Code: exec

exec 是一個系統調用，它用從檔案（稱為二進位檔案或可執行檔）讀取的資料取代進程的使用者位址空間。二進位檔案通常是編譯器和連結器的輸出，並儲存機器指令和程式資料。 1 章中進行了解釋8. 然後，它讀取 ELF 標頭。 Xv6 二進位檔案採用廣泛使用的 ELF 格式，在 (kernel/elf.h) 中定義。 ELF 二進位檔案由 ELF 標頭 struct elfhdr(kernel/elf.h:6) 和後面的一系列程式段標頭 struct proghdr(kernel/elf.h:25) 組成。每個progvhdr描述了必須載入到記憶體中的應用程式的一部分； xv6 程式有兩個程式節頭：一個用於指令，一個用於資料。第一步是快速檢查該檔案是否可能包含 ELF 二進位。 ELF 二進位檔案以四位元組「幻數」0x7F、'E'、'L'、'F' 或 ELF\_MAGIC(kernel/elf.h:3) 開頭。如果 ELF 標頭具有正確的幻數，則假定二進位檔案格式良好。 exec使用proc\_pagetable(kernel/exec.c:49)分配一個沒有使用者映射的新頁表，使用uvmalloc(kernel/exec.c:65)為每個ELF段分配內存，並使用loadseg(kernel/exec.c )將每個段落載入到記憶體中:10).loadseguseswalkaddr 尋找分配的記憶體的實體位址，在該位址寫入 ELF 段的每個頁面，並從檔案中讀取。 /init（用exec建立的第一個使用者程式）的程式節頭如下所示：

objdump -p user/\_init
======================

user/\_init: file format elf64-little

程式頭：0x70000003關閉0x0000000000006bb0 vaddr 0x000000000000000 paddr 0x000000000000000002\*\* 0個檔案 0x000000000000000002\*\* 0個檔案 0xmsz 0x0000000000000000 標誌 r-- 載入關閉 0x000000000001000000000 標誌 r-- 載入關閉 0x0000000000001000 memsz 0x0000000000001000 標誌 rx 載入關閉 0x00000000000000000001000 vaddr 0x00000000000100000000000000 0x00000000000 memsz 0x0000000000000030 標誌 rw-堆疊關閉 0x0000000000000000 vaddr 0x000000000000000000000000000 memsz 0x0000000000000000 標誌 rw-

我們看到文字段應該從檔案偏移量 0x1000 處的內容載入到記憶體中虛擬位址 0x0 處（沒有寫入權限）。我們也看到資料應該載入到位址 0x1000，該位址位於頁邊界，並且沒有可執行權限。

程式節頭的filesz可能小於memsz，這表示它們之間的間隙應該用零填充（對於C全域變數）而不是從檔案讀取。對於/init，datafilesz為0x10字節，memsz為0x30字節，因此uvmallocal分配了足夠的實體記憶體來容納0x30字節，但從檔案/init僅讀取0x10位元組。現在exec分配並初始化用戶堆疊。它只分配一個堆疊頁。它將一個空指標放置在傳遞給 main 的 argvlist 的末尾。 argc 和argva 的值透過系統呼叫返迴路徑傳遞給main：argcis 透過系統呼叫返回值傳遞，該返回值位於a0 中，而argvis 透過進程陷阱幀的a1 條目傳遞。 exec 將一個無法存取的頁面放置在堆疊頁面的正下方，因此嘗試使用多個頁面的程式將會出錯。這個不可訪問的頁面還允許 exec 處理太大的參數；在這種情況下，執行將參數複製到堆疊的copyout(kernel/vm.c:359)函數將注意到目標頁面不可訪問，並將傳回-1。在準備新的記憶體映像的過程中，ifexec偵測到錯誤，如無效的程式段，它跳到labelbad，釋放新的映像，並傳回-1。映像。唯一的錯誤情況發生在建立映像期間。映像完成後，exec 可以提交新頁表 (kernel/exec.c:125) 並釋放舊頁表 (kernel/exec.c:129)。 exec 將 ELF 檔案中的位元組載入到記憶體中由 ELF 檔案指定的位址處。使用者或進程可以將他們想要的任何位址放入 ELF 檔案中。因此執行是有風險的，因為 ELF 檔案中的位址可能無意或有意地引用核心。粗心的核心所造成的後果可能從崩潰到惡意破壞核心隔離機制（即安全漏洞）。 Xv6 執行許多檢查來避免這些風險。例如，if(ph.vaddr + ph.memsz < ph.vaddr) 檢查總和是否溢出 64 位元整數。危險在於，使用者可以使用指向使用者選擇的地址的 aph.vaddr 和足夠大的 ph.memsz 來建立 ELF 二進位文件，以致總和溢出到 0x1000，這看起來像是一個有效值。在舊版的 xv6 中，使用者位址空間也包含核心（但在使用者模式下不可讀寫），使用者可以選擇與核心記憶體相對應的位址，從而將資料從 ELF 二進位檔案複製到核心中。在 xv6 的 RISC-V 版本中這不會發生，因為核心有自己獨立的頁表； Loadseg載入到進程的頁表中，而不是核心的頁表。核心開發人員很容易忽略關鍵的檢查，並且現實世界的核心長期以來一直存在缺少檢查的情況，用戶程式可以利用這些檢查的缺失來獲取核心權限。 xv6 很可能沒有完成驗證提供給核心的使用者層級資料的完整工作，惡意使用者程式可能能夠利用這些資料來規避 xv6 的隔離。

### 3.9 Real world

與大多數作業系統一樣，xv6 使用分頁硬體進行記憶體保護和映射。大多數作業系統透過組合分頁來比 xv6 更複雜地使用分頁

和頁錯誤異常，我們將在第 4 章中討論。這適用於 QEMU，但在實際硬體上，這並不是一個好主意；真實的硬體將 RAM 和裝置放置在不可預測的實體位址處，因此（例如）0x80000000 處可能沒有 RAM，而 xv6 期望能夠在該位置儲存核心。更嚴格的核心設計利用頁表將任意硬體實體記憶體佈局轉換為可預測的核心虛擬位址佈局。 RISC-V 支援實體位址層級的保護，但 xv6 不使用該功能。在具有大量記憶體的機器上，使用 RISC-V 對「超級頁面」的支援可能很有意義。當實體記憶體較小時，小頁面有意義，以允許以細粒度分配和頁出到磁碟。例如，如果一個程式僅使用 8 KB 內存，則為其提供整個 4 MB 超級頁面的實體內存是一種浪費。較大的頁面對於具有大量 RAM 的電腦來說是有意義的，並且可以減少頁表操作的開銷。 xv6 核心缺乏可以為小物件提供記憶體的類似 amalloc 的分配器，從而阻止核心使用需要動態分配的複雜資料結構。更複雜的核心可能會分配許多不同大小的小塊，而不是（如 xv6 中）僅 4096 位元組塊；真正的核心分配器需要處理小型分配和大型分配。記憶體分配是一個長期的熱門話題，基本問題是有效利用有限記憶體並為未知的未來請求做好準備\[9\]。 如今，人們更關心速度而不是空間效率。

### 3.10 Exercises

1. 解析 RISC-V 的裝置樹以尋找電腦擁有的實體記憶體量。
2. 編寫一個使用者程序，透過呼叫 sbrk(1) 將其位址空間增加一個位元組。執行程式並在呼叫 tosbrk 之前和呼叫 tosbrk 之後調查程式的頁表。內核分配了多少空間？新記憶體的 PTE 包含什麼？
3. 修改 xv6 以對核心使用超級頁面。
4. exec 的 Unix 實作傳統上包含對 shell 腳本的特殊處理。如果要執行的檔案以文字#! 開頭，則第一行將被視為要執行以解釋該檔案的程式。例如，如果呼叫exec執行myprog arg1且myprog的第一行是#!/interp，則exec運行/interp與命令列/interp myprog arg1。在 xv6 中實現對此約定的支援。
5. 為核心實現位址空間佈局隨機化。

第4章
===

陷阱和系統調用
=======

共有三種事件導致 CPU 擱置普通指令執行並強制將控制權轉移到處理該事件的特殊程式碼。一種情況是系統調用，即用戶程式執行 ecall 指令來要求核心為其執行某些操作。另一種情況是異常：指令（使用者或核心）執行非法操作，例如除以零或使用無效的虛擬位址。第三種情況是設備中斷，當設備發出需要注意的訊號時，例如磁碟硬體完成讀取或寫入請求時。

本書使用「trapas」作為這些情況的通用術語。通常，陷阱發生時正在執行的任何程式碼稍後都需要恢復，並且不需要知道發生了任何特殊情況。也就是說，我們常常希望陷阱是透明的；這對於設備中斷尤其重要，而中斷的程式碼通常不希望發生這種情況。通常的順序是陷阱強制將控制權轉移到核心中；內核保存暫存器和其他狀態，以便可以恢復執行；核心執行適當的處理程式碼（例如，系統呼叫實作或裝置驅動程式）；內核恢復保存的狀態並從陷阱返回；原始碼從中斷處繼續。

xv6 處理內核中的所有陷阱；陷阱不會傳遞給使用者程式碼。對於系統呼叫來說，處理核心中的陷阱是很自然的。這對於中斷來說是有意義的，因為隔離要求僅允許核心使用設備，並且因為核心是在多個進程之間共享設備的便捷機制。它對於異常也有意義，因為 xv6 透過殺死有問題的程式來回應用戶空間的所有異常。

Xv6 陷阱處理分四個階段進行：RISC-V CPU 採取的硬體操作、為核心 C 程式碼做好準備的一些彙編指令、決定如何處理陷阱的 C 函數以及系統呼叫或裝置驅動程式服務常規。雖然三種陷阱類型之間的共通性表明核心可以使用單一程式碼路徑處理所有陷阱，但事實證明，對於兩種不同的情況使用單獨的程式碼會很方便：來自用戶空間的陷阱和來自核心空間的陷阱。處理陷阱的核心程式碼（彙編程式或 C）通常稱為處理程序；第一個處理程序指令通常用組譯器（而不是 C）編寫，有時稱為向量。

### 4.1 RISC-V trap machinery

每個 RISC-V CPU 都有一組控制暫存器，核心寫入這些控制暫存器來告訴 CPU 如何處理陷阱，而核心可以讀取這些暫存器來找出已發生的陷阱。 RISC-V 文件包含完整的故事 \[3\].riscv.h(kernel/riscv.h:1) 包含 xv6 使用的定義。以下是最重要寄存器的概述：

*   stvec：核心將其陷阱處理程序的位址寫入此處； RISC-V 跳到地址 instvec 來處理陷阱。
*   sepc：當陷阱發生時，RISC-V 將程式計數器保存在這裡（因為 pcis 隨後會被值 instvec 覆蓋）。 Thesret（從陷阱返回）指令將sepc複製到thepc。核心可以編寫sepc來控制ret去向。
*   原因：RISC-V 在此放置一個數字來描述陷阱的原因。
*   sscratch：陷阱處理程序程式碼使用 sscratch 來幫助避免在保存使用者暫存器之前覆蓋它們。
*   sstatus：sstatus 中的 SIE 位元控制是否允許設備中斷。如果核心清除 SIE，RISC-V 將推遲設備中斷，直到核心設定 SIE。 SPP 位元指示陷阱是來自使用者模式還是管理模式，並控制返回的模式。

上述暫存器與管理模式下處理的陷阱相關，且不能在使用者模式下讀取或寫入。多核心晶片上的每個 CPU 都有自己的一組暫存器，並且在任何給定時間都可能有多個 CPU 正在處理陷阱。當需要強制陷阱時，RISC-V 硬體會對所有陷阱類型執行以下操作：

1. 如果陷阱是裝置中斷，且 sstatusSIE 位元清零，則不要執行以下任何操作。
2. 透過清除狀態中的 SIE 位元來停用中斷。
3. Copy thepctosepc.
4. 將目前模式（使用者或管理者）儲存在 SPP 位元 insstatus 中。
5. Setscauseto reflect the trap’s cause.
6. Set the mode to supervisor.
7. Copystvecto thepc.
8. Start executing at the newpc.

請注意，CPU 不會切換到核心頁表，不會切換到核心中的堆疊，並且不會保存除 thepc 之外的任何暫存器。內核軟體必須執行這些任務。 CPU 在陷阱期間執行最少工作的原因之一是為軟體提供靈活性。例如，某些作業系統在某些情況下省略頁表切換以提高陷阱效能。值得思考是否可以省略上面列出的任何步驟，也許是為了尋找更快的陷阱。儘管在某些情況下可以採用更簡單的順序，但一般來說，省略許多步驟是很危險的。例如，假設 CPU 沒有切換程式計數器。然後，來自使用者空間的陷阱可以切換到管理員模式，同時仍執行使用者指令。這些使用者指令可能會破壞使用者/核心隔離，例如透過修改 satp 暫存器以指向允許存取所有實體記憶體的頁表。因此，CPU 切換到核心指定的指令位址（即stvec）非常重要。

### 4.2 使用者空間的陷阱

Xv6 對陷阱的處理方式有所不同，取決於陷阱是在核心中還是在使用者程式碼中執行時發生。這是來自使用者程式碼的陷阱的故事； 4.5 節描述了來自核心程式碼的陷阱。如果使用者程式進行系統呼叫（ecall 指令）、執行非法操作或裝置中斷，則在使用者空間執行時可能會發生陷阱。來自使用者空間的陷阱的高階路徑是uservec(kernel/trampoline.S:22)，然後是usertrap(kernel/trap.c:37)；回傳時，先是usertrapret(kernel/trap.c:90)，然後是userret(kernel/trampoline.S:101)。 xv6 陷阱處理設計的一個主要限制是 RISC-V 硬體在強制陷阱時不會切換頁表。這意味著 stvecm 中的陷阱處理程序地址必須在使用者頁表中具有有效的映射，因為這是陷阱處理程式碼開始執行時有效的頁表。此外，xv6的trap處理程式碼需要切換到核心頁表；為了能夠在該切換後繼續執行，內核頁表也必須具有指向 bystvec 的處理程序的對應。 Xv6 使用 atrampolinepage 滿足這些要求。 Trampoline 頁麵包含 uservec，stvec 指向的 xv6 陷阱處理程式碼。彈翻床頁面對應到每個進程的頁表中的位址TRAMPOLINE，該位址位於虛擬位址空間的頂部，因此它將位於程式本身使用的記憶體之上。 Trampoline 頁也對應到核心頁表中的位址 TRAMPOLINE。參見圖 2.3 和圖 3.3。由於彈翻床頁面會對應到使用者頁表中，因此陷阱可以在管理模式下開始執行。 由於彈翻床頁對應到核心位址空間中的相同位址，因此陷阱處理程序在切換到核心頁表後可以繼續執行。 uservectrap 處理程序的程式碼是intrampoline.S(kernel/trampoline.S:22)。當 uservecstarts 時，所有 32 個暫存器都包含中斷的使用者程式碼所擁有的值。這 32 個值需要保存在記憶體中的某個位置，以便稍後核心可以在返回使用者空間之前恢復它們。儲存到記憶體需要使用暫存器來保存位址，但目前還沒有可用的通用暫存器！幸運的是，RISC-V 以暫存暫存器的形式提供了幫助。uservecsavesa0 開頭的 csrwin 指令

刮擦。現在使用者有一個暫存器（a0）可以使用。

uservec 的下一個任務是保存 32 個使用者暫存器。核心為每個程序分配一頁記憶體用於 atrapframestruct 結構（除其他外），該結構有空間保存 32 個使用者暫存器 (kernel/proc.h:43)。因為satp仍然引用使用者頁表，所以使用者需要將trapframe對應到使用者位址空間。 Xv6將每個進程的陷阱幀對應到該進程的使用者頁表中的虛擬位址TRAPFRAME；TRAPFRAME就在TRAMPOLINE之下。進程的 sp->trapframe 也指向 trapframe，儘管位於其物理位址，因此內核可以透過內核頁表使用它。

因此uservec將位址TRAPFRAME載入到oa0中，並在那裡保存所有使用者暫存器，包括使用者的sa0，從sscratch讀回。

trapframe包含目前進程的核心堆疊的位址、目前CPU的hartid、usertrap函數的位址、核心頁表的位址。

usertrapi 的工作是確定陷阱的原因、處理它並返回（kernel/- trap.c:37）。它首先更改 stvec，以便核心中的陷阱將由 kernelvec 而不是 uservec 處理。它保存了這些pc寄存器（保存的用戶程式計數器），因為用戶陷阱可能會切換到另一個進程的內核線程，而該進程可能會返回到用戶空間，在這個過程中它會修改sepc。如果陷阱是系統調用，則使用者trap調用syscall來處理它；如果設備中斷，devintr；否則，這是一個異常，核心會終止出錯的進程。系統呼叫路徑將四個新增至已儲存的使用者程式計數器，因為 RISC-V 在系統呼叫的情況下使程式指標指向 ecall 指令，但使用者程式碼需要在後續指令處恢復執行。在退出時，usertrap 檢查程序是否已終止或是否應讓出 CPU（如果此陷阱是計時器中斷）。

傳回使用者空間的第一步是呼叫usertrapret(kernel/trap.c:90)。此函數設定 RISC-V 控制暫存器，為來自使用者空間的未來陷阱做好準備：設定 stvectouservecan 並準備使用者所依賴的陷阱幀欄位。最後，usertrapret會在使用者頁表和核心頁表都對應的trampoline頁上呼叫userret；原因是userret中的組譯程式碼會切換頁表。

usertrapret 的呼叫 userret 將指標傳遞給行程的使用者頁表 ina0 (kernel/trampoline.S:101)。回想一下，使用者頁表映射了彈跳床頁和 TRAPFRAME，但沒有映射來自核心的其他內容。使用者頁表和核心頁表中相同虛擬位址的彈跳床頁映射允許 userret 在變更 satp 後繼續執行。從此時起，userret 唯一能使用的資料就是暫存器內容和trapframe 的內容。 。

### 4.3 Code: Calling system calls

第2章在itcode內結束。讓我們看看用戶呼叫如何進入核心中 exec 系統呼叫的實作。 initcode. 將execin 的參數替換為registersa0anda1，並將系統呼叫號碼放入a7。系統呼叫號碼與 syscalls 陣列（函數指標表）中的條目相符 (kernel/syscall.c:107)。 ecall 指令陷入核心並導致 uservec、usertrap、然後 syscall 執行，如我們上面所見。 syscall(kernel/syscall.c:132) 從陷阱幀中保存的 7 中檢索系統呼叫號，並使用它來索引系統呼叫。對於第一個系統調用，a7包含SYS\_exec(kernel/syscall.h:8)，導致呼叫系統呼叫實作函式sys\_exec。當sys\_exec傳回時，syscall將其傳回值記錄在p->trapframe->a0中。這將導致原始用戶空間呼叫 exec() 傳回該值，因為 RISC-V 上的 C 呼叫約定將回傳值放在 a0 中。系統呼叫通常會傳回負數來指示錯誤，傳回零或正數來指示成功。如果系統呼叫號碼無效，則 syscall 會列印錯誤並傳回− 1。

### 4.4 代碼：系統呼叫參數

核心中的系統呼叫實作需要尋找使用者程式碼傳遞的參數。由於使用者程式碼呼叫系統呼叫包裝函數，因此參數最初位於 RISC-V C 呼叫約定放置它們的位置：暫存器中。內核陷阱程式碼將用戶寄存器保存到當前進程的陷阱幀，內核程式碼可以在其中找到它們。核心函數argint、argaddr和argfd從陷阱幀中檢索第一個系統呼叫參數作為整數、指標或檔案描述符。它們都會呼叫argraw來檢索適當的已儲存的使用者暫存器（kernel/syscall.c:34）。某些系統呼叫將指標作為參數傳遞，核心必須使用這些指標來讀取或寫入使用者記憶體。例如，exec 系統呼叫會向核心傳遞一個引用使用者空間中的字串參數的指標陣列。這些指示提出了兩個挑戰。首先，用戶程式可能有錯誤或惡意，並且可能向核心傳遞無效指標或旨在欺騙內核存取內核記憶體而不是用戶記憶體的指標。其次，xv6 核心頁表映射與使用者頁表映射不同，因此核心無法使用普通指令從使用者提供的位址載入或儲存。核心實現了安全地與用戶提供的位址之間傳輸資料的功能。 fetchstris 就是一個例子（kernel/syscall.c:25）。檔案系統呼叫（例如 execusefetchstr）從使用者空間檢索字串檔案名稱參數。 copyinstr(kernel/vm.c:415)從使用者頁表pagetable中的虛擬位址rcva複製最多maxbytes todst。由於頁表不是目前頁表，copyinstr 使用walkaddr（呼叫walk）在頁表中尋找srcva，產生實體位址pa0。 核心的頁表將所有實體 RAM 映射到等於 RAM 物理位址的虛擬位址。這允許copyinstr直接將字串位元組從pa0複製到dst。 walkaddr（核心/虛擬機器。c:109) 檢查使用者提供的虛擬位址是否為進程的一部分

使用者位址空間，因此程式無法欺騙核心讀取其他記憶體。類似的函數 copyout 將資料從核心複製到使用者提供的位址。

### 4.5 來自內核空間的陷阱

Xv6 處理來自核心程式碼的陷阱的方式與處理來自使用者程式碼的陷阱的方式不同。當進入核心時，使用者陷阱指向kernelvec處的彙編程式碼(kernel/kernelvec.S:12)。由於如果 xv6 已經在核心中，則 kernelvec 只能執行，因此 kernelvec 可以依賴設定為核心頁表的 satp 以及引用有效核心堆疊的堆疊指標。 kernelvecpu將所有32個暫存器放入堆疊中，稍後將從堆疊中恢復它們，以便中斷的內核程式碼可以不受干擾地恢復。 kernelvec 將暫存器保存在中斷的核心執行緒的堆疊上，這是有意義的，因為暫存器值屬於該執行緒。如果陷阱導致切換到不同的線程，這一點尤其重要——在這種情況下，陷阱實際上將從新線程的堆疊中返回，將被中斷線程保存的暫存器安全地保留在其堆疊上。儲存暫存器後，kernelvec跳到kerneltrap(kernel/trap.c:135)。它呼叫devintr(kernel/- trap.c:185)來檢查並處理前者。如果陷阱不是設備中斷，那麼它一定是異常，並且如果它發生在 xv6 核心中，則始終是致命錯誤；核心調用panic並停止執行。如果因為計時器中斷而呼叫kerneltrap，且行程的核心執行緒正在執行（而不是調度程式執行緒），則kerneltrap將呼叫sield以給其他執行緒執行的機會。在某些時候，其中一個線程將屈服，並讓我們的線程及其內核陷阱再次假定。第 7 章解釋了yield 中會發生什麼事。當kerneltrap的工作完成後，它需要返回到被陷阱中斷的任何程式碼。 因為yield可能會擾亂sep和先前的模式狀態，所以kerneltrap會在啟動時保存它們。現在它恢復這些控制暫存器並返回到kernelvec(kernel/kernelvec.S:38)。值得思考的是，如果核心陷阱因為計時器中斷而呼叫yield，陷阱回傳是如何發生的。當CPU從用戶空間進入核心時，xv6設定CPU的stvectokernelvec；你可以在usertrap(kernel/trap.c:29)看到這個。核心已開始執行但 stvec 仍設定為 uservec 時有一個時間窗口，並且在此窗口期間不會發生設備中斷至關重要。幸運的是，RISC-V 在開始捕獲陷阱時總是會停用中斷，並且 usertrap 在設定 stvec 之前不會再次啟用它們。

### 4.6 頁面錯誤異常

Xv6 對異常的回應相當無聊：如果使用者空間發生異常，核心就會殺死出錯的進程。如果內核中發生異常，內核就會發生恐慌。真實經營

系統通常會以更有趣的方式做出回應。

例如，許多核心使用頁面錯誤來實現寫入時複製 (COW) 分叉。為了解釋寫入時複製 fork，請考慮第 3 章中描述的 xv6 的 fork。 Xv6 實作了 fork withuvmcopy(kernel/vm.c:313)，它為子進程分配物理內存，並將父進程的內存複製到其中。如果孩子和父母可以共享父母的實體內存，那麼效率會更高。然而，直接實作此方法是行不通的，因為它會導致父級和子級透過寫入共享堆疊和堆疊來中斷彼此的執行。

父級和子級可以透過適當使用頁表權限和頁錯誤來安全地共享實體記憶體。當使用的虛擬位址在頁表中沒有對應、或具有 PTE\_Vflag 已清除的對應、或其權限位元（PTE\_R、PTE\_W、PTE\_X、PTE\_U）禁止所嘗試的操作的對應時，CPU 會引發頁錯誤異常。 RISC-V 區分三種頁面錯誤：載入頁面錯誤（由載入指令引起）、儲存頁面錯誤（由儲存指令引起）和指令頁面錯誤（由取得要執行的指令引起）。 cause 暫存器指示頁面錯誤的類型，thestval 暫存器包含無法轉換的位址。

COW fork 中的基本計劃是父級和子級最初共享所有實體頁，但每個將它們對應為唯讀（清除 PTE\_Wflag）。父母和孩子可以從共享實體記憶體中讀取資料。如果其中任何一個寫入給定頁面，RISC-V CPU 就會引發頁面錯誤異常。核心的陷阱處理程序透過分配新的實體記憶體頁並將故障位址對應的實體頁複製到其中來做出回應。核心會變更故障進程頁表中的相關 PTE 以指向副本並允許寫入和讀取，然後在導致故障的指令處恢復故障進程。由於 PTE 現在允許寫入，因此重新執行的指令將正常執行。寫時複製需要簿記來幫助決定何時可以釋放實體頁面，因為根據分叉、頁面錯誤、執行和退出的歷史記錄，每個頁面都可以由不同數量的頁表引用。這種簿記允許進行重要的最佳化：如果進程發生儲存頁錯誤並且僅從該進程的頁表引用物理頁，則不需要複製。

寫入時複製使 fork 更快，因為 fork 不需要複製記憶體。稍後寫入時，某些記憶體必須被複製，但通常情況下，大多數記憶體永遠不需要複製。一個常見的例子是 fork 之後是 exec：在 fork 之後可能會寫入幾頁，但隨後子進程的 exec 會釋放從父進程繼承的大部分記憶體。寫入時複製消除了複製該記憶體的需要。此外，COW 分叉是透明的：無需對應用程式進行修改即可受益。

除了 COW 分支之外，頁表和頁錯誤的組合還開啟了廣泛的有趣的可能性。另一個廣泛使用的功能稱為延遲分配，它有兩個部分。首先，當應用程式透過呼叫 sbrk 請求更多記憶體時，核心會注意到大小的增加，但不會分配實體內存，也不會為新的虛擬位址範圍建立 PTE。其次，當這些新位址之一發生頁面錯誤時，核心會分配實體記憶體頁面並將其對應到頁表中。與 COW fork 一樣，核心可以對應用程式透明地實現延遲分配。

由於應用程式經常要求比它們需要的更多的內存，因此延遲分配是一個勝利：內核根本不必為應用程式從不使用的頁面執行任何工作。此外，如果應用程式要求大量增加位址空間，那麼沒有延遲分配的brk會很昂貴：如果應用程式要求1GB內存，核心必須分配262,144個4096位元組頁面並將其歸零。惰性分配允許這種成本隨著時間的推移而分散。另一方面，惰性分配會帶來額外的頁面錯誤開銷，其中涉及使用者/核心轉換。作業系統可以透過為每個頁面錯誤分配一批連續頁面而不是一個頁面以及專門針對此類頁面錯誤的核心進入/退出代碼來降低此成本。

另一個廣泛使用的利用頁面錯誤的功能是請求分頁。在執行中，xv6 在啟動應用程式之前將應用程式的所有文字和資料載入到記憶體中。由於應用程式可能很大且從磁碟讀取資料需要時間，因此這種啟動成本對於用戶來說可能是顯而易見的。為了減少啟動時間，現代核心最初不會將可執行檔載入到記憶體中，而只是建立使用者頁表，並將所有 PTE 標記為無效。內核啟動程序運行；每次程式第一次使用某個頁面時，都會發生頁面錯誤，作為回應，核心從磁碟讀取該頁面的內容並將其映射到使用者位址空間。與 COW fork 和惰性分配一樣，核心可以對應用程式透明地實現此功能。

電腦上執行的程式可能需要比電腦 RAM 更多的記憶體。為了優雅地應對，作業系統可能會實現磁碟的分頁。這個想法是只將一小部分用戶頁面儲存在 RAM 中，並將其餘部分儲存在磁碟的分頁區域中。核心將與儲存在分頁區域（因此不在 RAM 中）的記憶體相對應的 PTE 標記為無效。如果應用程式嘗試使用已調出到磁碟的頁面之一，則應用程式將引發頁面錯誤，並且該頁面必須調入：核心陷阱處理程序將分配物理RAM 頁面，將該頁面從磁碟讀取到記憶體中。

如果需要調入一個頁面，但沒有空閒的實體 RAM，會發生什麼情況？在這種情況下，核心必須先透過將實體頁調出或將其移出到磁碟上的分頁區域來釋放實體頁，並將引用該實體頁的 PTE 標記為無效。逐出的成本很高，因此如果不頻繁進行分頁，則效能最佳：如果應用程式僅使用其記憶體頁面的子集，並且子集的並集適合 RAM。該屬性通常被稱為具有良好的引用局部性。與許多虛擬記憶體技術一樣，核心通常以對應用程式透明的方式實現對磁碟的分頁。

無論硬體提供多少 RAM，電腦通常都使用很少或根本沒有可用實體記憶體來運行。例如，雲端供應商在一台機器上多路復用許多客戶，以便經濟高效地使用他們的硬體。另一個例子，用戶在智慧型手機上的少量實體記憶體中運行許多應用程式。在此類設定中，分配頁面可能需要先逐出現有頁面。因此，當可用實體記憶體稀缺時，分配的成本就很高。

當可用記憶體稀缺且程式僅主動使用其分配記憶體的一小部分時，延遲分配和請求分頁特別有利。這些技術還可以避免在分配或載入頁面但從未使用過或在可以使用之前被驅逐時浪費的工作。

結合分頁和頁錯誤異常的其他功能包括自動擴展堆疊和記憶體映射文件，這些文件是程式使用map系統呼叫映射到其地址空間的文件，以便程式可以使用load和store讀取和寫入它們

指示。

### 4.7 Real world

蹦床和陷阱框架可能看起來過於複雜。一個驅動力是，RISC-V 在強制陷阱時有意盡可能少地執行操作，以允許非常快速的陷阱處理，事實證明這很重要。因此，核心陷阱處理程序的前幾條指令實際上必須在使用者環境中執行：使用者頁表和使用者暫存器內容。並且陷阱處理程序最初不知道有用的事實，例如正在運行的進程的標識或核心頁表的位址。解決方案是可能的，因為 RISC-V 提供了受保護的位置，內核可以在進入用戶空間之前在其中隱藏資訊：sscratch 暫存器和指向內核記憶體但由於缺少 PTE\_U 而受到保護的用戶頁表條目。 Xv6 的 Trampoline 和 trapframe 利用了這些 RISC-V 功能。

如果將核心記憶體對應到每個行程的使用者頁表（使用PTE\_Uclear），則可以消除對特殊彈跳床頁面的需求。當從用戶空間捕獲到核心時，這也將消除對頁表切換的需求。這反過來又允許內核中的系統呼叫實現利用當前進程的用戶記憶體映射，從而允許內核程式碼直接取消引用用戶指標。許多作業系統都使用了這些想法來提高效率。 Xv6 避免了它們，是為了減少因無意使用使用者指標而導致核心出現安全錯誤的可能性，並減少確保使用者和核心虛擬位址不重疊所需的複雜性。生產作業系統實作寫入時複製分叉、延遲分配、按需分頁、分頁到磁碟、記憶體對映檔案等。進程未使用的記憶體。生產作業系統還為應用程式提供系統呼叫來管理其位址空間並透過themmap、munmap和sigaction系統呼叫實現自己的頁面錯誤處理，以及提供將記憶體固定到RAM（seemlock）的呼叫並建議核心如何應用程式計劃使用其記憶體(seemadvise)。

### 4.8 Exercises

1. 函數copyin和copyinstr遍歷軟體中的使用者頁表。設定核心頁表，使核心對使用者程式進行映射，而copyin和copyinstr可以使用memcpy將系統呼叫參數複製到核心空間，並依靠硬體進行頁表遍歷。
2. 實現惰性記憶體分配。
3. 實施 COW 分叉。
4. 有沒有辦法消除每個使用者位址空間中的特殊TRAPFRAME頁映射？例如，是否可以修改 uservec 以簡單地將 32 個使用者暫存器推送到核心堆疊上，或將它們儲存在 proc 結構中？
5. 是否可以修改 xv6 以消除特殊的 TRAMPOLINE 頁面映射？
6. Implementmmap.

第5章
===

中斷和設備驅動程式
=========

Adriver 是作業系統中管理特定設備的代碼：它配置設備硬件，告訴設備執行操作，處理產生的中斷，並與可能等待設備 I/O 的進程交互。驅動程式程式碼可能很棘手，因為驅動程式與其管理的裝置同時執行。此外，驅動程式必須了解設備的硬體接口，該接口可能很複雜且記錄很少。需要作業系統關注的裝置通常可以配置為產生中斷，這是一種陷阱。核心陷阱處理程式碼識別設備何時引發中斷並呼叫驅動程式的中斷處理程序；在 xv6 中，此調度發生在 devintr(kernel/trap.c:185) 中。許多裝置驅動程式在兩個上下文中執行程式碼：上半部在進程的核心執行緒中運行，下半部在中斷時執行。上半部透過系統調用（例如 read 和 write）來調用，希望裝置執行 I/O。這段程式碼可能會要求硬體開始一個操作（例如，要求磁碟讀取一個區塊）；然後代碼等待操作完成。最終設備完成操作並引發中斷。驅動程式的中斷處理程序可作為下半部分，確定哪些操作已完成，在適當的情況下喚醒等待進程，並告訴硬體開始處理任何等待的下一個操作。

### 5.1 Code: Console input

控制台驅動程式(kernel/console.c)是驅動程式結構的簡單說明。控制台驅動程式透過連接到 RISC-V 的 UART 序列埠硬體接受人類輸入的字元。控制台驅動程式一次累積一行輸入，處理特殊輸入字符，例如退格鍵和 control-u。使用者進程（例如 shell）使用 read 系統呼叫從控制台取得輸入行。當您在 QEMU 中向 xv6 鍵入輸入時，您的按鍵將透過 QEMU 的模擬 UART 硬體傳送到 xv6。驅動程式與之通訊的 UART 硬體是由 QEMU 模擬的 16550 晶片 \[13\]。在真實的電腦上，16550 將管理連接到終端機或其他電腦的 RS232 串列連結。運行 QEMU 時，它會連接到您的鍵盤和顯示器。 UART 硬體對軟體來說就像是一組記憶體映射的控制暫存器。那

也就是說，RISC-V 硬體有一些實體位址連接到 UART 設備，以便載入和儲存與設備硬體而不是 RAM 進行互動。 UART 的記憶體映射位址從 0x10000000 或 UART0(kernel/memlayout.h:21) 開始。有幾個 UART 控制暫存器，每個暫存器都有一個位元組的寬度。它們與 UART0 的偏移量在 (kernel/uart.c:22) 定義。例如，LSR暫存器包含指示輸入字元是否正在等待軟體讀取的位元。這些字元（如果有）可從 RHR 暫存器讀取。每次讀取一個字元時，UART 硬體都會將其從等待字元的內部 FIFO 中刪除，並在 FIFO 為空時清除 LSR 中的「就緒」位元。 UART 發送硬體很大程度上獨立於接收硬體；如果軟體向 THR 寫入一個位元組，則 UART 會傳送該位元組。 Xv6的main呼叫consoleinit(kernel/console.c:182)來初始化UART硬體。此程式碼將 UART 配置為在 UART 接收每個輸入位元組時產生接收中斷，並在每次 UART 完成傳送一個輸出位元組時產生傳送完成中斷 (kernel/uart.c:53)。 xv6 shell 透過 init.c(user/init.c:19) 開啟的檔案描述子從控制台讀取。對 read 系統呼叫的呼叫透過核心到達 consoleread(kernel/console.c:80)。 ）返回到用戶進程。如果使用者尚未輸入完整的行，任何讀取進程都將在 sleepcall(kernel/console.c:96) 中等待（第 7 章解釋了 sleep 的細節）。 當使用者鍵入字元時，UART 硬體會要求 RISC-V 引發中斷，從而啟動 xv6 的陷阱處理程序。陷阱處理程序呼叫devintr(kernel/trap.c:185)，它查看RISC-Vscause暫存器以發現中斷來自外部設備。然後它要求稱為 PLIC \[3\] 的硬體單元告訴它哪個設備中斷了 (kernel/trap.c:193)。如果是 UART，devintrcallsuartintr。 uartintr(kernel/uart.c:177) 從 UART 硬體讀取任何等待的輸入字元並將它們交給consoleintr(kernel/console.c:136)；它不等待字符，因為將來的輸入將引發新的中斷。 consoleint 的工作是在 cons.buf 中累積輸入字符，直到整行到達。當換行符號到達時，consoleintr 會喚醒一個正在等待的consoleread（如果有）。一旦被喚醒，consoleread將觀察cons.buf中的整行，將其複製到使用者空間，然後返回（透過系統呼叫機制）到使用者空間。

### 5.2 代碼：控制台輸出

連接到控制台的檔案描述子上的 write 系統呼叫最終到達 atuartputc (kernel/uart.c:87)。裝置驅動程式維護一個輸出緩衝區（uart\_tx\_buf），以便寫入程序不必等待UART完成傳送；相反，uartputcappends 每個字元到緩衝區，呼叫suartstart 啟動裝置傳輸（如果還沒有），然後返回。 uartputc 等待的唯一情況是緩衝區已滿。 UART每次發送完一個字節，都會產生一個interrupt.uartintrcallsuartstart，

它檢查設備是否確實已完成發送，並將下一個緩衝的輸出字元交給設備。因此，如果一個進程向控制台寫入多個位元組，通常第一個位元組將由 uartputc 的呼叫 touartstart 發送，其餘的緩衝位元組將由 uartstart 呼叫 fromuartintras 傳輸完成中斷到達發送。需要注意的一般模式是透過緩衝和中斷將裝置活動與行程活動解耦。即使沒有進程正在等待讀取輸入，控制台驅動程式也可以處理輸入；隨後的讀取將看到輸入。同樣，進程可以發送輸出而無需等待設備。這種解耦可以透過允許進程與設備 I/O 同時執行來提高效能，並且當設備速度較慢（如 UART）或需要立即關注（如回顯鍵入的字元）時尤其重要。這種想法有時稱為 I/O 並發。

### 5.3 驅動程式中的並發性

您可能已經注意到對 acquireinconsoleread 和 inconsoleintr 的調用。這些呼叫會取得鎖，以保護控制台驅動程式的資料結構免遭並發存取。這裡有三個並發危險：不同CPU上的兩個行程可能同時呼叫consoleread；當 CPU 已經在 consoleread 內執行時，硬體可能會要求 CPU 傳遞控制台（實際上是 UART）中斷；當控制台讀取正在執行時，硬體可能會在不同的 CPU 上傳遞控制台中斷。第 6 章解釋如何使用鎖來確保這些危險不會導致不正確的結果。驅動程式中需要注意並發性的另一種方式是，一個進程可能正在等待來自裝置的輸入，但是當另一個進程（或根本沒有進程）正在運行時，輸入的中斷訊號到達可能會到達。因此，中斷處理程序不允許考慮它們中斷的程序或程式碼。例如，中斷處理程序無法安全地使用目前進程的頁表呼叫copyout。中斷處理程序通常執行相對較少的工作（例如，僅將輸入資料複製到緩衝區），並喚醒上半部程式碼以完成其餘工作。

### 5.4 Timer interrupts

Xv6 使用計時器中斷來維護當前時間並在計算密集型程序之間進行切換。定時器中斷來自連接到每個 RISC-V CPU 的時脈硬體。 Xv6 對每個 CPU 的時脈硬體進行編程，以定期中斷 CPU。 start.c(kernel/start.c:53) 中的程式碼設定一些控制位，允許管理員模式存取定時器控制暫存器，然後請求第一個定時器中斷。時間控制暫存器包含硬體以穩定速率遞增的計數；這是當前時間的概念。 stimecmp 暫存器包含 CPU 將引發定時器中斷的時間；設定timecmp為time的目前值加上x將在將來安排一個中斷x時間單位。 Forqemu的RISC-V仿真，1000000個時間單位大約是十分之一秒。與其他裝置中斷一樣，定時器中斷透過usertraporkerneltrap 和devintr 到達。定時器中斷到達，原因的低位元設定為 5；devintrap.c 偵測

這種情況並呼叫clockintr(kernel/trap.c:164)。後一個函數incrementsticks，允許內核追蹤時間的流逝。此增量只發生在一個 CPU 上，以避免在有多個 CPU 的情況下時間過得更快。

devintr 對於計時器中斷返回 2，以便向 kerneltraporusertrap 指示它們應該調用，以便 CPU 可以在可運行進程之間進行多路復用。

事實上，內核程式碼可以被定時器中斷中斷，定時器中斷透過yield強制進行上下文切換，這也是早期程式碼在啟用中斷之前小心保存狀態（例如assepc）的部分原因。這些上下文切換也意味著編寫核心程式碼時必須知道它可能會在沒有警告的情況下從一個 CPU 轉移到另一個 CPU。

### 5.5 Real world

Xv6 與許多作業系統一樣，在核心中執行時允許中斷甚至上下文切換（viayield）。這樣做的原因是為了在長時間運行的複雜系統呼叫期間保持快速回應時間。然而，如上所述，允許內核中斷是一些複雜性的根源；因此，一些作業系統僅在執行用戶代碼時允許中斷。支援典型電腦上的所有設備是一項艱鉅的工作，因為有很多設備，這些設備有很多功能，而且設備和驅動程式之間的協定可能很複雜且文件記錄很差。在許多作業系統中，驅動程式所佔的程式碼比核心核心還要多。

UART 驅動程式透過讀取 UART 控制暫存器一次擷取一個位元組的資料；這種模式稱為編程 I/O，因為軟體驅動資料移動。程式設計 I/O 很簡單，但速度太慢，無法在高資料速率下使用。需要高速移動大量資料的裝置通常使用直接記憶體存取 (DMA)。 DMA 裝置硬體直接將傳入資料寫入 RAM，並從 RAM 讀取傳出資料。現代磁碟和網路設備使用 DMA。 DMA 裝置的驅動程式將在 RAM 中準備數據，然後使用對控制暫存器的單次寫入來告訴裝置處理準備好的資料。

當設備在不可預測的時間（但不是太頻繁）需要關注時，中斷就有意義。但中斷的CPU開銷很高。因此，高速設備（例如網路和磁碟控制器）使用減少中斷需求的技巧。一個技巧是為整批傳入或傳出請求引發一個中斷。另一個技巧是驅動程式完全停用中斷，並定期檢查裝置以查看是否需要注意。這種技術稱為輪詢。如果裝置以高速率執行操作，則輪詢是有意義的，但如果裝置大部分時間處於閒置狀態，則輪詢會浪費 CPU 時間。某些驅動程式根據目前裝置負載在輪詢和中斷之間動態切換。

UART 驅動程式首先將傳入資料複製到核心中的緩衝區，然後複製到使用者空間。這在低數據速率下是有意義的，但這種雙重複製會顯著降低快速生成或消耗數據的設備的效能。一些作業系統能夠直接在用戶空間緩衝區和裝置硬體之間移動數據，通常使用 DMA。

如第 1 章中所提到的，控制台對於應用程式來說就像一個常規文件，應用程式使用 read 和 write 系統呼叫來讀取輸入和寫入輸出。應用程式可能想要控制無法透過標準檔案系統呼叫表達的裝置方面（例如，在控制台驅動程式中啟用/停用行緩衝）。 Unix 作業系統支援針對此類情況的ioctl 系統呼叫。電腦的某些用途要求系統必須在有限的時間內做出回應。例如，在安全關鍵系統中，錯過最後期限可能會導致災難。 Xv6 不適合硬即時設定。硬實時作業系統往往是與應用程式連結的庫，其方式允許分析以確定最壞情況的回應時間。 xv6 也不適合軟實時應用程序，偶爾錯過最後期限是可以接受的，因為 xv6 的調度程序過於簡單，並且它的內核代碼路徑長時間禁用中斷。

### 5.6 Exercises

1. 修改uart.c以完全不使用中斷。您可能需要好好修改console.cas。
2. 新增乙太網路卡驅動程式。

第6章
===

Locking
=======

大多數核心（包括 xv6）都會交錯執行多個活動。交錯的來源之一是多處理器硬體：具有多個獨立執行的 CPU 的計算機，例如 xv6 的 RISC-V。這些多個 CPU 共享實體 RAM，xv6 利用共享來維護所有 CPU 讀寫的資料結構。這種共享增加了一個 CPU 讀取資料結構而另一個 CPU 正在更新資料結構的可能性，甚至多個 CPU 同時更新相同的資料；如果不仔細設計，這種並行存取可能會產生不正確的結果或損壞的資料結構。即使在單處理器上，核心也可能在多個執行緒之間切換 CPU，導致它們的執行交錯。最後，如果中斷發生在錯誤的時間，則修改與某些可中斷程式碼相同的資料的裝置中斷處理程序可能會損壞資料。並發這個字是指由於多處理器並行、執行緒切換或中斷而導致多個指令流交錯的情況。

核心充滿了並發存取的資料。例如，兩個CPU可以同時呼叫kalloc，從而同時從空閒列表的頭部彈出。核心設計者喜歡允許大量並發，因為它可以透過並行性來提高效能並提高回應能力。然而，因此，儘管存在這樣的並發性，內核設計者仍必須讓自己相信其正確性。獲得正確程式碼的方法有很多，其中一些方法比其他方法更容易推理。旨在並發下正確性的策略以及支持它們的抽像被稱為並發控制技術。

Xv6根據情況使用了多種並發控制技術；還有更多可能。本章重點在於一種廣泛使用的技術：thelock。鎖提供互斥，確保一次只有一個 CPU 可以持有該鎖。如果程式設計師為每個共用資料項關聯一個鎖，且程式碼在使用某項時始終持有關聯的鎖，那麼該項一次只能由一個 CPU 使用。在這種情況下，我們說鎖保護了資料項。儘管鎖是一種易於理解的並發控制機制，但鎖的缺點是它們會限制效能，因為它們會序列化並發操作。

本章的其餘部分解釋了為什麼 xv6 需要鎖定、xv6 如何實現它們以及如何使用它們。

CPU CPU

l->next = list l->next = list


list


Memory

BUS


Figure 6.1: Simplified SMP architecture


### 6.1 Races

作為我們為什麼需要鎖的一個例子，考慮兩個具有退出子程序的程序在兩個不同的 CPU 上呼叫 wait。因此，在每個 CPU 上，核心將呼叫 kfree 來釋放子層級的記憶體頁面。核心分配器維護一個鍊錶：kalloc()(kernel/kalloc.c:69)從空閒頁列表中彈出一頁內存，kfree()(kernel/kalloc.c:47)將一頁推送到空閒列表。為了獲得最佳效能，我們可能希望兩個父進程的 kfree 能夠並行執行，而不必等待另一個，但考慮到 xv6 的 skfree 實現，這是不正確的。

圖 6.1 更詳細說明了該設定：空閒頁面的連結清單位於由兩個 CPU 共享的記憶體中，這兩個 CPU 使用載入和儲存指令來操作該清單。 （實際上，處理器有一個緩存，但從概念上講，多處理器系統的行為就好像有一個共享內存一樣。）如果沒有並發請求，您可以按如下方式實現 listpush 操作：

1 struct element {
2 int data;
3 struct element *next;
4 };
5
6 struct element *list = 0;
7
8 void
9 push(int data)
10 {
11 struct element *l;
12
13 l = malloc(sizeof *l);
14 l->data = data;
15 l->next = list;
16 list = l;


Memory


CPU 1


CPU2
15


l->next


16


list


15 16


l->next list


Time


Figure 6.2: Example race


17 }


如果單獨執行，此實作是正確的。但是，如果同時執行多個副本，則程式碼不正確。如果兩個 CPU 同時執行 pushat，則兩個 CPU 都可能會先執行第 15 行，如圖 6.1 所示，然後再執行第 16 行，這會導致錯誤的結果，如圖 6.2 所示。然後將有兩個列表元素，其 nextset 為 list 的前一個值。當第 16 行對 list 進行兩次賦值時，第二個賦值會覆寫第一個；第一個分配中涉及的元素將會遺失。第 16 行遺失的更新是 arace 的一個範例。競爭是一種同時存取記憶體位置且至少一次存取是寫入的情況。競爭通常是錯誤的跡象，要么是更新丟失（如果訪問是寫入），要么是讀取未完全更新的資料結構。競爭的結果取決於編譯器產生的機器碼、所涉及的兩個 CPU 的時序以及記憶體系統如何排序它們的記憶體操作，這可能會使競爭引起的錯誤難以重現和調試。例如，在偵錯推送時新增列印語句可能會改變執行時間，足以使競爭消失。避免競爭的常用方法是使用鎖。鎖確保互斥，這樣一次只有一個CPU可以執行push的敏感行；這使得上述情況變得不可能。上述程式碼的正確鎖定版本僅新增了幾行（以黃色突出顯示）：

6 struct element *list = 0;
7 struct lock listlock;
8
9 void
10 push(int data)
11 {
12 struct element *l;
13 l = malloc(sizeof *l);
14 l->data = data;


15
16 acquire(&listlock);
17 l->next = list;
18 list = l;
19 release(&listlock);
20 }


獲取和釋放之間的指令序列通常稱為關鍵部分。此鎖通常被稱為保護清單。

當我們說鎖保護資料時，我們真正的意思是鎖保護一些適用於資料的不變量集合。不變量是跨操作維護的資料結構的屬性。通常，操作的正確行為取決於操作開始時不變量是否為真。該操作可能會暫時違反不變量，但必須在完成之前重新建立它們。例如，在鍊錶情況下，不變式是list指向清單中的第一個元素，並且每個元素的next欄位指向下一個元素。 push 的實作暫時違反了這個不變量：在第 17 行，l 指向下一個清單元素，但 list 不指向 atlyet（在第 18 行重新建立）。我們上面檢查的競爭之所以發生，是因為第二個 CPU 執行了依賴列表不變量的程式碼，而它們（暫時）被違反了。正確使用鎖定可以確保一次只有一個 CPU 可以對臨界區中的資料結構進行操作，這樣當資料結構的不變量不成立時，就沒有 CPU 會執行該資料結構操作。

您可以考慮使用一把鎖來序列化並發關鍵部分，以便它們一次運行一個，從而保留不變量（假設關鍵部分在隔離中是正確的）。您還可以將由同一鎖保護的關鍵部分視為彼此之間的原子性，以便每個關鍵部分只能看到早期關鍵部分的完整更改集，而永遠不會看到部分完成的更新。

雖然鎖對於正確性很有用，但它本質上限制了性能。例如，如果兩個進程同時呼叫kfree，鎖將序列化兩個臨界區，因此在不同的CPU上執行它們沒有任何好處。如果多個進程同時想要相同的鎖，或是鎖發生爭用，我們就說它們發生衝突。核心設計中的一個主要挑戰是避免鎖爭用以追求並行性。 Xv6 幾乎沒有做到這一點，但複雜的核心專門組織資料結構和演算法來避免鎖爭用。在列表範例中，核心可以為每個 CPU 維護一個單獨的空閒列表，並且僅在當前 CPU 的列表為空並且必須從另一個 CPU 竊取記憶體時才觸及另一個 CPU 的空閒列表。其他用例可能需要更複雜的設計。

鎖的放置對於性能也很重要。例如，將acquireearlier inpush移到第13行之前是正確的。下面的「使用鎖定」部分提供了有關在何處插入獲取和釋放呼叫的一些指導原則。

### 6.2 Code: Locks

Xv6 有兩種類型的鎖：自旋鎖和睡眠鎖。我們將從自旋鎖開始。 Xv6 將自旋鎖表示為 struct spinlock(kernel/spinlock.h:2)。此結構中的重要欄位是鎖定的，當鎖定可用時該字為零，而當鎖定時該字為非零。從邏輯上講，xv6 應該透過執行類似的程式碼來取得鎖

21 void
22 acquire(struct spinlock *lk) // does not work!
23 {
24 for(;;) {
25 if(lk->locked == 0) {
26 lk->locked = 1;
27 break;
28 }
29 }
30 }


不幸的是，這種實作並不能保證多處理器上的互斥。可能會發生兩個CPU同時到達第25行，看到lk->locked為0，然後都透過執行第26行來取得鎖。 。我們需要的是一種使第 25 行和第 26 行作為解剖（即不可分割的）步驟執行的方法。

由於鎖被廣泛使用，多核心處理器通常提供實現第 25 行和第 26 行原子版本的指令。 amoswap 讀取記憶體位址 a 處的值，將暫存器 r 的內容寫入該位址，並將讀取的值放入 tor 中。也就是說，它交換了暫存器的內容和記憶體位址。它以原子方式執行此序列，使用特殊硬體來防止任何其他 CPU 使用讀取和寫入之間的記憶體位址。

Xv6的sacquire(kernel/spinlock.c:22)使用可移植的C函式庫呼叫\_\_sync\_lock\_test\_and\_set，它歸結為theamoswapin指令；傳回值是 lk->locked 的舊（交換）內容。 acquire 函數將交換包裝在一個循環中，重試（旋轉）直到獲得鎖。每次迭代將一個交換到lk->locked 並檢查前一個值；如果前一個值為零，則我們已取得鎖，並且交換將 setlk->locked 為 1。如果前一個值為 1，則其他某個 CPU 持有該鎖，而我們以原子方式將 1 交換為 lk->locked 的事實並沒有改變它的值。

取得鎖後，acquire 記錄取得鎖的 CPU，以供調試。 lk->cpu 欄位受鎖定保護，且只能在持有鎖定時進行變更。

函數release(kernel/spinlock.c:47)與acquire相反：它清除lk->cpu字段，然後釋放鎖定。從概念上講，該版本只需要分配零 tolk->locked。 C 標準允許編譯器使用多個儲存指令實作賦值，因此 C 賦值對於並發程式碼來說可能是非原子的。相反，release 使用執行原子分配的 C 函式庫函數 \_\_sync\_lock\_release。此函數也可以歸結為 RISC-Vamoswa 指令。

### 6.3 Code: Using locks

Xv6 在許多地方使用鎖來避免競爭。如上所述，kalloc(kernel/kalloc.c:69) 和 kfree(kernel/kalloc.c:47) 就是一個很好的例子。試著練習 1 和 2，看看如果這些函數忽略鎖會發生什麼事。您可能會發現很難觸發不正確的行為，這表明很難可靠地測試程式碼是否不存在鎖定錯誤和競爭。 Xv6 很可能有尚未被發現的種族。使用鎖的一個困難部分是決定使用多少個鎖以及每個鎖應保護哪些資料和不變量。有一些基本原則。首先，任何時候一個 CPU 可以寫入一個變量，同時另一個 CPU 可以讀取或寫入該變量，則應使用鎖來防止兩個操作重疊。其次，請記住，鎖定保護不變量：如果不變量涉及多個記憶體位置，通常所有這些位置都需要由單一鎖定保護，以確保保持不變量。上面的規則說明了何時需要鎖，但沒有提及何時不需要鎖，並且不要鎖太多對於效率很重要，因為鎖會降低並行性。如果並行性不重要，那麼可以安排只有一個執行緒而不用擔心鎖。一個簡單的核心可以在多處理器上透過擁有一個鎖來做到這一點，該鎖必須在進入核心時獲取並在退出核心時釋放（儘管阻塞系統呼叫（例如管道讀取或等待）會引起問題）。許多單處理器作業系統已使用這種方法（有時稱為“大核心鎖”）轉換為在多處理器上運行，但該方法犧牲了並行性：一次只能有一個 CPU 在核心中執行。 如果核心執行任何繁重的計算，那麼使用更大的一組更細粒度的鎖定會更有效，以便核心可以同時在多個 CPU 上執行。作為粗粒度鎖定的一個範例，xv6'skalloc.callocator 有一個由單一鎖定保護的單一空閒清單。如果不同 CPU 上的多個進程嘗試同時分配頁面，則每個進程都必須透過旋轉 inacquire 來等待輪到它。旋轉會浪費 CPU 時間，因為它不是有用的工作。如果鎖的爭用浪費了很大一部分 CPU 時間，也許可以透過將分配器設計更改為具有多個空閒列表（每個列表都有自己的鎖）以允許真正的並行分配來提高效能。作為細粒度鎖定的範例，xv6 對每個檔案都有一個單獨的鎖，因此操作不同檔案的進程通常可以繼續進行，而無需等待彼此的鎖。如果希望允許進程同時寫入相同檔案的不同區域，則可以使檔案鎖定方案變得更加細粒度。最終，鎖粒度決策需要由效能測量和複雜性考量來驅動。後續章節在解釋 xv6 的各個部分時，都會提到 xv6 使用鎖來處理並發的範例。作為預覽，圖 6.3 列出了 xv6 中的所有鎖。

### 6.4 Deadlock and lock ordering

如果通過核心的程式碼路徑必須同時持有多個鎖，則所有程式碼路徑以相同的順序取得這些鎖非常重要。如果不這樣做，就會有陷入僵局的風險。假設 xv6 中的兩個程式碼路徑需要鎖 A 和 B，但是程式碼路徑 1 按 A 的順序取得鎖

Lock Description
bcache.lock Protects allocation of block buffer cache entries
cons.lock Serializes access to console hardware, avoids intermixed output
ftable.lock Serializes allocation of a struct file in file table
itable.lock Protects allocation of in-memory inode entries
vdisk_lock Serializes access to disk hardware and queue of DMA descriptors
kmem.lock Serializes allocation of memory
log.lock Serializes operations on the transaction log
pipe’s pi->lock Serializes operations on each pipe
pid_lock Serializes increments of next_pid
proc’s p->lock Serializes changes to process’s state
wait_lock Helps wait avoid lost wakeups
tickslock Serializes operations on the ticks counter
inode’s ip->lock Serializes operations on each inode and its content
buf’s b->lock Serializes operations on each block buffer


Figure 6.3: Locks in xv6


B，另一條路徑依照B然後A的順序取得它們。取得鎖A。為了避免此類死鎖，所有程式碼路徑必須以相同的順序取得鎖。對全域鎖定獲取順序的需求意味著鎖實際上是每個函數規範的一部分：呼叫者必須以導致按照商定的順序獲取鎖的方式呼叫函數。

由於 sleep 的工作方式（請參閱第 7 章），Xv6 有許多長度為 2 的鎖定順序鏈，涉及每個進程鎖定（每個 struct proc 中的鎖定）。例如，consoleintr (kernel/console.c:136) 是處理鍵入字元的中斷例程。當換行到達時，任何正在等待控制台輸入的進程都應該被喚醒。為此，consoleintr 在呼叫wakeup 時持有cons.lock，它會取得等待進程的鎖定以將其喚醒。因此，全域避免死鎖的鎖定順序包括必須在任何進程鎖定之前取得 cons.lock 的規則。檔案系統代碼包含 xv6 最長的鎖鏈。例如，建立檔案需要同時持有目錄鎖定、新檔案 inode 鎖定、磁碟區塊緩衝區鎖定、磁碟驅動程式的 svdisk\_lock 以及呼叫進程的 sp->lock。為了避免死鎖，檔案系統程式碼始終按照上一句中提到的順序取得鎖。

遵守全球避免僵局的秩序可能異常困難。有時鎖順序與邏輯程式結構相衝突，例如，也許程式碼模組M1呼叫模組M2，但鎖順序要求先取得M2中的鎖，然後再取得M1中的鎖。有時，事先並不知道鎖的身份，可能是因為必須持有一個鎖才能發現下一個要取得的鎖的身份。這種情況在檔案系統中出現，因為它在路徑名中尋找連續的元件，並且在 forwaitandexitas 程式碼中它們搜尋表

尋找子進程的進程。最後，死鎖的危險通常是對鎖定方案的細粒度程度的限制，因為更多的鎖通常意味著更多的死鎖機會。避免死鎖的需要通常是核心實現的一個主要因素。

### 6.5 Re-entrant locks

使用可重入鎖（也稱為遞歸鎖）似乎可以避免一些死鎖和鎖排序挑戰。這個想法是，如果鎖被一個進程持有，並且該進程嘗試再次獲取鎖，那麼核心可以允許這樣做（因為該進程已經擁有鎖），而不是像 xv6 核心那樣調用恐慌。然而，事實證明，可重入鎖使推理並發性變得更加困難：可重入鎖打破了鎖導致臨界區相對於其他臨界區是原子的直覺。考慮以下函數 fandg 和假設函數 h：

struct spinlock lock;
int data = 0; // protected by lock


f() {
acquire(&lock);
if(data == 0){
call_once();
h();
data = 1;
}
release(&lock);
}


g() {
aquire(&lock);
if(data == 0){
call_once();
data = 1;
}
release(&lock);
}


h() { ... } 檢視此程式碼片段，直覺是 call\_once 只會被呼叫一次：要麼 byf ，要麼 byg ，但不能同時被兩者呼叫。但如果允許重入鎖，並且碰巧呼叫g，call\_once就會被呼叫兩次。如果不允許重入鎖，那麼 hcalling 會導致死鎖，這也不是很好。但是，假設 callcall\_once 將是一個嚴重的錯誤，那麼死鎖是更好的選擇。這

核心開發人員將觀察死鎖（核心恐慌）並可以修復程式碼以避免死鎖，而呼叫call\_oncetwice可能會默默地導致難以追蹤的錯誤。為此，xv6 使用了更容易理解的不可重入鎖。然而，只要程式設計師牢記鎖定規則，任何一種方法都可以發揮作用。如果 xv6 要使用可重入鎖，則必須修改acquire 才能注意到該鎖目前由呼叫執行緒持有。也必須以類似的 topush\_off 風格向 struct spinlock 添加嵌套獲取的計數，這將在接下來討論。

### 6.6 Locks and interrupt handlers

一些 xv6 自旋鎖保護執行緒和中斷處理程序使用的資料。例如，clockintrtimer 中斷處理程序可能會在核心執行緒讀取 sys\_sleep(kernel/sysproc.c:61) 的同時增加ticks(kernel/trap.c:164)。 locktickslock 序列化這兩個訪問。自旋鎖和中斷的相互作用會帶來潛在的危險。假設sys\_sleep持有tickslock，並且它的CPU被計時器中斷中斷。在這種情況下，tickslock永遠不會被釋放：只有sys\_sleep可以釋放它，但是sys\_sleep不會繼續運行，直到clockintr返回。因此，CPU 將發生死鎖，並且任何需要任一鎖的程式碼也將凍結。為了避免這種情況，如果中斷處理程序使用自旋鎖，則 CPU 絕不能在啟用中斷的情況下保持該鎖。 Xv6 更保守：當 CPU 取得任何鎖時，xv6 會始終禁止該 CPU 上的中斷。其他CPU上仍可能發生中斷，因此中斷的acquire可以等待執行緒釋放自旋鎖；只是不在同一個CPU上。當 CPU 沒有自旋鎖時，Xv6 重新啟用中斷；它必須做一些簿記來處理嵌套的關鍵部分。當該計數達到零時，pop\_off 恢復最外層臨界區開始處存在的中斷啟用狀態。 intr\_off 和intr\_on 函數執行RISC-V 指令以分別停用和啟用中斷。重要的是，必須在設定 lk->locked(kernel/spin-lock.c:28) 之前嚴格取得 callpush\_off。 如果兩者顛倒，則在啟用中斷的情況下保持鎖定時會出現一個短暫的窗口，不幸的是定時中斷將使系統死鎖。同樣，重要的是，只有在釋放鎖後才release呼叫pop\_off（kernel/spinlock.c:66）。

### 6.7 指令和記憶體排序

人們很自然地認為程式是按照原始碼語句出現的順序執行的。對於單線程程式碼來說，這是一個合理的心理模型，但當多個線程透過共享記憶體互動時，這是不正確的 \[2, 4\]。原因之一是編譯器發出載入和儲存指令的順序與原始程式碼所暗示的順序不同，並且可能完全省略它們（例如透過在暫存器中快取資料）。另一個原因是CPU可能會亂序執行指令

以提高性能。例如，CPU 可能會注意到指令 A 和 B 的序列序列中並不相互依賴。 CPU 可能會先啟動指令 B，要不是因為其輸入在 A 的輸入之前準備就緒，就是為了重疊執行 A 和 B。行對應的儲存移動到第6 行釋放之後的某個點：

1 l = malloc(sizeof *l);
2 l->data = data;
3 acquire(&listlock);
4 l->next = list;
5 list = l;
6 release(&listlock);


如果發生這樣的重新排序，則會出現一個窗口，在此期間另一個 CPU 可以獲得鎖定並觀察更新列表，但會看到未初始化的列表->ext。好消息是，編譯器和 CPU 透過遵循一組稱為記憶體模型的規則，並提供一些原語來幫助程式設計師控制重新排序，從而幫助並發程式設計師。為了告訴硬體和編譯者不要重新排序，xv6 在 acquire(kernel/spinlock.c:22) 和release(kernel/spinlock.c:47) 中使用 \_\_sync\_synchronize()。編譯器和CPU 不會跨過屏障重新排序載入或儲存。幾乎在所有重要的情況下，xv6 的獲取和釋放順序中的障礙都是如此，因為 xv6 在存取共享資料時使用了鎖定。第 9 章討論了一些例外。

### 6.8 Sleep locks

有時xv6需要長時間持有鎖。例如，檔案系統（第 8 章）在磁碟上讀取和寫入檔案內容時保持檔案鎖定，這些磁碟操作可能需要數十毫秒。如果另一個程序想要取得自旋鎖，持有這麼長時間的自旋鎖會導致浪費，因為取得程序會在自旋時長時間浪費 CPU。自旋鎖的另一個缺點是進程在保留自旋鎖的同時無法讓出 CPU。我們希望這樣做，以便其他進程可以在擁有鎖的進程等待磁碟時使用 CPU。持有自旋鎖時讓出是非法的，因為如果第二個執行緒隨後嘗試取得自旋鎖，可能會導致死鎖；由於acquired不會產生CPU，第二個執行緒的旋轉可能會阻止第一個執行緒運行並釋放鎖。在持有鎖時讓出也會違反在持有自旋鎖時中斷必須關閉的要求。因此，我們需要一種在等待獲取時讓出 CPU，並在持有鎖時允許讓出（和中斷）的鎖。 Xv6 以sleep-locks.acquiresleep(kernel/sleeplock.c:22) 的形式提供此類鎖，使用將在第7 章中解釋的技術，在等待時釋放CPU。 lockedfield，即受自旋鎖定保護，andacquiresleep 對sleep 的呼叫以原子方式讓出 CPU 並釋放自旋鎖。結果是其他執行緒可以在acquiresleepwaits 的同時執行。

由於睡眠鎖使中斷保持啟用狀態，因此它們不能在中斷處理程序中使用。因為取得睡眠可能會佔用 CPU，所以睡眠鎖不能在自旋鎖臨界區內使用（儘管自旋鎖可以在睡眠鎖臨界區內使用）。自旋鎖最適合短臨界區，因為等待它們會浪費 CPU 時間；睡眠鎖非常適合長時間操作。

### 6.9 Real world

儘管對並發原語和並行性進行了多年的研究，但使用鎖進行程式設計仍然具有挑戰性。通常最好在同步佇列等更高層級的構造中隱藏鎖，儘管 xv6 不這樣做。如果您使用鎖進行編程，那麼明智的做法是使用嘗試識別競爭的工具，因為很容易錯過需要鎖的不變量。大多數作業系統支援 POSIX 執行緒 (Pthreads)，它允許使用者進程在不同的 CPU 上同時執行多個執行緒。 Pthreads 支援用戶級鎖、屏障等。在使用者層級支援Pthreads需要作業系統的支援。例如，如果一個 pthread 在系統呼叫中阻塞，則同一進程的另一個 pthread 應該能夠在該 CPU 上運作。作為另一個範例，如果 pthread 更改其進程的位址空間（例如，映射或取消映射記憶體），則核心必須安排運行相同進程的執行緒的其他 CPU 更新其硬體頁表以反映位址空間中的變更。無需原子指令\[10\]也可以實現鎖，但成本昂貴，大多數作業系統都使用原子指令。如果許多 CPU 嘗試同時取得相同的鎖，那麼鎖的成本可能會很高。如果一個CPU在其本地快取中緩存了一個鎖，而另一個CPU必須取得該鎖，則更新持有該鎖的快取行的原子指令必須將該行從一個CPU的快取移動到另一個CPU的緩存，並且也許使快取行的任何其他副本無效。 從另一個 CPU 的高速緩存中獲取高速緩存行的成本可能比從本地高速緩存中獲取高速緩存行的成本高出幾個數量級。為了避免與鎖相關的開銷，許多作業系統使用無鎖定資料結構和演算法 \[6, 12\]。例如，可以實作像本章開頭那樣的鍊錶，在清單搜尋期間不需要鎖，並且可以使用一條原子指令在列表中插入一項。然而，無鎖編程比鎖編程更複雜。例如，我們必須擔心指令和記憶體的重新排序。使用鎖定編程已經很困難，因此 xv6 避免了無鎖編程的額外複雜性。

### 6.10 Exercises

1. 註解掉對acquireandreleaseinkalloc(kernel/kalloc.c:69) 的呼叫。這看起來應該會為呼叫skalloc的核心程式碼帶來問題；您預計會看到什麼症狀？當您執行 xv6 時，您是否看到這些症狀？跑步的時候怎麼樣

usertests? If you don’t see a problem, why not? See if you can provoke a problem by
inserting dummy loops into the critical section ofkalloc.


1. 假設您註解掉了 kfree 中的鎖定（在恢復鎖定 inkalloc 之後）。現在可能會出現什麼問題？缺少 inkfreeless 鎖是否比 kalloc 更有害？
2. 如果兩個 CPU 同時呼叫 kallocat，一個將不得不等待另一個，這對效能不利。修改kalloc.c以具有更多並行性，以便不同CPU對kalloc的同時呼叫可以繼續進行，而無需互相等待。
3. 使用大多數作業系統都支援的 POSIX 執行緒編寫並行程式。例如，實作一個並行哈希表並測量放入/獲取的數量是否隨著 CPU 數量的增加而變化。
4. 在 xv6 中實作 Pthread 的子集。即實作一個使用者級線程庫，使得一個使用者程序可以有1個以上的線程，並安排這些線程可以在不同的CPU上並行運行。提出一種設計，可以正確處理執行緒進行阻塞系統呼叫並更改其共享位址空間。

第7章
===

Scheduling
==========

任何作業系統運行的進程數都可能多於電腦的 CPU 數，因此需要製定計劃來在進程之間分時共享 CPU。理想情況下，共享對用戶進程是透明的。一種常見的方法是透過將進程重複使用到硬體 CPU 上，為每個進程提供一種假象，即它擁有自己的虛擬 CPU。本章解釋 xv6 如何實現這種多路復用。

### 7.1 Multiplexing

Xv6 透過在兩種情況下將每個 CPU 從一個進程切換到另一個進程來進行多路復用。首先，當進程發出阻塞（必須等待事件）的系統呼叫時，xv6 的睡眠和喚醒機制會切換，通常是在讀取、等待或睡眠中。其次，xv6 定期強制切換以處理長時間計算而不阻塞的程序。前者是自願切換；後者稱為非自願。這種多重化造成了每個行程都有自己的 CPU 的錯覺。

實施多路復用帶來了一些挑戰。一、如何從一個行程切換到另一個行程？基本思想是保存和恢復 CPU 暫存器，儘管事實上這不能用 C 語言表達，這使得它變得棘手。其次，如何以對使用者流程透明的方式強制切換？ Xv6 使用標準技術，其中硬體定時器的中斷驅動上下文切換。第三，所有 CPU 在同一組進程之間切換，因此需要一個鎖定計畫來避免競爭。第四，進程退出時必須釋放進程的記憶體和其他資源，但它本身無法完成所有這些操作，因為（例如）它無法在仍在使用自己的核心堆疊時釋放它。第五，多核心機器的每個CPU必須記住它正在執行哪個進程，以便系統呼叫影響正確的進程的核心狀態。最後，sleep和wakeup允許行程放棄CPU並等待被另一個行程或中斷喚醒。需要小心避免導致喚醒通知遺失的競爭。

Kernel


shell cat


user
space


kernel
space kstack
shell


kstack
cat


kstack
scheduler


save
swtch swtch restore


圖 7.1：從一個使用者進程切換到另一個使用者進程。在此範例中，xv6 使用一個 CPU（因此也有一個調度程序執行緒）來運行。

### 7.2 代碼：上下文切換

圖7.1 概述了從一個使用者程序切換到另一個使用者程序所涉及的步驟：從使用者空間到舊行程的核心執行緒的陷阱（系統呼叫或中斷）、到目前CPU 調度程序執行緒的上下文切換、到新行程的上下文切換內核線程，並返回用戶級進程的陷阱。 Xv6 有單獨的執行緒（已儲存的暫存器和堆疊）來執行調度程序，因為調度程序在任何進程的核心堆疊上執行都是不安全的：其他一些CPU 可能會喚醒該進程並運行它，這將是一場災難在兩個不同的 CPU 上使用相同的堆疊。每個CPU都有一個單獨的調度程序線程，以應對多個CPU正在運行一個想要放棄CPU的進程的情況。在本節中，我們將研究核心執行緒和調度程序執行緒之間切換的機制。

從一個執行緒切換到另一個執行緒涉及保存舊執行緒的CPU暫存器，並恢復新執行緒先前儲存的暫存器；堆疊指標和程式計數器的保存和復原意味著CPU將切換堆疊並切換正在執行的程式碼。

函數wtch保存和恢復內核線程切換的暫存器。它只是保存和恢復 RISC-V 暫存器組，稱為上下文。當進程需要放棄CPU時，進程的核心執行緒呼叫swtch來保存自己的上下文並恢復調度程序的上下文。每個上下文都包含在struct context(kernel/proc.h:2)中，它本身包含在進程的struct proc或CPU的struct cpu中。 swtch 採用兩個參數：struct context _old 和 struct context_ new。它將當前暫存器保存在old中，從new載入暫存器，然後返回。

讓我們追蹤一個透過 swtchin 到達調度程序的過程。我們在第4 章中看到，中斷結束時的一種可能性是usertrapcallsield.yield 轉而調用sched，它調用swtch 將當前上下文保存在p->context 中，並切換到先前保存在cpu->context (kernel/proc. c：506）。 swtch(kernel/swtch.S:3)僅保存被呼叫者保存的暫存器； C 編譯器在呼叫者中產生程式碼，以將呼叫者保存的暫存器保存在堆疊上。它不保存程式計數器。相反，swtch 保存了暫存器，

它保存了調用 swtch 的回傳地址。現在swtch從新上下文中還原暫存器，該上下文保存了先前swtch儲存的暫存器值。當swtch返回時，它會回到復原的暫存器所指向的指令，也就是新執行緒之前呼叫swtch的指令。此外，它會傳回新執行緒的堆疊，因為那是復原的點所在的位置。在我們的範例中，sched 呼叫 swtch 來切換到 cpu-> 上下文，即每 CPU 調度程式上下文。這個上下文是在調度程序呼叫swtch(kernel/proc.c:466)切換到現在放棄CPU的程序時保存的。當我們一直追蹤的swtch回傳時，它回傳的不是sched而是scheduler，堆疊指標位於目前CPU的調度程式堆疊中。

### 7.3 Code: Scheduling

最後一節介紹了 swtch 的底層細節；現在讓我們以給定的wtchas 為條件並檢查通過調度程序從一個進程的內核線程切換到另一個進程。調度程序以每個 CPU 的特殊執行緒的形式存在，每個執行緒都執行調度程序功能。此函數負責選擇接下來要運行哪個進程。想要放棄 CPU 的程序必須取得自己的程序鎖 p->lock，釋放其持有的任何其他鎖，更新自己的狀態 (p->state)，然後呼叫 sched。你可以在yield(kernel/proc.c:512)中看到這個序列，sleepandexit.sched雙重檢查其中一些要求(kernel/proc.c:496-501)，然後檢查一個含義：因為持有鎖，所以中斷應該被禁用。最後，sched呼叫swtch將目前上下文保存在p->context中，並切換到cpu->context中的調度程序上下文。 proc.c:466)。調度程序繼續其 for 循環，找到要執行的進程，切換到該進程，然後重複循環。我們剛剛看到 xv6 在呼叫 toswtch 時持有 sp->lock：swtch 的呼叫者必須已經持有該鎖，並且該鎖的控制權傳遞給切換到的程式碼。這種安排很不尋常：更常見的是獲取鎖的線程也釋放它。 Xv6 的上下文切換必須打破此約定，因為p->lock 保護進程的狀態和上下文欄位上的不變量，這些不變量在執行 inswtch 時不為真。例如，如果在 swtch 期間未保留 p->lock，則不同的 CPU 可能決定在將其狀態設為 RUNNABLE 之後運行該進程，但在 swtch 之前導致它停止使用自己的核心堆疊。結果將是兩個 CPU 在同一個堆疊上運行，這會導致混亂。 一旦yield開始修改正在運行的進程的狀態以使其可運行，p->lock必須保持保持狀態，直到恢復不變量：最早的正確釋放點是afterscheduler（在其自己的堆疊上運行）clearsc->proc 。類似地，一旦調度程式開始將 RUNNABLE 進程轉換為 RUNNING，鎖定就無法釋放，直到該進程的核心執行緒完全運行（在 swtch 之後，例如在 Yield 中）。核心執行緒放棄其 CPU 的唯一位置是 insched，並且它總是切換到調度程序中的相同位置，該位置（幾乎）總是切換到先前呼叫 sched 的某個核心執行緒。因此，如果要列印出xv6 切換執行緒的行號，則會觀察到以下簡單模式：(kernel/proc.c:466),(kernel/proc.c:466),(kernel/proc.c:466) ,(kernel/proc.c:466),(kernel/proc.c:466)c：506），

（核心/proc.c：466），（核心/proc.c：506），等等。透過執行緒切換故意將控制權轉移給彼此的過程有時稱為協程；在此範例中，sched 和schedulera 是彼此的協同例程。

有一種情況是調度程序對swtch 的呼叫沒有在sched 中結束。 forkretexists 來釋放thep->lock；否則，由於新進程需要返回到使用者空間，就像從 fork 返回一樣，因此它可以從 usertrapret 開始。

調度程序（kernel/proc.c:445）運行一個循環：找到一個要運行的進程，運行它直到它產生，重複。調度程序在進程表上循環尋找可運行的進程，即具有 sp->state == RUNNABLE 的進程。一旦找到進程，它就會設定每個 CPU 的目前進程變數 c->proc，將進程標記為 RUNNING，然後呼叫 swtch 開始運行它 (kernel/proc.c:461-466)。

### 7.4 Code: mycpu and myproc

Xv6 通常需要一個指向目前流程的過程結構的指標。在單處理器上，可以有一個指向目前進程的全域變數。這在多核心機器上不起作用，因為每個 CPU 執行不同的進程。解決這個問題的方法是利用每個CPU都有自己的一組暫存器。

當給定的CPU在核心中執行時，xv6確保CPU的stp暫存器始終保存CPU的hartid。 RISC-V 對其 CPU 進行編號，為每個 CPU 提供一個唯一的hartid.mycpu(kernel/proc.c:74)，使用stp 來索引一組 cpu 結構並傳回目前 CPU 的結構。 struct cpu(kernel/proc.h:22) 保存指向目前在該CPU 上執行的程序的proc 結構的指標（如果有）、為CPU 調度程式執行緒保存的暫存器以及管理中斷所需的巢狀自旋鎖的計數禁用。

確保CPU的stp持有CPU的hartid有點複雜，因為使用者程式碼可以自由修改tp。 page ，以防使用者程式碼修改它。最後，uservec恢復從使用者空間進入核心時所保存的tp（kernel/trampoline.S:78）。編譯器保證永遠不會修改核心程式碼。如果 xv6 可以在需要時向 RISC-V 硬體詢問當前的 hartid，那就更方便了，但 RISC-V 僅在機器模式下允許，在管理模式下不允許。 cpuid 和 mycpu 的回傳值很脆弱：如果計時器中斷並導致執行緒放棄並稍後在不同的 CPU 上恢復執行，則先前傳回的值將不再正確。為了避免這個問題，xv6要求呼叫者停用中斷，並且只有在使用完返回的struct cpu後才啟用它們。函數 myproc(kernel/proc.c:83) 傳回目前 CPU 上執行的程序的 struct proc 指標。即使啟用了中斷，myproc 的回傳值也可以安全使用：如果定時器中斷將呼叫程序移至不同的 CPU，其 struct procpointer 將保持不變。

### 7.5 Sleep and wakeup

Scheduling and locks help conceal the actions of one thread from another, but we also need ab-
stractions that help threads intentionally interact. For example, the reader of a pipe in xv6 may need
to wait for a writing process to produce data; a parent’s call towaitmay need to wait for a child
to exit; and a process reading the disk needs to wait for the disk hardware to finish the read. The
xv6 kernel uses a mechanism called sleep and wakeup in these situations (and many others). Sleep
allows a kernel thread to wait for a specific event; another thread can call wakeup to indicate that
threads waiting for a specified event should resume. Sleep and wakeup are often calledsequence
coordinationorconditional synchronizationmechanisms.
Sleep and wakeup provide a relatively low-level synchronization interface. To motivate the
way they work in xv6, we’ll use them to build a higher-level synchronization mechanism called
asemaphore[5] that coordinates producers and consumers (xv6 does not use semaphores). A
semaphore maintains a count and provides two operations. The “V” operation (for the producer)
increments the count. The “P” operation (for the consumer) waits until the count is non-zero,
and then decrements it and returns. If there were only one producer thread and one consumer
thread, and they executed on different CPUs, and the compiler didn’t optimize too aggressively,
this implementation would be correct:


100 struct semaphore { 101 struct spinlock lock; 102 int count; 103 }; 104 105 void 106 V(struct semaphore \*s) 107 { 108 acquire(&s->lock); 109 s->count += 1; 110 release(&s->lock); 111 } 112 113 void 114 P(struct semaphore \*s) 115 { 116 while(s->count == 0) 117 ; 118 acquire(&s->lock); 119 s->count -= 1; 120 release(&s->lock); 121 }

The implementation above is expensive. If the producer acts rarely, the consumer will spend
most of its time spinning in thewhileloop hoping for a non-zero count. The consumer’s CPU
could probably find more productive work thanbusy waitingby repeatedlypollings->count.


Avoiding busy waiting requires a way for the consumer to yield the CPU and resume only afterV
increments the count.
Here’s a step in that direction, though as we will see it is not enough. Let’s imagine a pair of
calls,sleepandwakeup, that work as follows.sleep(chan)waits for an event designated by
the value ofchan, called thewait channel.sleepputs the calling process to sleep, releasing the
CPU for other work.wakeup(chan)wakes all processes that are in calls tosleepwith the same
chan(if any), causing theirsleepcalls to return. If no processes are waiting onchan,wakeup
does nothing. We can change the semaphore implementation to usesleepandwakeup(changes
highlighted in yellow):


200 void 201 V(struct semaphore \*s) 202 { 203 acquire(&s->lock); 204 s->count += 1; 205 wakeup(s); 206 release(&s->lock); 207 } 208 209 void 210 P(struct semaphore \*s) 211 { 212 while(s->count == 0) 213 sleep(s); 214 acquire(&s->lock); 215 s->count -= 1; 216 release(&s->lock); 217 }

Pnow gives up the CPU instead of spinning, which is nice. However, it turns out not to be
straightforward to designsleepandwakeupwith this interface without suffering from what is
known as thelost wake-upproblem. Suppose thatPfinds thats->count == 0on line 212. While
Pis between lines 212 and 213,Vruns on another CPU: it changess->countto be nonzero and
callswakeup, which finds no processes sleeping and thus does nothing. NowPcontinues executing
at line 213: it callssleepand goes to sleep. This causes a problem:Pis asleep waiting for aVcall
that has already happened. Unless we get lucky and the producer callsVagain, the consumer will
wait forever even though the count is non-zero.
The root of this problem is that the invariant thatPsleeps only whens->count == 0is violated
byVrunning at just the wrong moment. An incorrect way to protect the invariant would be to move
the lock acquisition (highlighted in yellow below) inPso that its check of the count and its call to
sleepare atomic:


300 void 301 V(struct semaphore \*s) 302 { 303 acquire(&s->lock);

304 s->count += 1; 305 喚醒； 306 釋放(&s->lock); 307 } 308 309 void 310 P(struct semaphore \*s) 311 { 312 acquire(&s->lock); 313 while(s->count == 0) 314 sleep(s); 315 s->count -= 1; 316 釋放(&s->lock);第317章

One might hope that this version ofPwould avoid the lost wakeup because the lock preventsV
from executing between lines 313 and 314. It does that, but it also deadlocks:Pholds the lock
while it sleeps, soVwill block forever waiting for the lock.
We’ll fix the preceding scheme by changingsleep’s interface: the caller must pass thecon-
dition locktosleepso it can release the lock after the calling process is marked as asleep and
waiting on the sleep channel. The lock will force a concurrentVto wait untilPhas finished putting
itself to sleep, so that thewakeupwill find the sleeping consumer and wake it up. Once the con-
sumer is awake againsleepreacquires the lock before returning. Our new correct sleep/wakeup
scheme is usable as follows (change highlighted in yellow):


400 void 401 V(struct semaphore \*s) 402 { 403 acquire(&s->lock); 404 s->count += 1; 405 喚醒； 406 釋放(&s->lock); 407 } 408 409 void 410 P(struct semaphore \*s) 411 { 412 acquire(&s->lock); 413 while(s->count == 0) 414 sleep(s, &s->lock); 415 s->count -= 1;第416章 釋放（&s->lock）；第417章

The fact thatPholdss->lockpreventsVfrom trying to wake it up betweenP’s check of
s->countand its call tosleep. However,sleepmust releases->lockand put the consuming


從喚醒的角度來看，以原子的方式進行睡眠過程，以避免失去喚醒。

### 7.6 Code: Sleep and wakeup

Xv6的sleep(kernel/proc.c:548)和wakeup(kernel/proc.c:579)提供了上面最後一個範例所使用的介面。基本概念是讓 sleep 將目前程序標記為 SLEEPING，然後呼叫 ched 來釋放 CPU；wakeup 尋找在給定等待通道上休眠的程序並將其標記為 RUNNABLE。睡眠和喚醒的呼叫者可以使用任何彼此方便的號碼作為通道。 Xv6經常使用參與等待的核心資料結構的位址。 sleepacquiresp->lock(kernel/proc.c:559)，然後才釋放slk。正如我們將看到的，睡眠始終持有這些鎖中的一個或另一個這一事實阻止了並發喚醒（必須獲取並持有這兩個鎖）的執行。現在sleep只持有p->lock，它可以透過記錄睡眠通道、將行程狀態改為SLEEPING並呼叫sched(kernel/proc.c:563-566)來讓行程進入睡眠狀態。稍後您就會清楚為什麼在進程被標記為睡眠之前不釋放 p->lock（由調度程式）這一點很重要。在某個時刻，進程將取得條件鎖，設定休眠程式正在等待的條件，並呼叫wakeup(chan)。重要的是，在進程表上保持條件鎖^1 .wakeuploops 時呼叫wakeup (kernel/proc.c:579)。它取得它檢查的每個進程的 p->lock。當wakeup發現一個進程處於SLEEPING狀態並且具有匹配的chan時，它會將該進程的狀態變更為RUNNABLE。下次調度程序運行時，它將看到該進程已準備好運行。為什麼睡眠和喚醒的鎖定規則要確保將要睡眠的進程不會錯過並發喚醒？進入睡眠狀態的程序在檢查條件之前一直持有條件鎖或它自己的 p->lock，或兩者都持有，直到它被標記為 SLEEPING 為止。 呼叫wakeup的程序在wakeup的循環中同時持有兩個鎖。因此，喚醒器要麼在消費執行緒檢查條件之前使條件為真；要麼使條件為真。或喚醒者的wakeup在睡眠線程被標記為SLEEPING後嚴格檢查它。然後wakeup會看到睡眠進程並喚醒它（除非有其他東西先喚醒它）。有時多個進程在同一個頻道上休眠；例如，多個進程從管道讀取資料。只需呼叫一次喚醒即可將它們全部喚醒。其中一個將首先運行並獲取調用 sleep 的鎖，並且（在管道的情況下）讀取正在等待的任何資料。其他進程會發現，儘管被喚醒，卻沒有資料可讀取。從他們的角度來看，這次喚醒是“虛假的”，他們必須再次入睡。因此，總是在檢查條件的循環內呼叫 sleep。如果兩次使用睡眠/喚醒意外選擇相同的通道，則不會造成任何損害：它們會看到虛假喚醒，但如上所述的循環將容忍此問題。睡眠/喚醒的大部分魅力在於它既是輕量級的（不需要創建特殊的資料結構來充當睡眠通道），又提供了一個間接層（呼叫者不需要知道他們正在與哪個特定進程交互）。

(^1) 嚴格來說，如果wakeup只跟隨acquire就足夠了（也就是說，可以在release之後調用wakeup）。

### 7.7 代碼：管道

一個使用睡眠和喚醒來同步生產者和消費者的更複雜的範例是 xv6 的管道實現。我們在第一章中看到了管道的介面：寫入管道一端的位元組被複製到核心緩衝區中，然後可以從管道的另一端讀取。未來的章節將研究管道周圍的文件描述符支持，但現在讓我們看看管道寫入和管道讀取的實現。每個管道由一個結構體管道表示，其中包含一個鎖和一個資料緩衝區。欄位 nread 和 nwritecount 是從緩衝區讀取和寫入緩衝區的總位元組數。緩衝區迴繞：在buf\[PIPESIZE-1\]之後寫入的下一個位元組是buf\[0\]。計數不換行。此約定允許實作區分完整緩衝區(nwrite == nread+PIPESIZE) 和空緩衝區(nwrite == nread)，但這表示對緩衝區的索引必須使用buf\[nread % PIPESIZE\] 而不是buf\[nread\] ( nwrite 也類似）。假設piperead和pipewrite的呼叫同時發生在兩個不同的CPU上。 pipe.c:106 ）然後也嘗試取得鎖，但不能。它在acquire(kernel/spinlock.c:22)中旋轉等待鎖。當piperead等待時，pipewrite循環遍歷正在寫入的位元組(addr\[0..n-1\])，依序將每個位元組加入管道(kernel/pipe.c:95)。在此循環期間，緩衝區可能會被填滿（kernel/pipe.c:88）。在這種情況下，pipewrite 呼叫wakeup 來提醒任何睡眠的讀取器，緩衝區中有資料正在等待，然後在&pi->nwrite 上休眠，等待讀取器從緩衝區中取出一些位元組。sleep 會釋放管道的鎖，作為將 pipelinewrite 進程置於睡眠狀態的一部分。 pipelinereadnow 取得管道的鎖並進入其臨界區：它發現 pi->nread != pi->nwrite(kernel/pipe.c:113)(pipewrite 進入睡眠狀態，因為 pi->nwrite == pi->nread

*   PIPESIZE(kernel/pipe.c:88))，因此它會進入 for 循環，從管道 (kernel/pipe.c:120) 複製數據，並按複製的位元組數遞增 nread。現在有這麼多位元組可供寫入，因此piperead呼叫wakeup(kernel/pipe.c:127)以在返回之前喚醒任何休眠的寫入器。正在運行pipewrite但在緩衝區填滿時停止。它將該進程標記為可運行。管道代碼對讀取器和寫入器使用單獨的睡眠通道 (pi->nreadandpi->nwrite)；萬一有很多讀者和作者等待同一個管道，這可能會使系統更有效率。管道代碼在循環內休眠，檢查休眠條件；如果有多個讀取器或寫入器，則除了第一個喚醒的進程之外的所有進程都會看到條件仍然為假並再次睡眠。

### 7.8 代碼：等待、退出、終止

sleep和wakeup可用於多種等待。第一章介紹的一個有趣的例子是孩子的退出和父母的等待之間的互動。當孩子死亡時，父母可能已經在睡覺，或者可能正在做其他事情；在後一種情況下，隨後對 wait 的調用必須觀察子進程的死亡，也許在它調用很久之後

出口。 xv6 記錄子程序死亡直到wait 觀察到它的方式是forexit 將呼叫者置於ZOMBIE 狀態，它會一直保持在該狀態，直到父進程的wait 注意到它，將子進程的狀態更改為UNUSED，複製子進程的退出狀態，並將子進程的進程ID 回傳給父進程。如果父進程在子進程之前退出，則父進程將子進程交給 init 進程，該進程將永遠呼叫 wait；因此，每個孩子都有一個父母來清理。一個挑戰是避免同時父級和子級等待和退出以及同時退出和退出之間的競爭和死鎖。

wait 透過取得 wait\_lock(kernel/proc.c:391) 開始，它充當條件鎖，有助於確保 wait 不會錯過從現有子程序中喚醒。然後等待掃描進程表。如果它找到處於ZOMBIE 狀態的子進程，它會釋放該子進程的資源及其過程結構，將子進程的退出狀態複製到提供給wait 的位址（如果不是0），並傳回子進程的進程ID 。如果wait找到子程序但沒有退出，它會呼叫sleep來等待它們中的任何一個退出（kernel/proc.c:433），然後再掃描。 ->lock；避免死鎖的順序是先wait\_lock，然後pp->lock。

exit(kernel/proc.c:347)記錄退出狀態，釋放一些資源，呼叫reparent將其子進程交給init進程，喚醒處於等待狀態的父進程，將呼叫者標記為殭屍，並永久讓出CPU。 exitholds wait\_lock 和 p->lock 皆在此序列期間。它持有wait\_lock，因為它是喚醒(p->parent) 的條件鎖，防止等待中的父級丟失喚醒。最終呼叫switch 之前看到子級處於ZOMBIE 狀態。

在將其狀態設為ZOMBIE 之前喚醒父進程可能看起來不正確，但這是安全的：雖然喚醒可能會導致父進程運行，但wait 中的循環無法檢查子進程，直到子進程的sp->lock被調度程序釋放，因此wait 無法查看退出進程，直到退出後將其狀態設定為 ZOMBIE (kernel/proc.c:379)。

exit 允許行程自行終止，而kill(kernel/proc.c:598) 則允許一個行程請求另一個行程終止。如果直接破壞受害者進程，kill 會太複雜，因為受害者可能正在另一個 CPU 上執行，也許正在對核心資料結構進行敏感的更新序列。因此kill 的作用非常小：它只是設定受害者的p->killed，如果受害者正在睡覺，則將其喚醒。最終受害者將進入或離開內核，此時usertrap中的程式碼將呼叫exitifp->killedis設定（它透過呼叫killed（kernel/proc.c:627）進行檢查）。如果受害者運行在使用者空間，它很快就會透過系統呼叫或定時器（或其他裝置）中斷進入核心。

如果受害者進程處於睡眠狀態，kill 的喚醒呼叫將導致受害者從睡眠中返回。這具有潛在的危險，因為正在等待的條件可能不成立。然而，xv6 呼叫 tosleepare 總是包含在 whileloop 中，該迴圈在 sleep 返回後重新測試條件。有些呼叫 tosleep 也會在迴圈中測試 p->killed，並放棄目前活動（如果已設定）。只有當這種放棄是正確的時候才會這麼做。例如，管道讀寫程式碼(kernel/pipe.c:84)如果設定了killed標誌則回傳；最終程式碼將返回陷阱，陷阱將再次檢查 p->killed 並退出。

某些 xv6sleeploops 不會檢查 p->killed，因為程式碼處於應該是原子的多步驟系統呼叫的中間。 virtio 驅動程式（kernel/virtio\_disk.c:285）就是一個例子：

不檢查p->killed，因為磁碟操作可能是使檔案系統保持正確狀態所需的一組寫入操作之一。在等待磁碟 I/O 時被終止的進程在完成目前系統呼叫並且使用者陷阱看到終止標誌之前不會退出。

### 7.9 Process Locking

與每個程序關聯的鎖 (p->lock) 是 xv6 中最複雜的鎖。考慮p->lock 的一個簡單方法是，在讀取或寫入以下任何struct procfields 時必須保留它：p->state、p->chan、p->killed、p->xstate 和p->pid 。這些欄位可以被其他行程使用，或是被其他CPU上的排程器執行緒使用，所以它們自然必須受到鎖的保護。然而，p->lock 的大多數用途都是保護 xv6 過程資料結構和演算法的更高層次方面。以下是 p->lock 所做的全套事情：

*   與 p->state 一起，它可以防止為新進程分配 proc\[\] 槽時出現競爭。
*   它在創建或銷毀進程時隱藏進程。
*   它阻止父進程的 wait 收集已將其狀態設為 ZOMBIE 但尚未釋放 CPU 的進程。
*   它可以防止另一個 CPU 的調度程序在將其狀態設為 RUNNABLE 之後但在完成切換之前決定運行讓步進程。
*   它確保只有一個 CPU 的調度程式決定執行 RUNNABLE 進程。
*   它可以防止定時器中斷導致程序在插入時放棄。
*   與條件鎖定一起，它有助於防止喚醒忽略正在呼叫睡眠但尚未完成 CPU 釋放的程序。
*   它可以防止kill 的受害進程退出並可能在kill 檢查p->pid 和設定p->killed 之間重新分配。
*   它使kill對p->state的檢查和寫入原子化。

p->parent 欄位受全域鎖定 wait\_lock 而非 p->lock 保護。儘管進程本身和搜尋其子進程的其他進程都會讀取該字段，但只有進程的父進程會修改 p->parent。 wait\_lock的目的是在waitsleep等待任何子程序退出時充當條件鎖。退出的子進程將持有wait\_lock 或p->lock，直到將其狀態設為ZOMBIE、喚醒其父進程並釋放CPU。 ）從它的 wait 中喚醒。

### 7.10 Real world

xv6調度器實作了一個簡單的調度策略，它依序運行每個行程。此策略稱為循環法。真實的作業系統實作更複雜的策略，例如允許進程具有優先權。這個想法是，調度程序將優先選擇可運行的高優先權進程，而不是可運行的低優先權進程。這些策略可能很快就會變得複雜，因為經常存在相互競爭的目標：例如，作業系統可能也希望保證公平性和高吞吐量。此外，複雜的策略可能會導致意外的交互，例如優先反轉和車隊。當低優先權進程和高優先權進程都使用特定的鎖時，就會發生優先權反轉，低優先權行程取得該鎖時會阻止高優先權行程取得進展。當許多高優先權進程正在等待獲取共享鎖的低優先權進程時，就會形成一長串等待進程；車隊一旦形成，就可以持續很久。為了避免此類問題，複雜的調度程序中需要額外的機制。 sleep和wakeup是一種簡單而有效的同步方法，但還有很多其他方法。所有這些挑戰中的第一個挑戰是避免我們在本章開頭看到的「喚醒丟失」問題。最初的 Unix 核心的睡眠只是禁用了中斷，這已經足夠了，因為 Unix 運行在單 CPU 系統上。因為 xv6 在多處理器上運行，所以它添加了一個明確的鎖來睡眠。 FreeBSD 的 smsleep 採用相同的方法。 Plan 9 的sleep 使用一個回呼函數，該函數在睡前持有調度鎖的情況下運行；此功能用作睡眠狀況的最後一刻檢查，以避免丟失喚醒。 Linux核心的sleep使用明確的進程佇列，稱為等待佇列，而不是等待通道；隊列有自己的內部鎖。在喚醒時掃描整個進程集效率很低。更好的解決方案是用一個資料結構取代睡眠和喚醒中的鏈，該資料結構保存在該結構上睡眠的進程列表，例如 Linux 的等待隊列。計劃 9 的睡眠和喚醒呼叫構成了集合點。許多線程庫引用相同的結構作為條件變數；在這種情況下，睡眠和喚醒操作稱為等待和訊號。所有這些機制都有相同的特徵：睡眠條件受到睡眠期間原子刪除的某種鎖的保護。 wakeup 的實作會喚醒在特定通道上等待的所有進程，並且可能存在許多進程正在等待該特定通道的情況。作業系統將調度所有這些進程，並且它們將競相檢查睡眠狀況。以這種方式運行的進程有時被稱為“驚群”，最好避免這種情況。大多數條件變數都有兩種喚醒原語：訊號（喚醒一個行程）和廣播（喚醒所有等待流程）。信號量通常用於同步。此計數通常對應於管道緩衝區中可用的位元組數或進程具有的殭屍子程序的數量。使用顯式計數作為抽象的一部分可以避免「喚醒遺失」問題：對已發生的喚醒次數進行明確計數。該計數還避免了虛假喚醒和驚群問題。終止進程並清理它們在 xv6 中引入了許多複雜性。在大多數作業系統中，它甚至更加複雜，因為，例如，受害進程可能很深

在核心休眠和展開其堆疊時需要小心，因為呼叫堆疊上的每個函數可能需要進行一些清理。有些語言透過提供異常機制來提供幫助，但 C 則不然。例如，當一個 Unix 進程正在睡眠時，另一個進程可能會向它發送訊號。在這種情況下，進程將從中斷的系統呼叫中傳回，傳回值為 -1，錯誤代碼設定為 EINTR。應用程式可以檢查這些值並決定做什麼。 Xv6 不支援訊號，因此不會出現這種複雜性。 Xv6 對kill 的支持並不完全令人滿意：有一些睡眠循環可能應該檢查p->killed。一個相關的問題是，即使對於檢查 p->killed 的 sleeploops，sleep 和kill 之間也存在競爭；後者可能會設定 p->killed 並嘗試在受害者循環檢查 sp->killed 之後但調用 sleep 之前喚醒受害者。如果發生此問題，受害者將不會注意到 p->killed，直到其等待的情況發生。這可能會晚一些，甚至永遠不會發生（例如，如果受害者正在等待來自控制台的輸入，但用戶沒有鍵入任何輸入）。真實的作業系統會在常數時間內找到具有明確空閒清單的 freeproc 結構，而不是在 allocproc 中進行線性時間搜尋；為了簡單起見，xv6 使用線性掃描。

### 7.11 Exercises

1. 在xv6中實現信號量而不使用sleep和wakeup（但使用自旋鎖是可以的）。選擇 xv6 的睡眠和喚醒的一些用法，並將其替換為信號量。判斷結果。
2. 修復上面提到的kill 和sleep 之間的競爭，以便在受害者的睡眠循環檢查sp->killed 之後但在調用sleep 之前發生的kill 會導致受害者放棄當前的系統呼叫。
3. 設計一個計劃，以便每個睡眠循環都檢查 sp->killed，以便 virtio 驅動程式中的進程在被另一個進程殺死時可以快速從 while 循環返回。
4. 修改 xv6，使其在從一個行程的核心執行緒切換到另一個行程的核心執行緒時僅使用一次上下文切換，而不是透過調度程序執行緒進行切換。讓步線程需要選擇下一個線程本身並呼叫wtch。挑戰在於防止多個 CPU 意外執行同一個執行緒；正確鎖定；並避免僵局。
5. 修改xv6的調度程序以在沒有進程可運行時使用RISC-VWFI（等待中斷）指令。嘗試確保只要有可運行進程等待運行，WFI 中就沒有 CPU 暫停。

第8章
===

檔案系統
====

文件系統的目的是組織和儲存資料。檔案系統通常支援使用者和應用程式之間的資料共享以及持久性，以便資料在重新啟動後仍然可用。 xv6 檔案系統提供類別 Unix 的檔案、目錄和路徑名稱（請參閱第 1 章），並將其資料儲存在 virtio 磁碟上以實現持久性。文件系統解決了幾個挑戰：

*   檔案系統需要磁碟上的資料結構來表示命名目錄和檔案的樹，記錄保存每個檔案內容的區塊的標識，並記錄磁碟的哪些區域是空閒的。
*   檔案系統必須支援崩潰恢復。也就是說，如果發生崩潰（例如電源故障），檔案系統在重新啟動後仍必須正常運作。風險在於崩潰可能會中斷一系列更新並留下不一致的磁碟資料結構（例如，既在檔案中使用又標記為空閒的區塊）。
*   不同的進程可能同時對檔案系統進行操作，因此檔案系統程式碼必須協調以保持不變量。
*   存取磁碟比存取記憶體慢幾個數量級，因此檔案系統必須維護常用區塊的記憶體快取。

The rest of this chapter explains how xv6 addresses these challenges.


### 8.1 概述

xv6 檔案系統實作分為七層，如圖 8.1 所示。磁碟層在 virtio 硬碟上讀取和寫入區塊。緩衝區快取層快取磁碟區塊並同步對它們的訪問，確保一次只有一個核心進程可以修改儲存在任何特定區塊中的資料。日誌記錄層允許更高層將更新包裝到交易中的多個區塊，並確保在崩潰時自動更新區塊（即全部更新或不更新）。 inode 層提供單獨的文件，每個文件

Directory


Inode


Logging


Buffer cache


Pathname


File descriptor


(^) 磁碟^ 圖 8.1：xv6 檔案系統的層。表示為具有唯一 i 編號的節點和一些保存檔案資料的區塊。目錄層將每個目錄實作為一種特殊的索引節點，其內容是一系列目錄條目，每個目錄條目包含一個檔案名稱和 i 號。路徑名層提供了像/usr/rtm/xv6/fs.c這樣的分層路徑名，並透過遞歸查找來解析它們。檔案描述符層使用檔案系統介面抽象化許多Unix資源（例如管道、裝置、檔案等），簡化了應用程式設計師的工作。磁碟硬體傳統上將磁碟上的資料表示為 512 位元組區塊（也稱為磁區）的編號序列：磁區 0 是前 512 位元組，磁區 1 是下一個位元組，依此類推。作業系統用於其檔案系統的區塊大小可能與磁碟使用的磁區大小不同，但通常區塊大小是磁區大小的倍數。 Xv6 在型別結構 buf(kernel/buf.h:1) 的物件中儲存已讀入記憶體的區塊的副本。此結構中儲存的資料有時與磁碟不同步：它可能尚未從磁碟讀取（磁碟正在處理它，但尚未返回磁區的內容），或者它可能已更新軟體但尚未寫入磁碟。檔案系統必須規劃在磁碟上儲存 inode 和內容區塊的位置。為此，xv6 將磁碟分為幾個部分，如圖 8.2 所示。檔案系統不使用區塊 0（它保存引導磁區）。區塊 1 稱為超級區塊；它包含有關檔案系統的元資料（以區塊為單位的檔案系統大小、資料區塊的數量、inode 的數量以及日誌中的區塊的數量）。 從 2 開始的區塊保存日誌。日誌之後是索引節點，每個區塊有多個索引節點。之後是點陣圖塊，追蹤哪些資料塊正在使用。其餘塊為資料塊；每個都在點陣圖區塊中標記為空閒，或儲存檔案或目錄的內容。超級區塊由一個名為 mkfs 的單獨程式填充，該程式建構初始檔案系統。本章的其餘部分將討論每一層，從緩衝區快取開始。留意在較低層精心選擇的抽象可以簡化較高層設計的情況。

0


bootsuper log inodes bit map data


1


.... data


2


Figure 8.2: Structure of the xv6 file system.


### 8.2 Buffer cache layer

緩衝區高速緩存有兩個工作：（1）同步對磁碟區塊的訪問，以確保記憶體中只有一個區塊的副本，並且一次只有一個核心執行緒使用該副本； (2)快取流行的區塊，這樣就不需要從慢速磁碟重新讀取它們。程式碼是inbio.c。 buffer cache導出的主要介面由bread和bwrite組成；前者取得包含可以在記憶體中讀取或修改的區塊的副本的 abuf，後者將修改後的緩衝區寫入磁碟上的對應區塊。內核執行緒在使用緩衝區後必須透過呼叫 brelse 來釋放該緩衝區。緩衝區快取使用每個緩衝區睡眠鎖來確保一次只有一個執行緒使用每個緩衝區（以及每個磁碟區塊）；bread 傳回鎖定的緩衝區，brelse 釋放鎖定。讓我們回到緩衝區高速緩存。緩衝區高速緩存具有固定數量的緩衝區來保存磁碟區塊，這表示如果檔案系統請求高速緩存中尚未存在的區塊，則緩衝區快取必須回收目前保存其他區塊的緩衝區。緩衝區高速緩存為新區塊回收最近最少使用的緩衝區。假設最近最少使用的緩衝區是最不可能很快再使用的緩衝區。

### 8.3 Code: Buffer cache

緩衝區高速緩存是緩衝區的雙向鍊錶。函數 binit 由 main(kernel/- main.c:27) 調用，使用靜態數組 buf(kernel/bio.c:43-52) 中的 NBUF 緩衝區初始化清單。對緩衝區高速緩存的所有其他存取均引用鍊錶 viabcache.head，而不是 bufarray。緩衝區有兩個與其關聯的狀態欄位。字段valid指示緩衝區包含區塊的副本。欄位dis表示緩衝區內容已交給磁碟，這可能會改變緩衝區（例如，將資料從磁碟寫入資料）。 bread(kernel/bio.c:93)呼叫bget來取得給定磁區(kernel/bio.c:97)的緩衝區。如果需要從磁碟讀取緩衝區，則bread會在返回緩衝區之前呼叫virtio\_disk\_rw來執行此操作。 bget(kernel/bio.c:59) 掃描緩衝區清單以尋找具有給定設備和磁區號碼的緩衝區 (kernel/bio.c:65-73)。如果存在這樣的緩衝區，則 bget 取得該緩衝區的睡眠鎖定 然後 bget 傳回鎖定的緩衝區。如果給定磁區沒有快取緩衝區，則 bget 必須建立一個緩衝區，可能會重複使用保存不同磁區的緩衝區。它第二次掃描緩衝區列表，尋找未使用的緩衝區 (b->refcnt = 0)；可以使用任何此類緩衝區。請注意，賦值b->valid = 0 確保bread 將從磁碟讀取區塊數據，而不是錯誤地使用緩衝區的資料。

以前的內容。重要的是，每個磁碟區最多有一個快取緩衝區，以確保讀取器看到寫入，並且因為檔案系統使用緩衝區上的鎖來進行同步。持續持有thebache.lock bcache.lock 來確保這一不變性透過第二個循環聲明該區塊現在已被快取（透過設定dev、blockno和refcnt）來判斷該區塊是否已被快取。這會導致檢查區塊是否存在以及（如果不存在）用於保存該區塊的緩衝區的指定是原子的。 bget 在 bcache.lock 關鍵部分之外取得緩衝區的睡眠鎖是安全的，因為非零 b->refcnt 會阻止緩衝區被重新用於不同的磁碟區塊。睡眠鎖保護區塊緩衝內容的讀取和寫入，而 bcache.lock 保護有關快取哪些區塊的資訊。如果所有緩衝區都忙，則表示有太多進程同時執行檔案系統呼叫；bgetpanics。更優雅的反應可能是休眠直到緩衝區空閒，儘管這樣可能會出現死鎖。一旦bread讀取磁碟（如果需要）並將緩衝區傳回給其呼叫者，呼叫者就可以獨佔使用該緩衝區並可以讀取或寫入資料位元組。如果呼叫者確實修改了緩衝區，則必須在釋放緩衝區之前呼叫bwrite將更改的資料寫入磁碟。當呼叫者使用緩衝區後，必須呼叫brelse 來釋放它。 （brelse 這個名字是 b-release 的縮寫，很神秘，但值得學習：它起源於 Unix，也用於 BSD、Linux 和 Solaris。）brelse(kernel/bio.c:117)釋放睡眠鎖並將緩衝區移到鍊錶的前面(kernel/bio.c:128-133)。移動緩衝區會導致清單按照緩衝區最近使用的時間（即釋放）進行排序：清單中的第一個緩衝區是最近使用的緩衝區，最後一個緩衝區是最近最少使用的緩衝區。 bget 中的兩個循環利用了這一點：在最壞的情況下，對現有緩衝區的掃描必須處理整個列表，但是當存在良好的引用局部性時，首先檢查最近使用的緩衝區（從bcache .head 開始並跟隨下一個指標）將減少掃描時間。選擇要重複使用的緩衝區的掃描透過向後掃描（以下 prev 指標）來選擇最近最少使用的緩衝區。

### 8.4 Logging layer

檔案系統設計中最有趣的問題之一是崩潰復原。出現此問題的原因是許多檔案系統操作涉及對磁碟的多次寫入，並且寫入子集後發生崩潰可能會使磁碟上的檔案系統處於不一致的狀態。例如，假設在檔案截斷期間發生崩潰（將檔案長度設為零並釋放其內容區塊）。根據磁碟寫入的順序，當機可能會留下對標記為空閒的內容區塊的引用的索引節點，也可能會留下已指派但未引用的內容區塊。後者相對良性，但引用已釋放區塊的 inode 可能會在重新啟動後導致嚴重問題。重新啟動後，核心可能會將該區塊分配給另一個文件，現在我們有兩個不同的文件無意中指向同一個區塊。如果 xv6 支援多個用戶，這種情況可能會成為安全問題，因為舊檔案的擁有者將能夠讀取

並在新文件中寫入由不同使用者擁有的區塊。 Xv6 透過簡單的日誌記錄形式解決了檔案系統操作期間的崩潰問題。 xv6 系統呼叫不會直接寫入磁碟檔案系統資料結構。相反，它會在磁碟上放置它希望進行的所有磁碟寫入的描述。一旦系統呼叫記錄了所有寫入操作，它就會向磁碟寫入一個特殊的提交記錄，指示日誌包含完整的操作。此時，系統呼叫將寫入內容複製到磁碟檔案系統資料結構。這些寫入完成後，系統呼叫會擦除磁碟上的日誌。如果系統崩潰並重新啟動，檔案系統程式碼會在運行任何進程之前按以下方式從崩潰中恢復。如果日誌被標記為包含完整操作，則復原程式碼會將寫入內容複製到磁碟檔案系統中它們所屬的位置。如果日誌未標記為包含完整操作，則復原代碼將忽略該日誌。恢復代碼透過擦除日誌來完成。為什麼xv6的日誌解決了檔案系統操作時會崩潰的問題？如果當機發生在操作提交之前，則磁碟上的日誌將不會被標記為完成，復原程式碼將忽略它，並且磁碟的狀態將就像操作尚未開始一樣。如果當機發生在操作提交之後，那麼復原將重播該操作的所有寫入，如果該操作已開始將它們寫入磁碟資料結構，則可能會重複它們。在任何一種情況下，日誌都會使操作相對於崩潰而言是原子的：恢復後，要么所有操作的寫入都出現在磁碟上，要么都不出現。

### 8.5 Log design

日誌駐留在超級區塊中指定的已知固定位置。它由一個標頭區塊組成，後面跟著一系列更新的區塊副本（“記錄區塊”）。標頭區塊包含一組磁區號（每個記錄區塊對應一個磁區號）以及記錄區塊的計數。磁碟上標頭區塊中的計數要麼為零，表示日誌中沒有事務，要麼非零，表示日誌包含具有指定數量的已記錄區塊的完整提交事務。 Xv6 在交易提交時（而不是之前）寫入標頭區塊，並在將記錄的區塊複製到檔案系統後將計數設為零。因此，事務中途崩潰將導致日誌標頭區塊中的計數為零；提交後崩潰將導致非零計數。每個系統呼叫的程式碼指示寫入序列的開始和結束，這些寫入序列對於崩潰而言必須是原子的。為了允許不同進程並發執行檔案系統操作，日誌系統可以將多個系統呼叫的寫入累積到一個事務中。因此，單一提交可能涉及多個完整系統呼叫的寫入。為了避免跨事務分割系統調用，日誌系統僅在沒有檔案系統系統調用正在進行時提交。一起提交多個事務的想法稱為群組提交。群組提交減少了磁碟操作的數量，因為它將提交的固定成本分攤到多個操作上。群組提交還可以同時為磁碟系統提供更多並發寫入，也許允許磁碟在單一磁碟旋轉期間將它們全部寫入。 Xv6 的 virtio 驅動程式不支援這種批次處理，但 xv6 的檔案系統設計允許這樣做。

Xv6 在磁碟上指定固定數量的空間來保存日誌。事務中系統呼叫寫入的區塊總數必須適合該空間。這有兩個後果。不允許單一系統呼叫寫入比日誌中的空間更多的不同區塊。對於大多數系統呼叫來說這不是問題，但其中兩個呼叫可能會寫入許多區塊：writeandunlink。大檔案寫入可能會寫入很多資料塊和很多點陣圖塊以及一個inode塊；取消連結大檔案可能會寫入許多位圖塊和一個索引節點。 Xv6 的 write 系統呼叫將大型寫入分解為適合日誌的多個較小寫入，且 unlink 不會導致問題，因為實際上 xv6 檔案系統只使用一個位圖塊。有限日誌空間的另一個後果是日誌系統不能允許系統呼叫啟動，除非確定係統呼叫的寫入適合日誌中的剩餘空間。

### 8.6 Code: logging

系統呼叫中日誌的典型用法如下：

開始\_操作（）； ... bp = 麵包(...); bp->data\[...\] = ...; log\_write(bp); .... end\_op(); begin\_op(kernel/log.c:127) 等待，直到日誌系統目前未提交，並且直到有足夠的未保留日誌空間來保存此呼叫的寫入。總保留空間為log.outstanding timesMAXOPBLOCKS。 Incrementinglog.outstandingboth 保留空間並防止在此系統呼叫期間發生提交。該程式碼保守地假設每個系統呼叫可能寫入最多 MAXOPBLOCKS 個不同的區塊。 log\_write(kernel/log.c:215) 充當 bwrite 的代理。它在記憶體中記錄區塊的磁區號，在磁碟上的日誌中為其保留一個插槽，並將緩衝區固定在區塊快取中以防止區塊快取將其驅逐。該區塊必須保留在快取中直到提交：在此之前，快取的副本是修改的唯一記錄；在提交之後才能將其寫入磁碟上的位置；當在單一交易期間多次寫入區塊時，相同交易中的其他讀取必須看到修改。這種優化通常稱為吸收。例如，常見的是，包含多個檔案的 inode 的磁碟區塊在一個事務中被寫入多次。透過將多個磁碟寫入吸收為一個，檔案系統可以節省日誌空間並可以獲得更好的效能，因為只需將磁碟區塊的副本寫入磁碟即可。 end\_op(kernel/log.c:147) 先減少未完成的系統呼叫的計數。如果計數現在為零，則透過呼叫commit()提交目前事務。c:179) 將交易中修改的每個區塊從緩衝區快取複製到 disk.write\_head()(kernel/log.c:179) 上日誌中的插槽。c:103) 將標頭區塊寫入磁碟：這是提交點，寫入後崩潰將導致復原重播

log.install\_trans(kernel/log.c:69) 中的事務寫入從日誌中讀取每個區塊並將其寫入檔案系統中的正確位置。最後end\_op寫入計數為零的日誌頭；這必須在下一個事務開始寫入記錄塊之前發生，這樣崩潰就不會導致使用一個事務的標頭和後續事務的記錄塊進行恢復。

recovery\_from\_log(kernel/log.c:117) 被呼叫frominitlog(kernel/log.c:55)，在第一個使用者程序執行之前的啟動過程中被呼叫fromfsinit(kernel/fs.c:42)(kernel/ proc.c) ：535）。它會讀取日誌標頭，如果標頭指示日誌包含已提交的事務，則模仿 end\_op 的操作。

日誌的使用範例出現在 filewrite(kernel/file.c:135) 中。交易看起來像這樣：

begin_op();
ilock(f->ip);
r = writei(f->ip, ...);
iunlock(f->ip);
end_op();


該程式碼包含在一個循環中，該循環將大型寫入一次分解為幾個扇區的單獨事務，以避免日誌溢出。對 writei 的呼叫會寫入許多區塊作為此交易的一部分：檔案的索引節點、一個或多個位圖區塊以及一些資料區塊。

### 8.7 Code: Block allocator

檔案和目錄內容儲存在磁碟區塊中，必須從空閒池中分配磁碟區塊。 Xv6 的區塊分配器在磁碟上維護一個空閒位圖，每個區塊一位。零位表示對應的區塊是空閒的；一位表示它正在使用。程式mkfs設定與引導磁區、超級區塊、日誌區塊、索引節點區塊和點陣圖區塊相對應的位元。

區塊分配器提供兩個函數：balllocal分配一個新的磁碟區塊，bfree釋放一個區塊。中塊的數量系統。它尋找位圖位元為零的區塊，表示它是空閒的。如果balloc找到這樣的區塊，它會更新位圖並傳回該區塊。為了提高效率，循環被分成兩個部分。外循環讀取每個位圖位塊。內部循環檢查單一點陣圖塊中的所有每塊位元 (BPB) 位元。由於緩衝區高速緩存一次只允許一個進程使用任意一個點陣圖區塊，因此可以防止兩個進程同時嘗試分配一個區塊時可能發生的競爭。

bfree(kernel/fs.c:92) 找到正確的點陣圖塊並清除正確的位元。同樣，bread 和 brelsea 隱含的獨佔使用避免了明確鎖定的需要。

與本章其餘部分所描述的大部分程式碼一樣，ballocandbfree 必須在事務內部呼叫。

### 8.8 Inode layer

術語“minodecan”具有兩個相關含義之一。它可能指的是包含檔案大小和資料區塊編號清單的磁碟資料結構。或者「inode」可能指的是記憶體中的inode，其中包含磁碟上的inode 的副本以及核心中所需的額外資訊。磁碟上的索引節點被打包到稱為索引節點區塊的磁碟連續區域。每個 inode 的大小相同，因此給定數字 n，很容易找到磁碟上的第 n 個 inode。事實上，這個數字n，稱為inode編號或i-number，是實現中識別inode的方式。磁碟上的 inode 由 astruct dinode(kernel/fs.h:32) 定義。類型欄位區分檔案、目錄和特殊檔案（設備）。零類型表示磁碟上的索引節點是空閒的。然後linkfield 計算引用該inode 的目錄條目的數量，以便識別何時應釋放磁碟上的inode 及其資料區塊。 size 欄位記錄檔案中內容的位元組數。 addrs數組記錄保存檔案內容的磁碟區塊的區塊號。核心將記憶體中的活動 inode 集合保存在名為 itable 的表中；struct inode (kernel/file.h:17) 是 struct dinode 在磁碟上的記憶體中副本。只有當存在引用該 inode 的 C 指標時，核心才會在記憶體中儲存該 inode。 Thereffield 計算引用記憶體中 inode 的 C 指標的數量，如果引用計數降至零，則核心會從記憶體中丟棄該 inode。 getandiput 函數取得並釋放指向 inode 的指針，從而修改引用計數。指向 inode 的指標可以來自檔案描述符、目前工作目錄和瞬時核心程式碼（例如 exec）。 xv6的inode程式碼中有四種鎖或類似鎖的機制。每個記憶體中的索引節點都有一個包含睡眠鎖的鎖定字段，這確保了對索引節點字段（例如檔案長度）以及索引節點檔案或目錄內容區塊的獨佔存取。如果索引節點的參考大於零，則系統會在表中維護該索引節點，並且不會將表格條目重新用於不同的索引節點。最後，每個索引節點都包含一個連結欄位（在磁碟上，如果在記憶體中則複製到記憶體中），用於計算引用檔案的目錄條目的數量；如果連結計數大於零，xv6 將不會釋放索引節點。 iget()傳回的struct inodepointer保證在對應的toiput()呼叫之前有效； inode 不會被刪除，指標所引用的記憶體也不會被重新用於不同的 inode。檔案系統程式碼的許多部分都依賴iget() 的這種行為，既可以保存對inode 的長期引用（如開啟的檔案和目前目錄），也可以防止競爭，同時避免操作多個inode 的程式碼中的死鎖（例如路徑名查找）。傳回的struct inodethatiget可能沒有任何有用的內容。為了確保它保存磁碟上 inode 的副本，程式碼必須 callilock。這將鎖定 inode（以便沒有其他進程 canilockit）並從磁碟讀取 inode（如果尚未讀取）。 將 inode 指標的取得與鎖定分開有助於避免某些情況下的死鎖，例如在目錄查找期間。多個進程可以容納一個

C 指向 iget 傳回的 inode 的指針，但一次只有一個程序可以鎖定該 inode。 inode 表僅儲存核心程式碼或資料結構保存 C 指標的 inode。它的主要工作是同步多個進程的存取。 inode表也剛好快取了常用的inode，但快取是次要的；如果頻繁使用某個索引節點，緩衝區快取可能會將其保留在記憶體中。修改記憶體中 inode 的程式碼會使用 iupdate 將其寫入磁碟。

### 8.9 Code: Inodes

要指派新的 inode（例如，建立檔案時），xv6 呼叫ialloc(kernel/fs.c:199)。 allocis 與 balloc 類似：它循環遍歷磁碟上的 inode 結構，一次一個區塊，尋找標記為空閒的一個。當它找到一個時，它會透過將新類型寫入磁碟來聲明它，然後透過尾部呼叫 toiget(kernel/fs.c:213) 從索引節點表中傳回一個條目。 ialloc 的正確操作取決於這樣一個事實：一次只有一個進程可以持有對 bp 的參考：ialloc 可以確保某些其他進程不會同時看到該 inode 可用並嘗試聲明它。 iget(kernel/fs.c:247) 在 inode 表中尋找具有所需設備和 inode 編號的活動條目 (ip->ref > 0)。如果找到，它會傳回對該 inode 的新引用 (kernel/fs.c:256-260)。 asigetscans，它記錄第一個空槽的位置（kernel/fs.c:261-262），如果需要分配表項，則使用它。在讀取或寫入其元資料或內容之前，程式碼必須使用 ilock 鎖定 inode。一旦 ilock 擁有對 inode 的獨佔存取權限，它就會根據需要從磁碟（更可能是緩衝區快取）讀取 inode。函數 iunlock (kernel/fs.c:321) 釋放睡眠鎖，這可能會導致任何睡眠的進程被喚醒。 iput(kernel/fs.c:337) 透過減少引用計數 (kernel/fs.c:360) 來釋放指向 inode 的 C 指標。如果這是最後一次引用，則 inode 表中的 inode 槽現在空閒，並且可以重新用於不同的 inode。如果iput 發現沒有對某個inode 的C 指標引用，且該inode 沒有指向它的連結（不在目錄中出現），則必須釋放該inode 及其資料區塊。iputcallsitrunc 將檔案截斷為零字節，釋放資料區塊；將 inode 類型設為 0（未分配）；並將 inode 寫入磁碟（kernel/fs.c:342）。在釋放 inode 的情況下的鎖定協議值得仔細研究。一個危險是並發線程可能正在等待 inilock 使用此 inode（例如，讀取檔案或列出目錄），並且不會準備好發現該 inode 不再指派。這種情況不會發生，因為如果沒有指向記憶體中 inode 的連結並且 ip->ref 是一個，則系統呼叫無法取得指向該 inode 的指標。該引用是呼叫 iput 的執行緒所擁有的引用。另一個主要危險是並發呼叫 alloc 可能會選擇 iputis 釋放的相同 inode。只有當 iupdate 寫入磁碟以使 inode 的類型為零之後，才會發生這種情況。這個種族是良性的；分配線程將禮貌地等待獲取 inode 的睡眠鎖，然後再讀取或寫入 inode，此時 iput 已完成。 iput()可以寫入磁碟。這意味著使用該檔案系統的任何系統呼叫都可以寫入磁碟，因為該系統呼叫可能是最後一個引用該檔案的系統呼叫。甚至

像 read() 這樣看似唯讀的呼叫最終可能會呼叫 iput()。 iput() 和 crashes 之間存在具有挑戰性的交互作用。正在讀取和寫入文件，因為它已成功打開它。但是，如果在最後一個進程關閉該檔案的檔案描述符之前發生崩潰，則該檔案將被標記為已在磁碟上分配，但沒有目錄條目指向它。檔案系統以兩種方式之一處理這種情況。簡單的解決方案是，在復原時，重新開機後，檔案系統會掃描整個檔案系統以尋找標記為已指派但沒有指向它們的目錄條目的檔案。如果存在任何此類文件，則它可以釋放這些文件。第二種解決方案不需要掃描檔案系統。在該解決方案中，檔案系統在磁碟上（例如，在超級區塊中）記錄連結計數降至零但引用計數不為零的檔案的inode編號。如果檔案系統在其引用計數達到 0 時刪除該文件，則會透過從清單中刪除該 inode 來更新磁碟清單。恢復時，檔案系統釋放清單中的任何檔案。 Xv6 沒有實作這兩種解決方案，這表示 inode 可能會被標記為已在磁碟上分配，即使它們不再使用。這意味著隨著時間的推移，xv6 會面臨磁碟空間不足的風險。

### 8.10 Code: Inode content

磁碟上的 inode 結構，struct dinode，包含一個大小和一個區塊號陣列（見圖 8.3）。 inode 資料可在 dinode'saddrs 陣列中列出的區塊中找到。第一個 NDIRECT 資料塊列在陣列的第一個 NDIRECT 條目中；這些塊稱為直接塊。接下來的 NINDIRECT 資料塊不是在索引節點中列出，而是在稱為間接區塊的資料區塊中列出。 addrs 數組中的最後一項給出了間接區塊的位址。因此，檔案的前 12 kB (NDIRECT x BSIZE) 位元組可以從 inode 中列出的區塊載入，而接下來的 256 kB (NINDIRECT x BSIZE) 位元組只能在查閱間接區塊後載入。這是一種很好的磁碟表示形式，但對於客戶端來說卻很複雜。函數 bmap 管理表示，以便更高層級的例程（例如我們稍後將看到的 readian 和 writei）不需要管理這種複雜性。如果 ip 還沒有這樣的區塊，bmap 會分配一個。函數bmap(kernel/fs.c:383)先選擇簡單的情況：第一個NDIRECT區塊在inode本身列出(kernel/fs.c:388-396)。接下來的NINDIRECT 區塊列在間接區塊atip->addrs\[NDIRECT\] 中。 :408) ）。如果區塊號超過NDIRECT+NINDIRECT，bmappanics;writeicon包含防止這種情況發生的檢查(kernel/fs.c:513)。 bmap 根據需要分配塊。 Anip->addrs\[\] 或間接輸入零表示沒有分配區塊。 Asbmap遇到零，它用按需分配的新區塊數取代它們（kernel/fs.c:389-390）（kernel/fs.c:401-402）。 itrunc 釋放檔案的區塊，將 inode 的大小重設為零。c:426) 開始於

type
major
minor
nlink
size
address 1


address 12
indirect


dinode


address 1


address 256


indirect block


data


data


data


data


Figure 8.3: The representation of a file on disk.


釋放直接區塊（kernel/fs.c:432-437），然後釋放間接區塊中列出的區塊（kernel/fs.c:442-445），最後釋放間接區塊本身（kernel/fs.c:447） -448）。 bmap 讓 readi 和 write 更容易取得 inode 的 data.readi(kernel/fs.c:472) 首先確保偏移量和計數不會超出檔案結尾。從檔案結尾開始的讀取會回傳錯誤(kernel/fs.c:477-478)，而從檔案結尾開始或越過檔案結尾的讀取所傳回的位元組數少於請求的位元組數(kernel/fs .c:479-480) ）。主循環處理檔案的每個區塊，將資料從緩衝區複製到dst(kernel/fs.c:482-494)。位置開始的寫入或跨文件末尾增長文件，直到最大文件大小（kernel/fs.c:513-514）；循環將資料複製到緩衝區而不是輸出（kernel/fs.c:522）；如果寫入擴展了文件，則寫入必須更新其大小（kernel/fs.c:530-531）。函數stati(kernel/fs.c:458)將inode元資料複製到stat結構中，該結構透過stat系統呼叫暴露給使用者程式。

### 8.11 代碼：目錄層

目錄的內部實作與文件非常相似。它的 inode 類型為 T\_DIR，它的資料是目錄條目的序列。每個條目都是一個struct dirent(kernel/fs.h:56)，其中包含一個

名稱和索引節點號。名稱最多為 DIRSIZ(14) 個字元；如果較短，則以 NULL (0) 位元組結束。 inode 號為零的目錄條目是免費的。函數 dirlookup(kernel/fs.c:552) 在目錄中搜尋具有給定名稱的條目。如果找到，則傳回指向對應 inode 的指標（未鎖定），並將_poff 設為該位元組_ 目錄中條目的偏移量，以防呼叫者希望編輯它。如果目錄查找找到 一個具有正確名稱的條目，它會更新 poff 並傳回透過 iget 獲得的解鎖 inode。 dirlookup 是 iget 傳回未鎖定 inode 的原因。呼叫者已鎖定 dp，因此如果您尋找的是目前目錄的別名，則在返回之前嘗試鎖定 inode 將嘗試重新鎖定 dp 並導致死鎖。 （還有更複雜的死鎖場景涉及多個進程，並且..，父目錄的別名；.不是唯一的問題。）呼叫者可以unlockdp然後lockip，確保它一次只持有一個鎖。函數dirlink(kernel/fs.c:580)將具有給定名稱和inode編號的新目錄條目寫入directorydp。如果該名稱已存在，dirlink 將傳回錯誤（kernel/fs.c:586-590）。主循環讀取目錄條目以尋找未指派的條目。當它找到一個時，它會提前停止循環（kernel/fs.c:592-597），並偏移到可用條目的偏移量。否則，迴圈以偏移量 todp->size 結束。不管怎樣，dirlink 然後透過在 offsetoff(kernel/fs.c:602-603) 處寫入來為目錄新增一個條目。

### 8.12 Code: Path names

路徑名查找涉及一系列對 dirlookup 的調用，每個路徑元件調用一次。 namei(kernel/fs.c:687) 評估路徑並傳回對應的索引節點。函數nameiparent 是一個變體：它在最後一個元素之前停止，傳回父目錄的inode 並將最後一個元素複製到name 中。兩者都呼叫通用函數 namex 來完成實際工作。 namex(kernel/fs.c:652) 首先決定路徑評估從哪裡開始。如果路徑以斜線開頭，則從根開始求值；否則，目前目錄（kernel/fs.c:656-659）。然後它使用skipelem依序考慮路徑的每個元素（kernel/fs.c:661）。循環的每次迭代都必須在目前 inodeip 中尋找 name。迭代從鎖定並檢查它是否為目錄開始。如果不是，則查找失敗（kernel/fs.c:662-666）。 （鎖定ip 是必要的，不是因為ip->type 可以在腳下更改（它不能），而是因為在鎖定運行之前，不能保證ip->type 已從磁碟加載。）如果調用是nameiparent 並且這是最後一個路徑元素，則循環會提前停止，根據 nameiparent 的定義；最終的路徑元素已經複製到name中，sonamex只需要回傳unlockedip(kernel/fs.c:667-671)。最後，循環使用 dirlookup 來尋找路徑元素，並透過設定 ip = next(kernel/fs.c:672-677) 為下一次迭代做好準備。當循環用完路徑元素時，它會傳回 ip。 procedurenamex可能需要很長時間才能完成：它可能涉及多個磁碟操作來讀取路徑名中遍歷的目錄的索引節點和目錄區塊（如果它們不在緩衝區快取中）。 Xv6 經過精心設計，因此，如果一個核心執行緒對namex 的呼叫在磁碟I/O 上被阻塞，則查找不同路徑名的另一個核心執行緒可以同時進行。在不同目錄中進行尋找。這種並發帶來了一些挑戰。例如，當一個內核線程正在查找

另一個內核線程可能正在透過取消目錄連結來更改目錄樹。潛在的風險是尋找可能正在搜尋已被另一個核心執行緒刪除的目錄，並且其區塊已重新用於另一個目錄或檔案。 Xv6 避免了這樣的競爭。例如，當執行 dirlookupinnamex 時，尋找執行緒持有目錄上的鎖，並且 dirlookup 傳回使用 iget 取得的 inode。 iget 增加 inode 的參考計數。只有在從 dirlookup 接收到 inode 後，namex 才會釋放目錄上的鎖定。現在另一個執行緒可能會取消該 inode 與目錄的鏈接，但 xv6 還不會刪除該 inode，因為該 inode 的引用計數仍然大於零。另一個風險是僵局。例如，查找“.”時next指向與ip相同的inode。在釋放 IP 上的鎖之前鎖定下一個會導致死鎖。為了避免這種死鎖，namex 在取得鎖定之前先解鎖該目錄。在這裡，我們再次看到為什麼分離和雙鎖很重要。

### 8.13 File descriptor layer

Unix 介面的一個很酷的方面是，Unix 中的大多數資源都以檔案的形式表示，包括控制台、管道等設備，當然還有真實的檔案。文件描述符層是實現這種一致性的層。 Xv6 為每個進程提供了自己的開啟檔案表或檔案描述符，正如我們在第1 章中看到的那樣。它是一個inode 或a 的包裝器。每次呼叫 open 都會建立一個新的開啟文件（一個 newstruct 文件）：如果多個行程獨立開啟同一個文件，則不同的實例將具有不同的 I/O 偏移量。另一方面，單一開啟的檔案（相同的結構檔案）可以在一個進程的檔案表中多次出現，也可以在多個進程的檔案表中出現多次。如果一個行程使用 open 開啟文件，然後使用 du 建立別名或使用 fork 與子程序共用該文件，就會發生這種情況。引用計數追蹤對特定開啟檔案的引用數量。文件可以打開以進行讀取或寫入或兩者兼而有之。可讀和可寫欄位對此進行追蹤。系統中所有開啟的檔案都保存在一個全域檔案表中，可竊取。文件表具有分配文件（filealloc）、建立重複引用（filedup）、釋放引用（fileclose）以及讀取和寫入資料（filereadandfilewrite）的函數。前三個遵循現在熟悉的形式。 c :48) 增加引用計數； andfileclose(kernel/file.c:60) 減少它。當檔案的參考計數達到零時，fileclose 會根據類型釋放底層管道或索引節點。 函數filestat、fileread 和filewrite 實作檔案的統計、讀取和寫入操作。 ，然後透過呼叫到管道或索引節點來實現。如果檔案代表一個inode，則fileread和filewrite使用I/O偏移量作為操作的偏移量，然後將其前進(kernel/file.c:122-123)(kernel/file.c:153-154) 。管道沒有偏移的概念。回想一下，inode 函數需要

呼叫者處理鎖定（kernel/file.c:94-96）（kernel/file.c:121-124）（kernel/file.c:163-166）。 inode 鎖定有一個方便的副作用，即讀取和寫入偏移量會自動更新，因此同時對同一文件進行多次寫入不能覆蓋彼此的數據，儘管它們的寫入可能最終會交錯。

### 8.14 Code: System calls

使用較低層提供的功能，大多數系統呼叫的實作都是微不足道的（請參閱（kernel/sysfile.c））。有一些電話值得仔細研究。函數 sys\_link 和 sys\_unlinkedit 目錄，建立或刪除對 inode 的參考。它們是使用transactions.sys\_link(kernel/sysfile.c:124) 功能的另一個很好的例子。 :129)。假設 old 存在且不是目錄(kernel/sysfile.c:133-136)，sys\_link 增加其ip->nlink 計數。然後sys\_link呼叫nameiparent來尋找new(kernel/sysfile.c:149)的父目錄和最終路徑元素，並建立一個指向old的inode(kernel/sysfile.c:152)的新目錄條目。新的父目錄必須存在並且與現有 inode 位於相同裝置上：inode 編號僅在單一磁碟上具有唯一意義。如果發生這樣的錯誤，sys\_link 必須回傳並遞減ip->nlink。事務簡化了實現，因為它需要更新多個磁碟區塊，但我們不必擔心執行它們的順序。他們要么全部成功，要么一無所獲。例如，如果沒有事務，在建立連結之前更新 ip->nlink 會使檔案系統暫時處於不安全狀態，而其間的崩潰可能會導致嚴重破壞。有了交易，我們就不必擔心這個問題。 sys\_link 為現有 inode 建立新名稱。函數create(kernel/sysfile.c:246) 為新的inode 建立一個新名稱。它是三個文件創建系統調用的概括：帶有 O\_CREATE 標誌的 open 創建一個新的普通文件，mkdir 創建一個新目錄，mkdev 創建一個新設備文件。與sys\_link一樣，create首先透過呼叫nameiparent來取得父目錄的inode。 然後它會呼叫 dirlookup 來檢查該名稱是否已存在 (kernel/sysfile.c:256)。如果名稱確實存在，create 的行為取決於它所用於的系統呼叫：open 與 mkdir 和 mkdev 具有不同的語意。如果 create 代表 open(type == T\_FILE) 使用，而存在的名稱本身就是一個常規文件，那麼 open 會將其視為成功，因此 create 也會成功 (kernel/sysfile.c:260)。否則，這是一個錯誤（kernel/sysfile.c:261-262）。如果名稱尚不存在，createnow 將使用ialloc(kernel/sysfile.c:265) 指派一個新的inode。如果新的 inode 是目錄，則 create 使用 .and ..entries 對其進行初始化。最後，現在資料已經正確初始化，create可以將其連結到父目錄（kernel/sysfile.c:278）。不存在死鎖的可能性，因為inodeip是新分配的：系統中沒有其他程序會持有ip的鎖然後嘗試lockdp。使用create，很容易實作sys\_open、sys\_mkdir，而sys\_mknod.sys\_open (kernel/sysfile.c:305)是最複雜的，因為建立新檔案只是它能做的一小部分。如果open傳遞了O\_CREATE標誌，它會呼叫create(kernel/sysfile.c:320)。否則，它會呼叫namei(kernel/sysfile.c:326)。create回傳一個鎖定的inode，但nameidoes不是，sosys\_open

必須鎖定 inode 本身。這提供了一個方便的地方來檢查目錄是否僅打開用於讀取，而不是寫入。假設 inode 是透過一種或另一種方式取得的，sys\_open 指派一個檔案和一個檔案描述子（kernel/sysfile.c:344），然後填入該檔案（kernel/sysfile.c:356-361）。請注意，其他進程無法存取部分初始化的文件，因為它僅位於當前進程的表中。第 7 章在我們擁有文件系統之前研究了管道的實現。函數 sys\_pipe 透過提供建立管道對的方法將實作連接到檔案系統。它的參數是一個指向兩個整數空間的指針，它將在其中記錄兩個新的檔案描述符。然後它分配管道並安裝文件描述符。

### 8.15 Real world

實際作業系統中的緩衝區快取比 xv6 的緩衝區快取複雜得多，但它具有相同的兩個目的：高速緩存和同步對磁碟的存取。 Xv6 的緩衝區快取與 V6 一樣，使用簡單的最近最少使用 (LRU) 逐出策略；有許多更複雜的政策可以實施，每種政策都適合某些工作負載，但不適合其他工作負載。更有效率的 LRU 快取將消除鍊錶，而是使用雜湊表進行查找並使用堆疊進行 LRU 逐出。現代緩衝區高速緩存通常與虛擬記憶體系統整合以支援記憶體映射檔案。 Xv6 的日誌系統效率低。提交不能與檔案系統系統呼叫同時發生。系統會記錄整個區塊，即使區塊中僅更改了幾個位元組。它執行同步日誌寫入，一次一個區塊，每個寫入可能需要整個磁碟旋轉時間。真正的日誌系統可以解決所有這些問題。日誌記錄並不是提供崩潰復原的唯一方法。早期的檔案系統在重新引導期間使用清除程序（例如 UNIXfsck 程式）來檢查每個檔案和目錄以及區塊和 inode 空閒列表，尋找並解決不一致的問題。對於大型檔案系統，清理可能需要數小時，並且在某些情況下無法以導致原始系統呼叫成為原子的方式解決不一致問題。從日誌中恢復的速度要快得多，並且在崩潰時系統呼叫是原子的。 Xv6 使用與早期 UNIX 相同的基本磁碟索引節點和目錄佈局；多年來，這項計劃一直非常持久。 BSD 的 UFS/FFS 和 Linux 的 ext2/ext3 使用本質上相同的資料結構。 檔案系統佈局中效率最低的部分是目錄，它需要在每次查找期間對所有磁碟區塊進行線性掃描。當目錄只有幾個磁碟區塊時，這是合理的，但對於保存許多檔案的目錄來說，這是昂貴的。 Microsoft Windows 的 NTFS、macOS 的 HFS 和 Solaris 的 ZFS（僅舉幾例）將目錄實作為磁碟上平衡的區塊樹。這很複雜，但保證了對數時間的目錄查找。 Xv6 對於磁碟故障很天真：如果磁碟操作失敗，xv6 就會出現恐慌。這是否合理取決於硬體：如果作業系統位於使用冗餘來掩蓋磁碟故障的特殊硬體之上，那麼作業系統可能很少會看到故障，因此出現恐慌是可以接受的。另一方面，使用普通磁碟的作業系統應該預料到故障並更妥善地處理它們，以便一個檔案中的區塊遺失不會影響其餘檔案的使用。

文件系統。 Xv6 要求檔案系統適合一個磁碟設備且大小不變。隨著大型資料庫和多媒體檔案對儲存的要求越來越高，作業系統正在開發各種方法來消除「每個檔案系統一個磁碟」的瓶頸。基本方法是將許多磁碟組合成單一邏輯磁碟。 RAID 等硬體解決方案仍然是最受歡迎的，但目前的趨勢是盡可能在軟體中實現這種邏輯。這些軟體實作通常允許豐富的功能，例如透過動態新增或刪除磁碟來增大或縮小邏輯裝置。當然，可以動態成長或收縮的儲存層需要一個可以執行相同操作的檔案系統：xv6 使用的固定大小的 inode 區塊陣列在這種環境中無法正常運作。將磁碟管理與檔案系統分開可能是最簡潔的設計，但是兩者之間的複雜介面導致一些系統（例如 Sun 的 ZFS）將它們結合起來。 Xv6的檔案系統缺乏許多其他現代檔案系統的功能；例如，它缺乏對快照和增量備份的支援。現代Unix系統允許使用與磁碟儲存相同的系統呼叫來存取多種資源：命名管道、網路連接、遠端存取的網路檔案系統以及/proc等監視和控制介面。這些系統通常為每個開啟的檔案提供一個函數指標表（每個操作一個），而不是 xv6 的 fileread 和 filewrite 中的 if 語句，並呼叫該函數指標來呼叫該 inode 的呼叫實作。網路檔案系統和使用者級檔案系統提供將這些呼叫轉換為網路 RPC 並在返回之前等待回應的功能。

### 8.16 Exercises

1. 為什麼會恐慌 inballoc？ xv6還能恢復嗎？
2. 為什麼會恐慌 inialloc？ xv6還能恢復嗎？
3. 為什麼 fileallocanic 當檔案用完時不發生？為什麼這種情況更常見且值得處理？
4. 假設與 ip 對應的檔案在 sys\_link 呼叫 toiunlock(ip) 和 dirlink 之間被另一個程序取消連結。連結會正確建立嗎？為什麼或為什麼不呢？
5. create 會進行四次函數呼叫（一次呼叫 allococ，三次呼叫 dirlink）才能成功。如果沒有，則建立呼叫恐慌。為什麼這是可以接受的？為什麼這四個呼叫都不會失敗？
6. sys\_chdircallsiunlock(ip)beforeiput(cp->cwd)，可能會嘗試鎖定 cp->cwd，但將 iunlock(ip) 推遲到 iput 之後不會導致死鎖。為什麼不呢？
7. 實作lseek系統呼叫。支援 lseek 還要求您修改 filewrite 以使用零 iflseeksetsoff超出 f->ip->size 來填充檔案中的漏洞。
8. 新增O\_TRUNC和O\_APPEND打開，以便>和>>操作符在shell中工作。
9. 修改檔案系統以支援符號連結。
10. 修改檔案系統以支援命名管道。
11. 修改檔案和VM系統以支援記憶體映射檔案。

第9章
===

重溫並發
====

同時獲得良好的並行性能、並發時的正確性以及可理解的程式碼是核心設計的一大挑戰。直接使用鎖是實現正確性的最佳途徑，但並非總是可行。本章重點介紹 xv6 被迫以複雜方式使用鎖的範例，以及 xv6 使用類鎖技術但不使用鎖的範例。

### 9.1 Locking patterns

快取的項目通常很難鎖定。例如，檔案系統的區塊快取 (kernel/bio.c:26) 儲存最多 NBUF 磁碟區塊的副本。給定的磁碟區塊在快取中最多有一個副本至關重要；否則，不同的進程可能會對本應是同一塊的不同副本進行衝突的變更。每個快取區塊都儲存在struct buf (kernel/buf.h:1) 中。 Astruct buf 有一個鎖定字段，有助於確保一次只有一個程序使用給定的磁碟塊。但是，該鎖還不夠：如果快取中根本不存在某個區塊，並且兩個進程想要同時使用它怎麼辦？沒有struct buf（因為該區塊尚未快取），因此沒有什麼可以鎖定。 Xv6 透過將附加鎖定 (bcache.lock) 與快取區塊的識別集相關聯來處理這種情況。需要檢查區塊是否已快取的程式碼（例如，bget(kernel/bio.c:59)），或更改快取區塊集的程式碼，必須holdbcache.lock；在該程式碼找到所需的區塊和結構 buf 後，它可以釋放 bcache.lock 並僅鎖定特定區塊。這是常見模式：一組項目一把鎖，每個項目一把鎖。

通常，取得鎖的相同函數也會釋放它。但更精確的看待事物的方法是，在必須呈現原子性的序列開始時取得鎖，並在該序列結束時釋放鎖。如果序列在不同的函數、不同的執行緒或不同的 CPU 上開始和結束，則鎖定獲取和釋放必須執行相同的操作。鎖的作用是強制其他用途等待，而不是將一條資料固定到特定的代理。一個例子是 acquireinyield(kernel/proc.c:512)，它是在調度程序線程中而不是在獲取過程中釋放的。另一個例子是acquiresleepinilock(kernel/fs.c:293);這段程式碼經常在讀磁碟時休眠；它可能在不同的CPU上喚醒，這意味著鎖定可能在不同的CPU上取得和釋放。

釋放受嵌入在物件中的鎖保護的物件是一件微妙的事情，因為擁有鎖並不足以保證釋放是正確的。當其他執行緒正在等待獲取使用該物件時，就會出現問題；釋放物件會隱式釋放嵌入的鎖，這將導致等待執行緒發生故障。一種解決方案是追蹤存在多少個對該物件的引用，以便僅在最後一個引用消失時才釋放該物件。請參閱pipeclose(kernel/pipe.c:59) 作為範例；pi->readopen 和 pi->writeopen 追蹤管道是否有檔案描述符引用它。通常人們會看到一組相關項的讀寫序列周圍的鎖；這些鎖確保其他執行緒只能看到已完成的更新序列（只要它們也鎖定）。如果更新是對單一共享變數的簡單寫入，那麼情況又如何呢？例如，setkilledandkilled(kernel/proc.c:619) 圍繞 p->killed 的簡單用法進行鎖定。如果沒有鎖，一個執行緒可能會在另一個執行緒讀取 p->killed 的同時寫入它。這是一場競賽，C 語言規範規定競賽會產生未定義的行為，這意味著程式可能會崩潰或產生不正確的結果^1。鎖可以防止競爭並避免未定義的行為。競爭可能破壞程式的原因之一是，如果沒有鎖或等效結構，編譯器可能會產生以與原始 C 程式碼完全不同的方式讀寫記憶體的機器碼。例如，呼叫killed的執行緒的機器碼可以將p->killed複製到暫存器並僅讀取該快取值；這意味著該線程可能永遠不會看到任何寫入 top->killed。鎖可以防止此類快取。

### 9.2 Lock-like patterns

在許多地方，xv6 以類似鎖的方式使用引用計數或標誌來指示物件已分配且不應釋放或重新使用。進程的 sp->state 以這種方式起作用，檔案、inode 和 buf 結構中的參考計數也是如此。雖然在每種情況下鎖都會保護標誌或引用計數，但後者可以防止物件過早釋放。

檔案系統使用struct inodereference counts作為一種可以被多個程序持有的共享鎖，以避免程式碼使用普通鎖定時出現的死鎖。例如，循環 innamex(kernel/fs.c:652) 依序鎖定每個路徑名稱元件指定的目錄。然而，namex 必須在循環結束時釋放每個鎖，因為如果它持有多個鎖，如果路徑名包含點（例如，a/./b），它可能會與自身發生死鎖。它也可能因涉及目錄的並發查找而死鎖…正如第 8 章所解釋的，解決方案是循環將目錄 inode 傳遞到下一次迭代，其引用計數遞增，但不鎖定。某些資料項在不同時間由不同機制保護，有時可能透過 xv6 程式碼的結構而不是透過明確鎖定來隱式地防止並發存取。例如，當實體頁空閒時，它受到kmem.lock(kernel/kalloc.c:24)的保護。如果該頁隨後被分配為管道 (kernel/pipe.c:23)，則它會受到不同鎖（embeddedpi->lock）的保護。如果該頁面被重新指派給新進程的使用者內存，則該頁面不受保護

(^1) [https://en.cppreference.com/w/c/language/memory\_model](https://en.cppreference.com/w/c/language/memory_model)中的“線程和資料競爭”

根本就沒有鎖。相反，分配器不會將該頁面提供給任何其他進程（直到它被釋放），這一事實可以保護它免受並發存取。新進程記憶體的所有權很複雜：首先父進程分配並操作它，然後子進程使用它，並且（子進程退出後）父進程再次擁有內存並將其傳遞給tokfree。這裡有兩個教訓：資料物件可以在其生命週期的不同點以不同的方式防止並發，並且保護可以採取隱式結構的形式而不是顯式鎖的形式。最後一個類似鎖的範例是需要停用呼叫 tomycpu()(kernel/proc.c:83) 周圍的中斷。停用中斷會導致呼叫程式碼相對於計時器中斷而言是原子的，這可能會強制進行上下文切換，從而將進程移至不同的 CPU。

### 9.3 No locks at all

有一些地方 xv6 完全不加鎖地共享可變資料。其中之一是自旋鎖的實現，儘管人們可以將 RISC-V 原子指令視為依賴硬體中實現的鎖。另一個是main.c(kernel/main.c:7)中的started變量，用於阻止其他CPU運行，直到CPU 0完成初始化xv6； thevolatile 確保編譯器實際產生載入和儲存指令。 Xv6 包含一個 CPU 或執行緒寫入一些數據，而另一個 CPU 或執行緒讀取資料的情況，但沒有專門用於保護該資料的特定鎖。例如，在 fork 中，父行程寫入子程序的使用者記憶體頁面，而子程序（不同的線程，可能位於不同的 CPU 上）讀取這些頁面；沒有鎖明確保護這些頁面。嚴格來說，這不是一個鎖定問題，因為子進程直到父進程完成寫入後才開始執行。這是一個潛在的記憶體排序問題（請參閱第 6 章），因為如果沒有記憶體屏障，就沒有理由期望一個 CPU 看到另一個 CPU 的寫入。但是，由於父進程釋放鎖，而子進程在啟動時會取得鎖，因此取得和釋放中的記憶體屏障可確保子進程的 CPU 看到父進程的寫入。

### 9.4 並行性

鎖定主要是為了正確性而抑制並行性。因為效能也很重要，所以核心設計者經常必須考慮如何以既實現正確性又允許並行性的方式使用鎖。雖然 xv6 不是為高效能而係統設計的，但仍值得考慮哪些 xv6 操作可以並行執行，以及哪些操作可能會發生鎖定衝突。 xv6 中的管道是相當好的並行性的一個例子。每個管道都有自己的鎖，因此不同的進程可以在不同的CPU上並行讀取和寫入不同的管道。然而，對於給定的管道，寫入者和讀取者必須等待對方釋放鎖；他們不能同時讀/寫同一個管道。還有一種情況是，從空管道讀取（或向滿管道寫入）必須阻塞，但這不是由於鎖定方案造成的。上下文切換是一個更複雜的例子。兩個核心執行緒各自在自己的 CPU 上執行，可以同時呼叫 Yield、sched 和 swtchat，並且這些呼叫將會並行執行。

線程各自持有一個鎖，但它們是不同的鎖，因此它們不必互相等待。然而，一旦進入調度程序，在進程表中搜尋可運行的進程時，兩個 CPU 可能會發生鎖定衝突。也就是說，xv6 可能會在上下文切換期間從多個 CPU 中獲得效能優勢，但可能不會那麼多。另一個例子是不同 CPU 上的不同程序並發呼叫 fork。這些呼叫可能必須等待彼此的 pid\_lock 和 kmem.lock，以及在進程表中搜尋 UNUSED 進程所需的每個進程鎖定。另一方面，兩個分叉進程可以完全並行地複製使用者記憶體頁面和格式化頁表頁面。上述每個範例中的鎖定方案在某些情況下都會犧牲並行效能。在每種情況下，都可以使用更精細的設計來獲得更多的並行性。是否值得取決於細節：相關操作被呼叫的頻率、程式碼在持有競爭鎖的情況下花費了多長時間、有多少個CPU 可能同時運行衝突的操作、程式碼的其他部分是否是更具限制性的瓶頸。很難猜測給定的鎖定方案是否會導致效能問題，或者新的設計是否明顯更好，因此通常需要對實際工作負載進行測量。

### 9.5 Exercises

1. 修改 xv6 的管道實現，以允許對相同管道的讀取和寫入在不同的 CPU 上並行進行。
2. 修改xv6的scheduler()以減少不同CPU同時尋找可運行進程時的鎖爭用。
3. 消除xv6的fork()中的一些序列化。

第10章
====

Summary
=======

本文透過對作業系統xv6的逐行研究，介紹了作業系統的主要思想。有些程式碼行體現了主要想法的精髓（例如，上下文切換、使用者/核心邊界、鎖等），並且每一行都很重要；其他程式碼行提供瞭如何實現特定作業系統想法的說明，並且可以輕鬆地以不同的方式完成（例如，更好的調度演算法、更好的磁碟資料結構來表示檔案、更好的日誌記錄以允許並發）交易等）。所有的想法都是在一個特定的、非常成功的系統呼叫介面（Unix 介面）的背景下闡述的，但這些想法也延續到了其他作業系統的設計。

Bibliography
============

[1] Linux common vulnerabilities and exposures (CVEs). https://cve.mitre.org/
cgi-bin/cvekey.cgi?keyword=linux.


[2] The RISC-V instruction set manual Volume I: unprivileged specification ISA. https:
//drive.google.com/file/d/17GeetSnT5wW3xNuAHI95-SI1gPGd5sJ_
/view?usp=drive_link, 2024.


[3] The RISC-V instruction set manual Volume II: privileged specification. https:
//drive.google.com/file/d/1uviu1nH-tScFfgrovvFCrj7Omv8tFtkp/
view?usp=drive_link, 2024.


[4] Hans-J Boehm. Threads cannot be implemented as a library.ACM PLDI Conference, 2005.


[5] Edsger Dijkstra. Cooperating sequential processes. https://www.cs.utexas.edu/
users/EWD/transcriptions/EWD01xx/EWD123.html, 1965.


[6] Maurice Herlihy and Nir Shavit. The Art of Multiprocessor Programming, Revised Reprint.
2012.


[7] Brian W. Kernighan. The C Programming Language. Prentice Hall Professional Technical
Reference, 2nd edition, 1988.


[8] Gerwin Klein, Kevin Elphinstone, Gernot Heiser, June Andronick, David Cock, Philip Derrin,
Dhammika Elkaduwe, Kai Engelhardt, Rafal Kolanski, Michael Norrish, Thomas Sewell,
Harvey Tuch, and Simon Winwood. Sel4: Formal verification of an OS kernel. InProceedings
of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, page 207–220, 2009.


[9] Donald Knuth.Fundamental Algorithms. The Art of Computer Programming. (Second ed.),
volume 1. 1997.


\[10\] L蘭波特。 dijkstra 並發程式設計問題的新解決方案。

\[11\] John Lions.UNIX 第六版評論。點對點通信，2000。

\[12\] 保羅·E·麥肯尼、塞拉斯·博伊德-維克澤和喬納森·沃波爾。 RCU 在 Linux 核心中的使用：十年後，2013 年。

\[13\] 馬丁·麥可和丹尼爾·杜里奇。 NS16550A：UART 設計與應用注意事項。 [http://bitsavers.trailing-edge.com/components/national/](http://bitsavers.trailing-edge.com/components/national/) \_appNotes/AN-0491.pdf，1987 年。

\[14\]阿萊夫一號。為了樂趣和利潤而粉碎堆疊。 [http://phrack.org/issues/49/](http://phrack.org/issues/49/) 14.html#文章。

\[15\] 大衛·帕特森和安德魯·沃特曼。 RISC-V 閱讀器：開放式架構圖集。草莓峽谷，2017。

\[16\] 戴夫·普雷索托、羅伯·派克、肯·湯普森和霍華德·特里基。方案9，分散式系統。 1991 年春季歐洲公開會議紀錄，第 43-50 頁，1991 年。

\[17\] 丹尼斯·M·里奇和肯·湯普森。 UNIX 分時系統。交流。 ACM，17(7)：365–375，1974 年 7 月。

Index
=====

#### ., 96, 98

#### .., 96, 98

/init, 28, 40 \_entry, 28

absorption, 90 acquire, 63, 67 address space, 26 argc, 41 argv, 41 atomic, 63

balloc, 91, 93 batching, 89 bcache.head, 87 begin\_op, 90 bfree, 91 bget, 87 binit, 87 block, 86 bmap, 94 bottom half, 53 bread, 87, 88 brelse, 87, 88 BSIZE, 94 buf, 87 busy waiting, 75 bwrite, 87, 88, 90

chan、76、78 子級、10 提交、89 並發、59 並發控制、59

condition lock, 77
conditional synchronization, 75
conflict, 62
contention, 62
contexts, 72
convoys, 82
copy-on-write (COW) fork, 49
copyinstr, 47
copyout, 41
coroutines, 74
CPU, 9
cpu->context, 72, 73
crash recovery, 85
create, 98
critical section, 62
current directory, 17


deadlock, 64
demand paging, 50
direct blocks, 94
direct memory access (DMA), 56
dirlink, 96
dirlookup, 96, 98
DIRSIZ, 96
disk, 87
driver, 53
dup, 97


ecall, 23, 27
ELF format, 40
ELF_MAGIC, 40
end_op, 90
exception, 43
exec, 12–14, 28, 41, 47


exit, 11, 79

file descriptor, 13 filealloc, 97 fileclose, 97 filedup, 97 fileread, 97, 100 filestat, 97 filewrite, 91, 97, 100 fork, 10, 12–14, 97 forkret, 74 freerange, 37 fsck, 99 fsinit, 91 ftable, 97

getcmd，12 組提交，89 保護頁，35

handler, 43 hartid, 74

I/O、13 I/O 並發、55 I/O 重定向、14 ialloc、93、98 iget、92、93、96 ilock、92、93、96 間接區塊、94 initcode.S、28、47 initlog、 91 inode, 18, 86, 92 install\_trans, 91 介面設計, 9 中斷, 43 iput, 92, 93 隔離, 21 itable, 92 itrunc, 93, 94 iunlock, 93

kalloc, 38 kernel, 9, 23

kernel space, 9, 23
kfree, 37
kinit, 37
kvminit, 36
kvminithart, 36
kvmmake, 36
kvmmap, 36


lazy allocation, 49
links, 18
loadseg, 40
lock, 59
log, 89
log_write, 90
lost wake-up, 76


machine mode, 23
main, 36, 37, 87
malloc, 13
mappages, 36
memory barrier, 68
memory model, 68
memory-mapped, 35, 53
memory-mapped files, 50
metadata, 18
microkernel, 24
mkdev, 98
mkdir, 98
mkfs, 86
monolithic kernel, 21, 23
multi-core, 21
multiplexing, 71
multiprocessor, 21
mutual exclusion, 61
mycpu, 74
myproc, 74


namei, 40, 98
nameiparent, 96, 98
namex, 96
NBUF, 87
NDIRECT, 94
NINDIRECT, 94


#### O\_CREATE, 98

open, 97, 98

p->killed、80 p->kstack、27 p->lock、73、74、78 p->pagetable、27 p->state、27 p->xxx、27 頁、31 個頁表條目(PTE) 、 31 頁錯誤異常、32、49 分頁區域、50 分頁到磁碟、50 父級、10 路徑、17 持久性、85 PGROUNDUP、37 實體位址、26 PHYSTOP、36、37 PID、10 管道、16 管道讀取、79 管道寫入、 79 輪詢、56、75 pop\_off、67 printf、12 優先權反轉、82 特權指令、23 proc\_mapstacks、36 proc\_pagetable、40 程序、9、26 程式設計I/O、56 PTE\_R、33 PTE\_U 、33 PTE\_V、33 PTE\_W、33 PTE\_X , 33 推出, 67

race, 61, 104 re-entrant locks, 66 read, 97

readi, 40, 94, 95
recover_from_log, 91
recursive locks, 66
release, 63, 67
root, 17
round robin, 82
RUNNABLE, 78, 79


satp, 33
sbrk, 13
scause, 44
sched, 72–74, 78
scheduler, 73, 74
sector, 86
semaphore, 75
sepc, 44
sequence coordination, 75
serializing, 62
sfence.vma, 37
shell, 10
signal, 83
skipelem, 96
sleep, 76–78
sleep-locks, 68
SLEEPING, 78
sret, 27
sscratch, 44
sstatus, 44
stat, 95, 97
stati, 95, 97
struct context, 72
struct cpu, 74
struct dinode, 92, 94
struct dirent, 95
struct elfhdr, 40
struct file, 97
struct inode, 92
struct pipe, 79
struct proc, 27
struct run, 37
struct spinlock, 63
stval, 49
stvec, 44


超級區塊、86 管理程式模式、23 swtch、72–74 SYS\_exec、47 sys\_link、98 sys\_mkdir、98 sys\_mknod、98 sys\_open、98 sys\_pipe、99 sys\_sleep、67 sys\_unlink、98 sys\_unall、9

T\_DIR, 95 T\_FILE, 98 執行緒, 27 雷群, 82 滴答, 67 滴答鎖定, 67 分時, 10, 21 上半部, 53 TRAMPOLINE, 45 彈翻床, 27, 45 上半部, 85 轉換事務後備緩衝區 (TLB) 32、36 傳輸完成、54 陷阱、43

trapframe, 27
type cast, 37


UART, 53
undefined behavior, 104
unlink, 90
user memory, 26
user mode, 23
user space, 9, 23
usertrap, 72
ustack, 41
uvmalloc, 40, 41


valid, 87
vector, 43
virtio_disk_rw, 87, 88
virtual address, 26


wait, 11, 12, 79
wait channel, 76
wakeup, 65, 76, 78
walk, 36
walkaddr, 40
write, 90, 97
writei, 91, 94, 95


yield, 72, 73


ZOMBIE, 80


