### CUDA 的基本程式結構  

CUDA 程式設計的核心是透過將計算任務劃分為主機（Host，CPU）和裝置（Device，GPU）兩部分來實現異構運算。主機負責邏輯控制，裝置負責並行計算。在 CUDA 程式中，以下是基本結構與組成部分。

---

#### **1. CUDA 程式的基本組成**
1. **主機代碼（Host Code）**：  
   - 在 CPU 上執行。
   - 負責初始化、分配記憶體、將資料傳輸到 GPU，以及啟動 GPU 核心函數（Kernel）。  

2. **裝置代碼（Device Code）**：  
   - 在 GPU 上執行。  
   - 通常以 Kernel 函數的形式撰寫，用來執行並行計算。  

---

#### **2. 基本程式結構**
以下是一個基本的 CUDA 程式範例，包括常見的組成部分。

```cpp
#include <cuda_runtime.h>
#include <iostream>

// 核心函數（Kernel Function）：在 GPU 上執行
__global__ void add(int* a, int* b, int* c, int n) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x; // 計算全域線程索引
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

int main() {
    int n = 1024; // 資料大小
    size_t size = n * sizeof(int);

    // 主機記憶體分配
    int *h_a = (int*)malloc(size);
    int *h_b = (int*)malloc(size);
    int *h_c = (int*)malloc(size);

    // 初始化資料
    for (int i = 0; i < n; i++) {
        h_a[i] = i;
        h_b[i] = 2 * i;
    }

    // 裝置記憶體分配
    int *d_a, *d_b, *d_c;
    cudaMalloc((void**)&d_a, size);
    cudaMalloc((void**)&d_b, size);
    cudaMalloc((void**)&d_c, size);

    // 資料從主機拷貝到裝置
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    // 啟動 Kernel 函數
    int threadsPerBlock = 256; // 每個 Block 的線程數
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock; // Block 的數量
    add<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);

    // 等待 GPU 計算完成
    cudaDeviceSynchronize();

    // 將結果從裝置拷貝回主機
    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    // 輸出結果
    for (int i = 0; i < 10; i++) {
        std::cout << h_c[i] << " ";
    }
    std::cout << std::endl;

    // 釋放記憶體
    free(h_a);
    free(h_b);
    free(h_c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    return 0;
}
```

---

#### **3. 程式結構解析**
1. **記憶體管理**：  
   - 主機與裝置需要獨立分配記憶體（`malloc` 和 `cudaMalloc`）。  
   - 資料在主機與裝置間進行拷貝（`cudaMemcpy`）。  

2. **Kernel 函數定義**：  
   - 使用 `__global__` 修飾符定義在 GPU 上執行的函數。  
   - 透過 `threadIdx`, `blockIdx`, 和 `blockDim` 計算每個線程的全域索引。

3. **Kernel 函數啟動**：  
   - 使用特殊語法 `<<<blocksPerGrid, threadsPerBlock>>>` 啟動 GPU 並行運算。  
   - `blocksPerGrid` 表示 Block 的數量，`threadsPerBlock` 表示每個 Block 的線程數。

4. **同步與結果回傳**：  
   - 使用 `cudaDeviceSynchronize()` 確保 GPU 完成計算。  
   - 使用 `cudaMemcpy` 將結果傳回主機記憶體。

5. **資源釋放**：  
   - 使用 `cudaFree` 釋放裝置記憶體，避免記憶體洩漏。

---

#### **4. 設計考量**
- **並行化設計**：  
  確保計算工作能有效劃分到多個線程，並充分利用 GPU 資源。  

- **資源管理**：  
  確保分配與釋放記憶體正確無誤，避免浪費 GPU 資源。  

- **性能優化**：  
  使用最佳化的 Grid 和 Block 配置來提升計算效率（例如避免線程分支和記憶體訪問衝突）。

---

以上為 CUDA 程式的基本結構與範例。接下來可以進一步探討性能優化策略，如共享記憶體、流（Streams）、以及複雜應用場景的設計方式。