### 核心函數（Kernel）與執行配置  

CUDA 程式的核心函數（Kernel）定義了在 GPU 上執行的計算邏輯。這部分包括核函數的基本定義方式、執行配置的組成以及如何設計和優化。

---

#### **1. 核心函數（Kernel）的基本概念**
1. **定義方式**：  
   核心函數使用 `__global__` 修飾符定義，表示該函數將在 GPU 上執行，但由 CPU 呼叫。  
   ```cpp
   __global__ void kernelFunction() {
       // 核心邏輯
   }
   ```

2. **線程模型**：  
   - CUDA 使用大量輕量級的「線程」進行並行計算。  
   - 線程組織成 Block，每個 Block 包含多個線程。多個 Block 再組成 Grid（網格）。  
   - 線程和 Block 的索引由內建變數提供：  
     - `threadIdx`：線程在 Block 中的索引。  
     - `blockIdx`：Block 在 Grid 中的索引。  
     - `blockDim`：Block 中的線程數量。  
     - `gridDim`：Grid 中的 Block 數量。

---

#### **2. 核心函數範例**
以下是一個執行向量加法的簡單核心函數範例：  
```cpp
__global__ void vectorAdd(int* a, int* b, int* c, int n) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x; // 計算全域索引
    if (idx < n) { // 確保索引合法
        c[idx] = a[idx] + b[idx];
    }
}
```
- `threadIdx.x`：當前線程在 Block 中的索引。  
- `blockIdx.x`：當前 Block 在 Grid 中的索引。  
- `blockDim.x`：每個 Block 中的線程數量。

---

#### **3. 核心函數的執行配置**
核心函數執行時需指定 Grid 和 Block 的大小，透過 CUDA 的特定語法啟動：  
```cpp
kernelFunction<<<gridDim, blockDim>>>(args...);
```
1. **執行配置參數**：  
   - `gridDim`：Grid 的維度（Block 的數量）。  
   - `blockDim`：每個 Block 中線程的數量。  
   - 可選第三參數和第四參數：  
     - 第三參數：動態分配的共享記憶體大小（以位元組為單位，默認為 0）。  
     - 第四參數：用於指定 Stream。  

2. **計算 Grid 和 Block 大小**：  
   Grid 和 Block 的設置應能最大化利用 GPU 資源。  
   通常的計算公式：  
   ```cpp
   int threadsPerBlock = 256; // Block 中線程數量
   int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock; // Grid 中 Block 數量
   ```

3. **範例：向量加法執行配置**：
   ```cpp
   int n = 1024; // 向量大小
   int threadsPerBlock = 256;
   int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;

   vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);
   ```

---

#### **4. 執行配置中的進階技巧**
1. **多維 Grid 和 Block**：  
   CUDA 支援一維、二維和三維的 Grid 和 Block 配置，適合高維數據的處理：  
   - 線程和 Block 的索引可使用 `threadIdx.y`, `blockIdx.z` 等。  
   - 配置範例：  
     ```cpp
     dim3 blockDim(16, 16); // 每個 Block 包含 16x16 個線程
     dim3 gridDim((width + blockDim.x - 1) / blockDim.x,
                  (height + blockDim.y - 1) / blockDim.y);
     kernelFunction<<<gridDim, blockDim>>>(args...);
     ```

2. **共享記憶體與同步化**：  
   - 使用共享記憶體（Shared Memory）提升同一 Block 內線程的資料交換效率。  
   - 使用內建函數 `__syncthreads()` 進行同步，確保所有線程完成計算後再繼續。

3. **執行配置最佳化**：  
   - 設定 Block 大小為 32 的倍數（因為 CUDA 的線程組織為 Warp 單位）。  
   - 減少分支分歧（Branch Divergence），保證同一 Warp 的線程執行相同路徑。

---

#### **5. 核心函數與執行配置的常見問題**
1. **記憶體訪問錯誤**：  
   - 核心函數中的索引超出界限可能導致未定義行為。需加邊界檢查：  
     ```cpp
     if (idx < n) {
         // 避免訪問越界
     }
     ```

2. **資源限制**：  
   - 每個 Block 的線程數量受到硬體限制（通常最大為 1024）。  
   - 超過限制會導致 CUDA 核心啟動失敗。

3. **性能瓶頸**：  
   - 全域記憶體訪問速度慢，應優先使用共享記憶體和寄存器（Registers）。  

---

核心函數與執行配置是 CUDA 程式設計的基礎，設計良好的執行配置能顯著提升運算性能。進階主題可進一步探討如何優化記憶體訪問模式、減少分支分歧以及提升多 GPU 程式的可擴展性。