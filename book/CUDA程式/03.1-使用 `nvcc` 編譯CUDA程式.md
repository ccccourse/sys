### 使用 `nvcc` 編譯 CUDA 程式  

CUDA 程式開發需要使用 NVIDIA 提供的專用編譯器 `nvcc`（NVIDIA CUDA Compiler）。`nvcc` 能將 CUDA 程式中包含的 C/C++ 和 GPU 核心程式碼（Device Code）進行編譯，生成可在 CUDA 支援的 GPU 上運行的可執行檔或目標文件。  

---

#### **1. `nvcc` 的基本概念**  

1. **C/C++ 與 CUDA 的結合**：  
   CUDA 程式碼包含主機端（Host）和裝置端（Device）程式碼，`nvcc` 負責將裝置端程式碼轉換為 GPU 能夠理解的 PTX（Parallel Thread Execution）或機器代碼，同時處理主機端程式碼。

2. **執行流程**：  
   - 主機端程式碼使用標準 C/C++ 編譯器（如 GCC）處理。  
   - 裝置端程式碼由 `nvcc` 處理，生成與 GPU 硬體匹配的機器代碼。  

---

#### **2. 安裝與確認 `nvcc`**  

1. **檢查 CUDA Toolkit 安裝**：  
   安裝 NVIDIA CUDA Toolkit 後，自動包含 `nvcc` 編譯器。  

2. **確認 `nvcc` 是否可用**：  
   開啟終端，輸入以下指令：  
   ```bash
   nvcc --version
   ```  
   範例輸出：
   ```
   nvcc: NVIDIA (R) Cuda compiler driver
   Built on Fri_Feb__3_23:34:00_PST_2023
   Cuda compilation tools, release 12.1, V12.1.105
   ```

---

#### **3. 基本使用方式**  

1. **編譯單一 CUDA 程式**：  
   假設 CUDA 程式碼文件為 `vector_add.cu`：  
   ```bash
   nvcc vector_add.cu -o vector_add
   ```  
   這將生成名為 `vector_add` 的執行檔案。  

2. **編譯多文件專案**：  
   如果專案包含多個 CUDA 文件，可以分別編譯成目標文件，然後鏈結：  
   ```bash
   nvcc -c kernel.cu -o kernel.o
   nvcc -c main.cu -o main.o
   nvcc kernel.o main.o -o program
   ```  

3. **指定 GPU 架構**：  
   可以通過 `-arch` 選項指定目標 GPU 架構：  
   ```bash
   nvcc -arch=sm_75 vector_add.cu -o vector_add
   ```  
   - `sm_75` 表示針對 NVIDIA Turing 架構（如 RTX 2080）。  
   - 常用架構對照表見 [NVIDIA 官網](https://developer.nvidia.com/cuda-gpus)。

---

#### **4. 編譯選項**  

`nvcc` 提供多種選項來控制編譯流程和輸出，以下是常用的選項：  

| **選項**           | **描述**                                                                                 |
|--------------------|-----------------------------------------------------------------------------------------|
| `-o <file>`       | 指定輸出的檔案名稱（可執行檔或目標文件）。                                                 |
| `-c`              | 只編譯為目標文件，不進行鏈結。                                                            |
| `-arch=<arch>`    | 指定目標 GPU 架構（如 `sm_75` 或 `compute_70`）。                                          |
| `--ptx`           | 僅生成 PTX 中間代碼文件。                                                                 |
| `-I <dir>`        | 指定包含檔案的路徑（例如 CUDA 標頭檔）。                                                    |
| `-L <dir>`        | 指定庫檔案的路徑。                                                                         |
| `-l<library>`     | 指定鏈結的庫（如 `-lcudart` 代表鏈結 CUDA Runtime）。                                       |
| `-G`              | 開啟調試模式（生成調試信息，禁用某些最佳化）。                                               |
| `-O<n>`           | 設置最佳化等級，`n` 可為 `0`（無最佳化）、`2`（常用最佳化）等。                              |

---

#### **5. 範例：從編寫到編譯執行**  

##### **程式碼：`vector_add.cu`**  
```cpp
#include <iostream>
#include <cuda_runtime.h>

__global__ void addVectors(int* a, int* b, int* c, int n) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    if (idx < n) {
        c[idx] = a[idx] + b[idx];
    }
}

int main() {
    const int N = 1024;
    const int size = N * sizeof(int);

    int h_a[N], h_b[N], h_c[N];
    for (int i = 0; i < N; ++i) {
        h_a[i] = i;
        h_b[i] = i * 2;
    }

    int *d_a, *d_b, *d_c;
    cudaMalloc(&d_a, size);
    cudaMalloc(&d_b, size);
    cudaMalloc(&d_c, size);

    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    addVectors<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, N);

    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    for (int i = 0; i < 10; ++i) {
        std::cout << h_c[i] << " ";
    }

    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    return 0;
}
```

##### **編譯與執行**  
1. **編譯**：  
   ```bash
   nvcc vector_add.cu -o vector_add
   ```  

2. **執行**：  
   ```bash
   ./vector_add
   ```  
   範例輸出（部分）：  
   ```
   0 3 6 9 12 15 18 21 24 27
   ```

---

#### **6. 調試與性能分析**  

1. **開啟調試模式**：  
   使用 `-G` 選項編譯，允許在 CUDA-GDB 中進行調試：  
   ```bash
   nvcc -G vector_add.cu -o vector_add_debug
   ```

2. **執行性能分析**：  
   使用 `nvprof` 或 `Nsight Systems` 工具進行性能分析：  
   ```bash
   nvprof ./vector_add
   ```

---

#### **7. 最佳實踐建議**  

1. **明確指定 GPU 架構**：  
   確保生成的程式碼針對目標硬體最佳化，避免編譯過程的冗餘。  

2. **按需啟用調試與性能分析**：  
   開啟調試選項可能導致運行效率下降，應僅在必要時使用。  

3. **分離編譯與鏈結**：  
   在大型專案中，採用分離編譯能提升開發效率和編譯速度。  

使用 `nvcc` 是進行 CUDA 開發的基礎，熟練掌握其選項和使用方法能顯著提升開發效率和程式性能。