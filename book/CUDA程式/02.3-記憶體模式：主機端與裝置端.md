### 記憶體模式：主機端與裝置端  

CUDA 程式的運行涉及 CPU 和 GPU 兩種計算單元，分別被稱為主機（Host）和裝置（Device）。這種雙端架構導致了記憶體操作的複雜性，理解主機端和裝置端的記憶體模式是 CUDA 開發的核心。

---

#### **1. 主機端與裝置端的記憶體分類**
CUDA 記憶體可大致分為以下幾種類型，對應不同的硬體資源和應用場景：  

1. **主機記憶體（Host Memory）**：
   - 位於 CPU 的 DRAM（系統主記憶體）。  
   - 透過 CUDA API 將數據從主機記憶體傳輸到裝置記憶體，或從裝置傳回主機。  

2. **裝置記憶體（Device Memory）**：
   - 位於 GPU 的全球記憶體（Global Memory），可被所有 GPU 核心訪問，但速度相對較慢。  

3. **其他記憶體類型（在裝置內部分）**：
   - **共享記憶體（Shared Memory）**：
     - Block 級別的快速記憶體，適合同一 Block 的線程進行數據共享。  
   - **寄存器記憶體（Registers）**：
     - 每個線程私有，速度最快，但數量有限。  
   - **常數記憶體（Constant Memory）**：
     - 儲存只讀數據，所有線程可共享，速度相對較快。  
   - **紋理記憶體和表面記憶體（Texture & Surface Memory）**：
     - 用於特定應用，如影像處理或查表操作。

---

#### **2. 主機端與裝置端的記憶體操作**
在 CUDA 中，數據傳輸和記憶體分配是開發的重要環節，常用的操作包括：

1. **記憶體分配**：
   - 在裝置上分配記憶體使用 `cudaMalloc`。  
     ```cpp
     int* d_a;
     cudaMalloc((void**)&d_a, n * sizeof(int)); // 分配裝置記憶體
     ```

2. **數據傳輸**：
   - 主機與裝置間數據傳輸使用 `cudaMemcpy`。  
     ```cpp
     cudaMemcpy(d_a, h_a, n * sizeof(int), cudaMemcpyHostToDevice); // 主機到裝置
     cudaMemcpy(h_a, d_a, n * sizeof(int), cudaMemcpyDeviceToHost); // 裝置到主機
     ```

3. **釋放記憶體**：
   - 用 `cudaFree` 釋放裝置記憶體。  
     ```cpp
     cudaFree(d_a);
     ```

---

#### **3. 記憶體模式範例**
以下範例展示如何分配主機和裝置記憶體，進行數據傳輸，並執行核心函數：  

```cpp
#include <cuda_runtime.h>
#include <iostream>

__global__ void addKernel(int* d_a, int* d_b, int* d_c, int n) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    if (idx < n) {
        d_c[idx] = d_a[idx] + d_b[idx];
    }
}

int main() {
    int n = 1024;
    int size = n * sizeof(int);

    // 主機記憶體分配
    int* h_a = (int*)malloc(size);
    int* h_b = (int*)malloc(size);
    int* h_c = (int*)malloc(size);

    // 初始化數據
    for (int i = 0; i < n; ++i) {
        h_a[i] = i;
        h_b[i] = i * 2;
    }

    // 裝置記憶體分配
    int *d_a, *d_b, *d_c;
    cudaMalloc((void**)&d_a, size);
    cudaMalloc((void**)&d_b, size);
    cudaMalloc((void**)&d_c, size);

    // 主機到裝置數據傳輸
    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);

    // 核心函數執行
    int threadsPerBlock = 256;
    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;
    addKernel<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, n);

    // 裝置到主機數據傳輸
    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);

    // 驗證結果
    for (int i = 0; i < 10; ++i) {
        std::cout << h_c[i] << " ";
    }

    // 釋放記憶體
    free(h_a);
    free(h_b);
    free(h_c);
    cudaFree(d_a);
    cudaFree(d_b);
    cudaFree(d_c);

    return 0;
}
```

---

#### **4. 主機端與裝置端記憶體模式的進階特性**
1. **頁鎖記憶體（Pinned Memory）**：  
   - 使用 `cudaMallocHost` 分配頁鎖記憶體，提高數據傳輸效率。  
     ```cpp
     cudaMallocHost((void**)&h_a, n * sizeof(int));
     ```

2. **統一記憶體（Unified Memory）**：  
   - 使用 `cudaMallocManaged` 分配統一記憶體，主機和裝置可共用，簡化數據管理。  
     ```cpp
     cudaMallocManaged(&data, size);
     ```

3. **異步傳輸**：  
   - 使用 CUDA Stream 實現異步數據傳輸，提升性能。  
     ```cpp
     cudaMemcpyAsync(d_a, h_a, size, cudaMemcpyHostToDevice, stream);
     ```

4. **零拷貝（Zero-Copy）模式**：  
   - 在某些情況下，主機和裝置記憶體可以共用相同的物理記憶體，省去數據傳輸開銷。

---

#### **5. 主機端與裝置端記憶體管理的最佳實踐**
1. **減少數據傳輸**：
   - 將多次計算盡量安排在裝置端，減少主機與裝置之間的數據傳輸。  

2. **優化傳輸模式**：
   - 使用頁鎖記憶體或統一記憶體，提升數據傳輸速度。  

3. **正確釋放記憶體**：
   - 所有分配的記憶體必須釋放，避免記憶體洩漏。

主機端與裝置端記憶體模式的有效管理是提升 CUDA 應用性能的關鍵。未來章節將深入探討如何透過共享記憶體和寄存器進一步優化記憶體訪問效率。